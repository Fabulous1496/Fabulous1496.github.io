<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>CMU15-213</title>
    <link href="/2024/06/25/CMU15-213/"/>
    <url>/2024/06/25/CMU15-213/</url>
    
    <content type="html"><![CDATA[<p>本篇主要记录在学习课程CMU15-213(version:sp23)以及配套教材CS:APP中的总结、梳理、拓展以及个人感想。<br>lab的代码部分更新于Github。</p><h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><blockquote><p>对应CS:APP第一章</p></blockquote><p>让我们从详细理解一段代码的生命周期开始深入了解计算机在这一过程中完成了哪些操作。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdio.h&gt;</span></span><br><br><span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">()</span> <br>&#123;<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;hello, world\n&quot;</span>);<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>hello程序的生命周期是从一个高级的C语言程序开始的，但是在机器执行时需要将这些语句转化为一系列的低级<strong>机器语言</strong>指令。然后这些指令按照一种称为<strong>可执行目标程序</strong>的格式打包，并以二进制磁盘文件的形式存放起来。</p><p>通过一条指令 <em>gcc -o hello hello.c</em> ，我们便可以将程序编译为可执行文件。具体而言，一般需要经历以下过程。</p><p><img src="/Pictures/CMU15-213/%E7%BC%96%E8%AF%91%E7%B3%BB%E7%BB%9F.png" alt="编译系统"></p><ul><li><strong>预处理阶段</strong>。预处理器（cpp）根据 # 开头的命令修改原始的C程序。在这里，include语句告诉预处理器将stdio.h文件中从内容插入程序文本中。经过这一步，我们实现了从 <em>hello.c</em>到<em>hello.i</em>的变化。</li><li><strong>编译阶段</strong>。编译器（ccl）将文本文件 <em>hello.i</em> 翻译成 <em>hello.s</em> ，即翻译为汇编语言程序。</li><li><strong>汇编阶段</strong>。汇编器（as）将 <em>hello.s</em> 翻译为机器语言指令并打包为<strong>可重定位目标程序</strong>的格式，并保存在二进制文件 <em>hello.o</em> 中。</li><li><strong>链接阶段</strong>。在hello程序中调用了printf函数，该函数保存在<em>printf.o</em>文件中，链接过程就是将这些文件以某种方式进行合并。合并完成后我们得到<strong>可执行目标文件</strong> <em>hello</em>。</li></ul><p>在得到可执行目标文件后，我们可以将其输入到shell（命令行解释器）中。</p><p>为了更深入的理解运行程序时计算机内部发生了什么，我们需要了解一个典型系统的硬件知识。</p><img src="/Pictures/CMU15-213/System model.png"><ol><li><p>总线</p><p>总线携带信息字节并负责在各个部件之间进行传递。通常总线被设计为定长的字节块，也就是字（word）。32位指代4字节，而64位指代8字节。</p></li><li><p>I&#x2F;O设备</p><p>输入输出设备时系统与外部世界进行联系的通道。常见的I&#x2F;O设备包括键鼠、显示器、磁盘等。每个设备都通过一个<strong>控制器</strong>或<strong>适配器</strong>与I&#x2F;O总线相连。</p><p>控制器与适配器之间的区别在于封装方式。控制器通常是I&#x2F;O设备本身或者系统的主板上的芯片组，而适配器时插在主板上的卡。</p></li><li><p>主存</p><p>主存是一个临时存储设备，用于存放程序和程序处理的数据。主存由一组<strong>动态随机存取存储器（DRAM）</strong>芯片组成。从逻辑上来说，存储器是一个线性的字节数组，每一个字节都有其唯一的地址（数组索引）。</p></li><li><p>处理器</p><p>处理器（CPU）是解释（或执行）存储在主存中指令的引擎。处理器的核心是一个大小为一个字的存储设备（或寄存器），称为程序计数器（PC），在任何时刻，PC都指向主存中某条机器指令。</p><p>指令集架构决定指令执行模型。</p></li></ol><p>在运行代码的过程中，数据需要在内存、处理器、总线上来回搬运。因此要提高运行速度，就需要是这些复制搬运操作加快。我们可以通过在处理器和较大较慢的设备（例如主存）之间插入一个更小更快的存储设备（例如cache）来加速这个过程，于是便产生了一个<strong>存储器层次结构</strong>。</p><p><img src="/Pictures/CMU15-213/%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84.png" alt="存储器层次结构"></p><p>为了防止硬件被失控的应用程序滥用以及提供一个简单一致的机制来控制复杂低级的硬件，我们使用操作系统来提供这些服务。操作系统提供了几个基本的抽象概念来实现基本功能。</p><p><img src="/Pictures/CMU15-213/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.png" alt="操作系统"></p><ul><li><p>进程</p><p>进程是操作系统对正在运行的程序的一种抽象。一个系统可以同时运行多个进程。在系统中，一个CPU通过在进程之间切换来实现交错执行的机制，称为<em>上下文切换</em>，也是CPU能进行并发执行的原因。在这里，上下文是一个抽象的概念，指操作系统保持跟踪进程运行所需的所有状态信息。上下文切换时，操作系统会保存当前状态的上下文，恢复新进程的上下文。新进程会从上次中断的地方开始。</p></li><li><p>线程</p><p>一个进程可以由多个称为线程的执行单元组成。</p></li><li><p>虚拟内存</p><p>虚拟内存为每一个进程提供了一个假象，即每个进程都在独占地使用主存。每个进程看到的内存是一致的，称为虚拟地址空间。</p><p>对于所有进程而言，代码是从统一固定位置开始，紧接着的是和C全局变量相对应的数据位置。</p><p>涉及的一些名词和概念：</p><ul><li><strong>运行时堆</strong>：代码和数据在进程一开始时确定大小，调用函数时堆可以在运行时动态的扩展和收缩。</li><li><strong>共享库</strong>：用于存放C标准库和数学库这样的共享的代码和数据。</li><li><strong>用户栈</strong>：用于实现函数的调用。调用函数时会导致栈增长，函数返回时栈收缩。</li><li><strong>内核虚拟内存</strong>：应用程序调用内核执行操作。</li></ul></li></ul><p><img src="/Pictures/CMU15-213/%E8%99%9A%E6%8B%9F%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4.png" alt="虚拟地址空间"></p><p><strong>Amdahl定律</strong>：在对系统某个部分进行加速时，其对系统整体性能的影响取决于该部分的重要性和加速程度。假设执行某应用程序所需要的时间为$T_{old}$，某部分与执行时间总体的比例为$\alpha$，该部分提升性能比例为$k$，则有：<br>$$<br>T_{new}&#x3D;(1-\alpha)T_{old}+(\alpha T_{old})&#x2F;k&#x3D;T_{old}[(1-\alpha)+\alpha&#x2F;k]<br>$$<br>$$<br>S&#x3D;T_{old}&#x2F;T_{new}&#x3D; \frac{1}{(1-\alpha)+\alpha&#x2F;k}<br>$$</p><p>$$<br>k\to\infty,\quad S_\infty&#x3D;\frac{1}{1-\alpha}<br>$$<br>最后，我们来了解并发与并行。一般来说，我们重点从三个抽象级层次来理解。</p><ol><li>线程级并发。简单来说，就是利用一个处理器同时处理多个线程。这其中需要用到<strong>超线程技术</strong>，具体来说就是CPU内部的寄存器和PC有多个备份，用于储存不同的线程上下文，而共用一份其它的硬件。</li><li>指令级并行。利用一个处理器同时执行多条指令。</li><li>单指令、多数据并行。利用特殊的硬件允许一条指令产生多个可以并行执行的操作，简称SIMD并行。</li></ol><h1 id="Representing-and-Manipulating-Information"><a href="#Representing-and-Manipulating-Information" class="headerlink" title="Representing and Manipulating Information"></a>Representing and Manipulating Information</h1><blockquote><p>对应原书CS:APP第二章</p></blockquote><h2 id="Representing-information-as-bits"><a href="#Representing-information-as-bits" class="headerlink" title="Representing information as bits"></a>Representing information as bits</h2><p>在现代计算机系统中，我们通常用位（bits）：0&#x2F;1来表示数据。</p><table><thead><tr><th>C Data Type</th><th>Typical 32-bit</th><th>Typical 64-bit</th></tr></thead><tbody><tr><td>char</td><td>1</td><td>1</td></tr><tr><td>short</td><td>2</td><td>2</td></tr><tr><td>int</td><td>4</td><td>4</td></tr><tr><td>long</td><td>4</td><td>8</td></tr><tr><td>float</td><td>4</td><td>4</td></tr><tr><td>double</td><td>8</td><td>8</td></tr><tr><td>pointer</td><td>4</td><td>8</td></tr></tbody></table><h2 id="Boolean-Algebra"><a href="#Boolean-Algebra" class="headerlink" title="Boolean Algebra"></a>Boolean Algebra</h2><p>布尔代数：我们用0代表false，1代表true</p><p>布尔运算：定义四种基本布尔运算。对于 Bit Vectors，采取逐位计算的方式。</p><ol><li>AND:  A&amp;B &#x3D; 1 when A &#x3D; 1 and B &#x3D; 1</li><li>OR:  A | B &#x3D; 1 when A &#x3D; 1 or B &#x3D; 1 or both</li><li>NOT:  ~A &#x3D; 1 when A &#x3D; 0</li><li>XOR:  A^B &#x3D; 1 when A !&#x3D; B</li></ol><p>对于Bit Vectors 的运算，我们可以采用下面这种表示方式：若一个Bit Vector 定义为A，我们从左至右从0开始给每一位编号，然后将其中为1的位的序号组成一个集合，代表这个向量。</p><p>例如：$A&#x3D;01101001 \quad \rightarrow \quad {0,3,5,6},B&#x3D;01010101 \quad \rightarrow \quad {0,2,4,6}$</p><p>这样表示后，我们可以将布尔代数转化为集合的运算：</p><ul><li>&amp;  交集（intersection）：A&amp;B&#x3D;{0,6}</li><li>|  并集（union）：A|B&#x3D;{0,2,3,4,5,6}</li><li>^  相异的元素（Symmetric difference）：A^B&#x3D;{2,3,4,5}</li><li>~  补集（Complement）：~A&#x3D;{1,2,4,7}</li></ul><div class="note note-info">            <p>C语言的Shift Operations：</p><p>x&lt;&lt;y:将一个整数x的二进制形式向左移动y位，右侧用0填补，在数学意义上会导致值乘2的y次方。</p><p>例：5(0000 0101)&lt;&lt;2 &#x3D; 5*2^2&#x3D;20(0001 0100)</p><p>x&gt;&gt;y:分为算术右移和逻辑右移。</p><p>算术右移会保留符号位（最高位），即右移操作不改变数字的正负。而逻辑右移不考虑符号位，直接将左侧用0填充。</p>          </div><h2 id="Integer"><a href="#Integer" class="headerlink" title="Integer"></a>Integer</h2><p>一些关于转换编码的名词：</p><table><thead><tr><th>符号</th><th>类型</th><th>含义</th></tr></thead><tbody><tr><td>$B$</td><td>数据类型</td><td>Binary，二进制数</td></tr><tr><td>$T$</td><td>数据类型</td><td>Two’s Complement，补码</td></tr><tr><td>$U$</td><td>数据类型</td><td>Unsigned，无符号数</td></tr><tr><td>$\omega$</td><td>常数</td><td>数据表示的位数</td></tr><tr><td>$X2Y_\omega$</td><td>函数</td><td>从$X$的数据类型转换为$Y$</td></tr><tr><td>$TMin_\omega$ &#x2F; $TMax_\omega$</td><td>常数</td><td>最小&#x2F;最大补码值</td></tr><tr><td>$UMax_\omega$</td><td>常数</td><td>最大无符号数</td></tr><tr><td>$+^{t}_{\omega}$  &#x2F;  $+^u_\omega$</td><td>运算操作</td><td>补码  &#x2F;  无符号数加法</td></tr><tr><td>$*^t_\omega$  &#x2F;  $*^u_\omega$</td><td>运算操作</td><td>补码  &#x2F;  无符号数乘法</td></tr><tr><td>$-^t_\omega$  &#x2F;  $-^u_\omega$</td><td>运算操作</td><td>补码  &#x2F;  无符号数取反</td></tr></tbody></table><p>无符号数的编码定义：<br>$$<br>B2U_\omega(x)&#x3D;\sum_{i&#x3D;0}^{\omega-1}x_i 2^i<br>$$<br>补码编码定义：即最高有效位的权值为负数。<br>$$<br>B2T_\omega(x)&#x3D;-x_{\omega-1}2^{\omega-1}+\sum_{i&#x3D;1}^{\omega-2}x_i 2^i<br>$$<br>可以把反码理解为最高有效位的权值为$2^{\omega-1}-1$。故有补码&#x3D;反码+1.</p><p>无符号数加法(包含溢出情况)：<br>$$<br>x+y&#x3D;\begin{cases}x+y \ ,\ x+y\le2^\omega \\ x+y-2^\omega \ , \ x+y\ge2^\omega \end{cases}<br>$$<br>补码加法（包含正溢出和负溢出）：<br>$$<br>x+y&#x3D;\begin{cases}x+y-2^\omega \ , \ x+y\ge2^{\omega-1}  \\ x+y \\ x+y+2^\omega \ , \ x+y&lt;-2^{\omega-1} \end{cases}<br>$$</p><h2 id="Float"><a href="#Float" class="headerlink" title="Float"></a>Float</h2><p>浮点数的编码表示：利用小数点后的第$i$位来表示权值为$2^{-i}$的位。</p><p>例如，浮点数$0.111_2&#x3D;1\times2^{-1}+1\times2^{-2}+1\times2^{-3}&#x3D;0.5+0.25+0.125&#x3D;0.875$</p><p><strong>IEEE浮点表示</strong>：IEEE浮点标准用$V&#x3D;(-1)^s\times M\times 2^E$的形式来表示一个数。</p><ul><li>符号（sign）：s决定这个数的正负属性</li><li>尾数（significand）M是一个二进制小数，范围是$1\sim 2-\varepsilon$，或者是$0 \sim 1-\varepsilon$</li><li>阶码（exponent）E的作用是对浮点数进行加权，这个权重是2的E次幂（可能是负次幂）</li><li>一个单独的符号位编码s</li><li>k位的阶码字段 $exp&#x3D;e_{k-1}…e_1e_0$编码阶码E</li><li>n位的小数字段$frac&#x3D;f_{n-1}…f_1f_0$编码位数M</li></ul><p>单精度与双精度浮点数的存储：</p><p><img src="/Pictures/CMU15-213/float.png" alt="float"></p><p>根据不同的exp的取值，被编码的值可以分为三种不同的情况：</p><ol><li><p>规格化的，此时 $exp \ne 0 且\ne 255$，此时$E&#x3D;e-Bias$，其中$Bias&#x3D;2^{k-1}-1$，单精度为127，双精度为1023. 指数的范围为单精度$-126 \sim 127 $，双精度为$-1022 \sim 1023$。</p><p>小数字段frac被解释为$0.f_{n-1}…f_1f_0$，尾数定义为$M&#x3D;1+f$。这种方式也被称为隐含的以1开头的表示。</p></li><li><p>非规格化，此时$exp&#x3D;0$，在这种情况下，阶码值是$E&#x3D;1-Bias$，尾数的值为$M&#x3D;f$，也就是小数字段的值，不包含隐含的开头的1.</p></li><li><p>特殊值，当阶码全为1即$exp&#x3D;255$时，小数域全为0时，得到的值表示无穷。当小数域的结果非0时，结果值被称为NaN。</p></li></ol><p>浮点数的<strong>舍入（Rounding）</strong>：</p><p>浮点数的舍入有多种方式，下面举例说明四种常见的舍入方式：</p><table><thead><tr><th>方式</th><th>1.40</th><th>1.60</th><th>1.50</th><th>2.50</th><th>-1.50</th></tr></thead><tbody><tr><td>向偶数舍入</td><td>1</td><td>2</td><td>2</td><td>2</td><td>-2</td></tr><tr><td>向零舍入</td><td>1</td><td>1</td><td>1</td><td>2</td><td>-1</td></tr><tr><td>向上舍入</td><td>2</td><td>2</td><td>2</td><td>3</td><td>-1</td></tr><tr><td>向下舍入</td><td>1</td><td>1</td><td>1</td><td>2</td><td>-2</td></tr></tbody></table><p>向偶数舍入是计算机默认的舍入方式，其原理是找到一个最接近的整数进行舍入，在出现两个结果的中间数时（1.5,2.5等）使舍入后的数最低有效位为偶数。</p><p>向偶数舍入的优势是：在计算平均值是，向上舍入或向下舍入会导致整体的平均值偏大或偏小，而向偶数舍入在大多数情况下避免了这种现实偏差，即有50%的概率向上舍入，同时有50%的概率向下舍入。</p><p>浮点数的运算：</p><p>我们将浮点值的计算定义为$x+y&#x3D;Round(x+y)$，只需要计算到一个可以得到正确舍入结果的答案即可。</p><p>浮点加法不具有结合性。例如$3.14+1e10-1e10&#x3D;0$，这是因为计算前两项时由于舍入的原因值3.14会丢失。而计算$3.14+(1e10-1e10)&#x3D;3.14$。</p><p>同时，这也导致了浮点乘法不具备分配性。</p>]]></content>
    
    
    <categories>
      
      <category>CMU5-213</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>GNN——图神经网络</title>
    <link href="/2024/03/20/GNN%E2%80%94%E2%80%94%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <url>/2024/03/20/GNN%E2%80%94%E2%80%94%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
    
    <content type="html"><![CDATA[<h1 id="Graph"><a href="#Graph" class="headerlink" title="Graph"></a>Graph</h1><p>首先，我们来了解一下什么是<em>Graph</em>。一般而言，图由三部分组成：</p><ol><li><strong>V</strong>  Vertex(or node) attributes，节点</li></ol><p><img src="/Pictures/DL/GNN/Vertex.png" alt="Vertex"></p><p>子属性包括节点标识，节点邻居数</p><ol start="2"><li><strong>E</strong> Edge(or link) attributes and directions，边</li></ol><p><img src="/Pictures/DL/GNN/Edge.png" alt="Edge"></p><p>子属性包括边标识，边权重。<br>边可以包括有向边和无向边，有向边表示信息单方向流入，即从源节点流向目标节点；而无向边可以看为两个有向边的叠加，表示信息双向流动。</p><p><img src="/Pictures/DL/GNN/twoEdges.png" alt="twoEdges"></p><ol start="3"><li><strong>U</strong> Global(or masternode) attributes，全局信息</li></ol><p><img src="/Pictures/DL/GNN/Global.png" alt="Global"></p><p>子属性包括节点数，最长路径</p><p>为了深入探究三者之间的关系，我们将每个节点信息、边信息和全局信息做Embedding，储存为向量形式。所以图神经网络的核心就是如何将我们想要的有效信息保存为向量以及如何建立神经网络从里面学习到有用的信息。</p><p><img src="/Pictures/DL/GNN/Embedding.png" alt="Embedding"></p><h1 id="将数据转化为Graph"><a href="#将数据转化为Graph" class="headerlink" title="将数据转化为Graph"></a>将数据转化为Graph</h1><h2 id="Images-as-graphs"><a href="#Images-as-graphs" class="headerlink" title="Images as graphs"></a>Images as graphs</h2><p>我们通常将图像视为具有图像通道的矩形网格，将它们表示为数组（例如，244x244x3）。<br>在这里，我们将图像理解为一种具有规则结构的Graph：每一个像素为一个节点，储存着代表RGB值的三维向量，并通过边连接到其他的像素，所以每一个非边界像素正好有8个邻居。</p><p><img src="/Pictures/DL/GNN/img2grp.png" alt="img2grp"></p><h2 id="Text-as-graphs"><a href="#Text-as-graphs" class="headerlink" title="Text as graphs"></a>Text as graphs</h2><p>我们可以通过将索引与每个字符、单词或标记相关联，并将文本表示为这些索引的序列来数字化文本，这将创建一个简单的有向图，其中每一个字符或索引都是一个系欸但，并通过边连接到其后面的节点。</p><p><img src="/Pictures/DL/GNN/text.png" alt="text"></p><h2 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h2><p>除了上面提到的将图运用于CV和NLP领域的用法，我们还可以将图运用于其它各种数据内容中。<br>例如，我们可以将分子结构转换为图，其中每一个原子代表一个节点，每一个化学键代表一条边；<br>我们还可以将社交网络转换为图，每个人是一个节点，人与人之间的关系作为边；我们可以将论文的引文网络转换为图，将每篇论文看作一个节点，而一篇论文与另一篇论文之间的引用关系看作是一条有向边。</p><h1 id="利用图进行预测"><a href="#利用图进行预测" class="headerlink" title="利用图进行预测"></a>利用图进行预测</h1><p>Graph的预测任务一般分为三种：graph-level, node-level, and edge-level.</p><h2 id="Graph-level"><a href="#Graph-level" class="headerlink" title="Graph-level"></a>Graph-level</h2><p>在图级任务中，我们的目标是预测整个图的属性。例如，对于用图表表示的分子，我们可能想要预测该分子闻起来像什么，或者它是否会与与疾病有关的受体结合。</p><p>我们输入不含标签的Graph，经过学习后，神经网络会输出一个带有特定标签的图。</p><p><img src="/Pictures/DL/GNN/graph-level.png" alt="graph-level"></p><p>这类似于CIFAR的图片分类或者文本的标签分类问题。</p><h2 id="Node-level-task"><a href="#Node-level-task" class="headerlink" title="Node-level task"></a>Node-level task</h2><p>同理，对节点的预测一般是预测节点自身的一些属性和特征。</p><p>按照图像类比，节点级预测问题类似于图像分割，我们试图标记图像中每个像素的作用。对于文本，类似的任务是预测句子中每个单词的词性（例如名词、动词、副词等）。</p><p><img src="/Pictures/DL/GNN/node.png" alt="node-level"></p><h2 id="Edge-level-task"><a href="#Edge-level-task" class="headerlink" title="Edge-level task"></a>Edge-level task</h2><p>对边的预测一般是预测边连接哪些节点以及信息的传递方式。</p><p><img src="/Pictures/DL/GNN/edge-leve.png" alt="edge-level"></p><h1 id="构建图神经网络"><a href="#构建图神经网络" class="headerlink" title="构建图神经网络"></a>构建图神经网络</h1><h2 id="图的数据结构"><a href="#图的数据结构" class="headerlink" title="图的数据结构"></a>图的数据结构</h2><p>在深度学习中，我们的数据一般以张量形式出现。对于图，最多包含四种类型的信息：节点、边、全局、连接性。</p><p>前三个相对而言比较简单，例如对于每个节点，我们都可以为其分配一个索引 $i$ ，这样我们可以构建出一个特征矩阵 $N$ , $node_{n}$ 的特征就储存在矩阵 $N$ 中。</p><p>困难的是如何表示图的连通性。一个直观的方式是使用邻接矩阵。</p><div class="note note-info">            <p>邻接矩阵（Adjacency Matrix）是用来表示图的一种常见方法之一。它是一个二维矩阵，其中的行和列分别代表图中的节点，而矩阵的元素表示节点之间是否存在边。</p><p>对于一个有向图，邻接矩阵的元素 $A_{ij}$ 表示从节点 $i$ 到节点 $j$ 是否存在一条边。如果存在边，则 $A_{ij}$ 的值通常为 1 或者表示边的权重；如果不存在边，则 $A_{ij}$ 的值通常为 0 或者其他表示不存在的值。在无向图中，如果节点 $i$ 与节点 $j$ 之间有边相连，则 $A_{ij}$ 和 $A_{ji}$ 都被设为 1（或者边的权重），否则为 0。</p><p>举例来说，对于一个无向图，如果存在节点 1 和节点 2 之间的边，则对应的邻接矩阵中的元素 $A_{12}$ 和 $A_{21}$ 都会被设为 1。而如果节点 1 和节点 3 之间没有边，则对应的 $A_{13}$ 和 $A_{31}$ 元素都会被设为 0。</p>          </div><p>邻接矩阵的优点是易于理解和实现，同时可以很方便地进行一些矩阵运算，比如矩阵乘法，从而在一些图算法中提供了便利。然而，对于大规模稀疏图来说，邻接矩阵会占用较多的内存空间，因为它会存储大量的零元素，因此在这种情况下，邻接表等其他数据结构可能更为高效。</p><p><img src="/Pictures/DL/GNN/adjacency_matrix.png" alt="adjacency_matrix"></p><p>可以看见，表示四个节点之间的连接关系，我们就需要相当数量的矩阵来表示。</p><p>另一种方式是使用邻接表。</p><p><img src="/Pictures/DL/GNN/adjacency_list.png" alt="adjacency_list"></p><p>在表中，我们将每个node进行编码，然后使用一个tuple来储存两个node之间的连接关系。<br>上图中的节点、边和全局信息都可以用向量表示，而不一定只是标量。</p><h2 id="图神经网络"><a href="#图神经网络" class="headerlink" title="图神经网络"></a>图神经网络</h2><p>图的描述是排列不变的矩阵格式，我们将描述使用图神经网络（GNN）来解决图预测任务。 GNN 是对图的所有属性（节点、边、全局上下文）的可优化变换，可保留图对称性（排列不变性）。</p><p>GNN 采用“图输入、图输出”架构，这意味着这些模型类型接受图作为输入，将信息加载到其节点、边和全局上下文中，并逐步转换这些嵌入，而不改变输入的连接性图形。</p><h3 id="The-simplest-GNN"><a href="#The-simplest-GNN" class="headerlink" title="The simplest GNN"></a>The simplest GNN</h3><p>我们利用简单的MLP来构建GNN Layer</p><p><img src="/Pictures/DL/GNN/GNNlayer.png" alt="GNNlayer"></p><p>在经过多个全连接层的梯度下降和反向传播更新参数后，我们得到了一张不改变连接性但是改变节点和边、全局内容的图作为输出，我们可以使用与输入图相同的邻接表和相同数量的特征向量来描述 GNN 的输出图。</p><p>与神经网络模块或层一样，我们可以将这些 GNN 层堆叠在一起，获得更好的拟合效果。</p><div class="note note-info">            <p>多层感知机是一种常见的人工神经网络模型，由多个全连接层（Fully Connected Layer）组成，每个全连接层都包含多个神经元（或称为节点），相邻层之间的神经元之间全部连接。</p><p>在图神经网络中，MLP 通常被用作节点级别的特征转换器。具体来说，MLP 接收节点的特征作为输入，并通过多个全连接层来学习节点的新表示。这些新表示可以捕捉节点在图中的局部结构和全局信息，从而用于各种任务，如节点分类、节点预测等。</p><p>在 GNN 中，MLP 通常被应用在每个节点的特征更新过程中，以帮助节点表示学习更丰富的信息。例如，在图卷积网络（GCN）中，MLP 可以被用来对节点的邻居特征进行聚合和变换，以生成新的节点表示。在此过程中，MLP 的参数通常是可学习的，它们会通过反向传播算法来进行训练，以最大化模型的性能。</p>          </div><h3 id="Pooling"><a href="#Pooling" class="headerlink" title="Pooling"></a>Pooling</h3><p>如果我们进行的只是简单的分类任务，我们只需要对每个节点的embedding（即对应的张量）应用一个线性分类器即可。</p><p>但是这仅仅只利用了节点所储存的信息，并没有利用到边储存的信息和连接性。通过池化，我们可以收集边所储存的信息提供给节点进行预测。</p><p>池化的过程分两步进行：</p><ol><li>对于要池化的每个项目，收集对应的张量并将它们连接成一个矩阵。</li><li>通过求和运算来得到收集的信息张量。</li></ol><p><img src="/Pictures/DL/GNN/Pooling.png" alt="Pooling"></p><p>通过这种简单的叠加方式，我们可以将信息从节点传递到边或者从边传递到节点。</p><p>如果我们只有节点级特征，并且需要预测全局属性，则需要将所有可用的节点信息收集在一起并聚合它们。这类似于 CNN 中的全局平均池层。对于边缘也可以进行同样的操作。</p><p>我们用 $\rho$ 表示池化操作，并用 $pE_{n}\to V_{n}$ 表示从边收集信息到节点</p><h3 id="Passing-messages"><a href="#Passing-messages" class="headerlink" title="Passing messages"></a>Passing messages</h3><p>消息传递分三个步骤进行：</p><ol><li>对于每个节点，我们收集所有相邻节点的特征张量</li><li>通过聚合函数（如简单的相加）聚合收集到的信息</li><li>将聚合的信息通过更新函数传递</li></ol><p><img src="/Pictures/DL/GNN/passing.png" alt="passing"></p><p>这让人想起标准卷积：本质上，消息传递和卷积是聚合和处理元素邻居信息以更新元素值的操作。在图形中，元素是节点，在图像中，元素是像素。然而，图中相邻节点的数量可以是可变的，这与每个像素具有固定数量的相邻元素的图像不同。</p><h3 id="Learning-edge-representations"><a href="#Learning-edge-representations" class="headerlink" title="Learning edge representations"></a>Learning edge representations</h3><p>当我们想要对节点进行预测，但我们的数据集只有边缘信息时，我们在上面展示了如何使用池化将信息从边缘路由到节点，但仅限于模型的最终预测步骤。我们可以使用消息传递在 GNN 层内的节点和边之间共享信息。</p><p>我们可以采用与之前使用相邻节点信息相同的方式合并来自相邻边缘的信息，首先池化边缘信息，使用更新函数对其进行转换，然后存储它。</p><p><img src="/Pictures/DL/GNN/weavelayer.png" alt="weavelayer"></p><h3 id="Adding-global-representations"><a href="#Adding-global-representations" class="headerlink" title="Adding global representations"></a>Adding global representations</h3><p>到目前为止，我们描述的网络存在一个缺陷：即使我们多次应用消息传递，图中彼此相距较远的节点也可能永远无法有效地相互传输信息。</p><p>对于一个节点，如果我们有 k 层，信息将最多传播 k 步。</p><p>一种解决方案是让所有节点都能够相互传递信息。不幸的是，对于大型图，这很快就会变得计算成本高昂。此问题的一种解决方案是使用图 (U) 的全局表示，有时称为主节点或上下文向量，这个全局上下文向量连接到网络中的所有其他节点和边，并且可以充当它们之间传递信息的桥梁，构建整个图的表示。</p><p><img src="/Pictures/DL/GNN/Globallayer.png" alt="Globallayer"></p><p>在这个图中，所有图属性都已经学习了表示，因此我们可以在池化期间通过调节我们感兴趣的属性相对于其余属性的信息来利用它们。例如，对于一个节点，我们可以考虑来自相邻节点的信息、连接的边和全局信息。为了使新节点嵌入所有这些可能的信息源，我们可以简单地将它们连接起来。此外，我们还可以通过线性映射将它们映射到同一空间并添加它们或应用特征调制层,这可以被认为是一种特征化注意力机制。</p><h1 id="其他类型的图"><a href="#其他类型的图" class="headerlink" title="其他类型的图"></a>其他类型的图</h1><ul><li>多边图：一对节点可以共享多种类型的边，当我们想要根据节点的类型对节点之间的交互进行不同的建模时，就会发生这种情况。</li><li>嵌套图：一个节点代表一个图，也称为超节点图。嵌套图对于表示层次结构信息很有用。</li></ul><hr><p>参考：<br><a href="https://distill.pub/2021/gnn-intro/">https://distill.pub/2021/gnn-intro/</a></p>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>T5</title>
    <link href="/2024/03/19/T5/"/>
    <url>/2024/03/19/T5/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>T5 的基本思想是将每个 NLP 问题都视为“text-to-text”问题，即将文本作为输入并生成新的文本作为输出，这允许将相同的模型、目标、训练步骤和解码过程，直接应用于每个任务。</p><p>模型和框架称为 “<strong>T</strong>ext-<strong>t</strong>o-<strong>T</strong>ext <strong>T</strong>ransfer <strong>T</strong>ransformer”——T5。</p><h1 id="Embedding"><a href="#Embedding" class="headerlink" title="Embedding"></a>Embedding</h1><p>T5模型的结构基于传统Transformer模型。<br>但Transformer 使用正余弦函数的位置编码，BERT 使用的是学习到的位置嵌入，而本文使用的是相对位置嵌入。</p><p>相对位置嵌入不是对每个位置使用固定的嵌入，而是根据 self-attention 机制中的“key”和“query”之间的偏移量生成不同的学习嵌入。T5将(key和query)相对位置的数值加在attention softmax之前的logits上，每个head的有自己的position embeddings，所有的层共享一套position embeddings，每一层都计算一次，让模型对位置更加敏感。</p><h1 id="预训练过程"><a href="#预训练过程" class="headerlink" title="预训练过程"></a>预训练过程</h1><p><img src="/Pictures/DL/T5/4.png" alt="tasks"></p><h2 id="高层次方法（自监督的预训练方法）对比"><a href="#高层次方法（自监督的预训练方法）对比" class="headerlink" title="高层次方法（自监督的预训练方法）对比"></a>高层次方法（自监督的预训练方法）对比</h2><ol><li><p>语言模型式，类 GPT-2 方式，从左到右预测</p></li><li><p>BERT-style式，就是像BERT一样将一部分给破坏掉，然后还原出来，其效果最好</p></li><li><p>Deshuffling（顺序还原）式，就是将文本打乱，然后还原出来</p></li></ol><h2 id="掩码策略"><a href="#掩码策略" class="headerlink" title="掩码策略"></a>掩码策略</h2><ol><li><p>Mask法，如现在大多模型的做法，将被破坏token换成特殊符如[M]</p></li><li><p>Replace span法，可以当作是把上面 Mask 法中相邻 [M] 都合成了一个特殊符，每一小段替换一个特殊符，提高计算效率，其效果最好</p></li><li><p>Drop法，没有替换操作，直接随机丢弃一些字符</p></li></ol><h2 id="对文本进行多大程度的破坏"><a href="#对文本进行多大程度的破坏" class="headerlink" title="对文本进行多大程度的破坏"></a>对文本进行多大程度的破坏</h2><p>挑了 4 个值：10%，15%，25%，50%，最后发现 BERT 的 15%效果最好</p><h2 id="Replace-Span"><a href="#Replace-Span" class="headerlink" title="Replace Span"></a>Replace Span</h2><p>需要决定对大概多长的小段进行破坏，于是对不同长度进行探索：2，3，5，10这四个值，最后发现3效果最好。</p><h1 id="训练结论"><a href="#训练结论" class="headerlink" title="训练结论"></a>训练结论</h1><ul><li>Architectures</li></ul><p>原始的Transformer结构表现最好</p><p>encoder-decoder结构和BERT、GPT的计算量差不多</p><p>共享encoder和decoder的参数没有使效果差太多</p><ul><li>Unsupervised objectives</li></ul><p>自编码和自回归的效果差不多</p><p>推荐选择更短目标序列的目标函数，提高计算效率</p><ul><li>Datasets</li></ul><p>在领域内进行无监督训练可以提升一些任务的效果，但在一个小领域数据上重复训练会降低效果</p><p>Large、diverse的数据集效果最好</p><ul><li>Training strategies</li></ul><p>精调时更新所有参数 &gt; 更新部分参数</p><p>在多个任务上预训练之后微调 &#x3D; 无监督预训练</p><ul><li>Scaling</li></ul><p>在小模型上训练更多数据 &lt; 用少量步数训练更大的模型</p><p>从一个预训练模型上微调多个模型后集成 &lt; 分开预训练+微调后集成</p><h1 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h1><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs routeros">T5Block(<br>    (layer): ModuleList(<br>      (0): T5LayerSelfAttention(<br>        (SelfAttention): T5Attention(<br>          (q): Linear(<span class="hljs-attribute">in_features</span>=1024, <span class="hljs-attribute">out_features</span>=1024, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">False</span>)<br>          (k): Linear(<span class="hljs-attribute">in_features</span>=1024, <span class="hljs-attribute">out_features</span>=1024, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">False</span>)<br>          (v): Linear(<span class="hljs-attribute">in_features</span>=1024, <span class="hljs-attribute">out_features</span>=1024, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">False</span>)<br>          (o): Linear(<span class="hljs-attribute">in_features</span>=1024, <span class="hljs-attribute">out_features</span>=1024, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">False</span>)<br>        )<br>        (layer_norm): T5LayerNorm()<br>        (dropout): Dropout(<span class="hljs-attribute">p</span>=0.1, <span class="hljs-attribute">inplace</span>=<span class="hljs-literal">False</span>)<br>      )<br>      (1): T5LayerCrossAttention(<br>        (EncDecAttention): T5Attention(<br>          (q): Linear(<span class="hljs-attribute">in_features</span>=1024, <span class="hljs-attribute">out_features</span>=1024, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">False</span>)<br>          (k): Linear(<span class="hljs-attribute">in_features</span>=1024, <span class="hljs-attribute">out_features</span>=1024, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">False</span>)<br>          (v): Linear(<span class="hljs-attribute">in_features</span>=1024, <span class="hljs-attribute">out_features</span>=1024, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">False</span>)<br>          (o): Linear(<span class="hljs-attribute">in_features</span>=1024, <span class="hljs-attribute">out_features</span>=1024, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">False</span>)<br>        )<br>        (layer_norm): T5LayerNorm()<br>        (dropout): Dropout(<span class="hljs-attribute">p</span>=0.1, <span class="hljs-attribute">inplace</span>=<span class="hljs-literal">False</span>)<br>      )<br>      (2): T5LayerFF(<br>        (DenseReluDense): T5DenseReluDense(<br>          (wi): Linear(<span class="hljs-attribute">in_features</span>=1024, <span class="hljs-attribute">out_features</span>=4096, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">False</span>)<br>          (wo): Linear(<span class="hljs-attribute">in_features</span>=4096, <span class="hljs-attribute">out_features</span>=1024, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">False</span>)<br>          (dropout): Dropout(<span class="hljs-attribute">p</span>=0.1, <span class="hljs-attribute">inplace</span>=<span class="hljs-literal">False</span>)<br>          (relu_act): ReLU()<br>        )<br>        (layer_norm): T5LayerNorm()<br>        (dropout): Dropout(<span class="hljs-attribute">p</span>=0.1, <span class="hljs-attribute">inplace</span>=<span class="hljs-literal">False</span>)<br>      )<br>    )<br>)<br></code></pre></td></tr></table></figure><hr><p>参考：</p><ol><li><a href="https://www.jianshu.com/p/627d4643f7a7">https://www.jianshu.com/p/627d4643f7a7</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>CNN——卷积神经网络</title>
    <link href="/2024/03/18/CNN/"/>
    <url>/2024/03/18/CNN/</url>
    
    <content type="html"><![CDATA[<h1 id="卷积神经网络-CNN-概述"><a href="#卷积神经网络-CNN-概述" class="headerlink" title="卷积神经网络(CNN)概述"></a>卷积神经网络(CNN)概述</h1><p>整体架构分为：</p><ol><li>输入层</li><li>卷积层</li><li>池化层</li><li>全连接层</li><li>激活函数</li></ol><p>卷积神经网络由一个或多个卷积层、池化层以及全连接层等组成。与其他深度学习结构相比，卷积神经网络在图像等方面能够给出更好的结果。</p><p><img src="/Pictures/DL/CNN/plot01.svg" alt="img"></p><h2 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h2><h3 id="卷积运算"><a href="#卷积运算" class="headerlink" title="卷积运算"></a>卷积运算</h3><p>若一个 6*6的单通道图像与一个 3*3的卷积核进行卷积运算，那么从图像的左上角开始选取3*3的区域，将该区域的矩阵与卷积核的对应位置的元素相乘求和得到的结果便为输出矩阵的左上角元素。</p><p>$$\begin{bmatrix}<br>  10&amp;  10&amp;  10&amp;  0&amp;  0&amp; 0\\<br>  10&amp;  10&amp;  10&amp;  0&amp;  0&amp; 0\\<br>  10&amp;  10&amp;  10&amp;  0&amp;  0&amp; 0 \\<br>  10&amp;  10&amp;  10&amp;  0&amp;  0&amp; 0\\<br>  10&amp;  10&amp;  10&amp;  0&amp;  0&amp; 0 \\<br>  10&amp;  10&amp;  10&amp;  0&amp;  0&amp; 0<br>\end{bmatrix}*\begin{bmatrix}<br>  1&amp; 0 &amp; -1\\<br>  1&amp; 0 &amp; -1\\<br>  1&amp; 0 &amp; -1<br>\end{bmatrix}&#x3D;\begin{bmatrix}<br>  0&amp;  30&amp;  30&amp; 0\\<br>  0&amp;  30&amp;  30&amp; 0\\<br>  0&amp;  30&amp;  30&amp; 0\\<br>  0&amp;  30&amp;  30&amp; 0<br>\end{bmatrix}$$</p><p>卷积运算的目的是提取输入的不同特征，某些卷积层可能只能提取一些低级的特征，更多层的网络能从低级特征中迭代提取更复杂的特征。</p><h3 id="卷积层的构成"><a href="#卷积层的构成" class="headerlink" title="卷积层的构成"></a>卷积层的构成</h3><p><strong>参数：</strong></p><ul><li><p>size：卷积核的大小，选择一般有 1*1, 3*3, 5*5</p><blockquote><p>对于卷积核大小，一般采取奇数，这样做的目的是便于指出中心。</p></blockquote></li><li><p>padding：一般为零填充，有<em>Valid和Same</em>两种方式。</p><p>  对于padding的解释：</p><ul><li><p>零填充：在图片像素的最外层加上若干层0值，若加1层，记为 <em>p&#x3D;1</em><br>  增加0是因为0在权重乘积运算中对最终结果不造成影响，也就避免了图片增加了额外的干扰信息。</p></li><li><p>Valid：不填充，保持原状，结果变小</p></li><li><p>Same：输出的大小与原图大小一致</p></li></ul></li><li><p>stride：步长，通常默认为1</p></li><li><p>bias：偏置</p></li></ul><p>对于每个卷积核，都会有一个偏置参数 $b$。</p><p>在卷积操作的计算中，偏置会与卷积核的加权和相加，并且会在整个输出图像上共享。具体地，输出图像中的每个像素值 $y$ 可以计算如下：</p><p>$$y &#x3D; \sum_{i&#x3D;1}^{M} \sum_{j&#x3D;1}^{N} (w_{i,j} \cdot x_{i,j}) + b $$</p><p>其中 $w_{i,j}$ 是卷积核的权重，$x_{i,j}$ 是输入数据的对应像素值，$b$ 是偏置参数。</p><p><strong>多通道卷积：</strong></p><p>当输入有多个通道（channel）时（例如图片可以有RGB三通道），卷积核需要拥有相同的channel数，每个卷积核channel与输入层对应的channel进行卷积，将每个channel的卷积结果按位相加得到最终的 Feature Map。</p><p><strong>多卷积核卷积：</strong></p><p>当有多个卷积核时，可以学习到多种不同的特征，对应产生包含多个channel的 Feature Map，例如当拥有两个kernel时，输出结果会有两个channel。</p><p>得到的特征图大小不变，数量变多。</p><p><strong>这里的多少个卷积核也可以理解为多少个神经元。</strong></p><p><strong>例子：</strong></p><p>假设我们有一张 $200\times 200$ 的图片，10个kernel，size&#x3D;3*3，channel&#x3D;3(计算RGB图片)，并且只有一层卷积，步长为1，那么参数的计算过程为：</p><p>对于每个kernel，有 $3\times 3\times 3+1$ 个参数</p><p>所以总共有 $28\times 10&#x3D;280$ 个参数。</p><p>零填充的层数 $P&#x3D;\frac{(N-1)\times s+F-N}{2}&#x3D;\frac{199+3-200}{2}&#x3D;1$</p><p>$N$ 为图片大小， $s$ 为stride， $F$ 为卷积核大小</p><h2 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h2><p>池化层主要对卷积层学习到的特征图进行亚采样（subsampling），主要有两种：</p><ol><li>最大池化：Max Pooling，取窗口内的最大值作为输出</li><li>平均池化：Avg Pooling，取窗口内所有值的均值作为输出</li></ol><p>意义在于：</p><ul><li>降低了后续网络层的输入维度，缩减模型大小，提高计算速度</li><li>提高了Feature Map的鲁棒性，防止过拟合</li></ul><p>一般来说池化操作即为选取图片的一个固定大小的区域（窗口），在该区域中得到一个代表这个区域的数值，并总和输出结果。</p><p>窗口设置：一般大小为 $2\times 2$, $stride&#x3D;2$ 。</p><p>在处理多通道输入数据时，池化层对每个输入通道分别池化，而不是像卷积层那样将各个通道的输入相加。这意味着池化层的输出和输入的通道数是相等。</p><h2 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h2><p>全连接层的目的是将卷积和池化层提取的特征进行整合，并输出到最终的输出层，以进行分类、回归或其他任务。</p><p>卷积层＋激活层＋池化层可以看作是CNN的特征学习&#x2F;特征提取层，而学习到的特征最终运用于模型任务，一般来说分为分类或回归。</p><ul><li><p>先对所有 Feature Map 进行扁平化（flatten，即reshape成 $1\times N$ 的向量）</p></li><li><p>再接一个或多个全连接层，进行模型学习</p></li></ul><p><img src="/Pictures/DL/CNN/plot02.png" alt="img"></p><h1 id="构建CNN实现图片分类"><a href="#构建CNN实现图片分类" class="headerlink" title="构建CNN实现图片分类"></a>构建CNN实现图片分类</h1><h2 id="分类器任务和数据介绍"><a href="#分类器任务和数据介绍" class="headerlink" title="分类器任务和数据介绍"></a>分类器任务和数据介绍</h2><ul><li>构造一个将不同图像进行分类的神经网络分类器，对输入的图片进行判别并完成分类</li><li>采用 <strong>CIFAR10</strong> 数据集作为原始图片数据</li></ul><blockquote><p>CIFAR10数据集介绍：数据集中每张图片的尺寸是 3*32*32 ，代表彩色三通道。<br>CIFAR10数据集总共有10种不同的分类，分别是 <em>“airplane”,”automobile”,”bird”,”cat”,”deer”,”dog”,”frog”,”horse”,”ship”,”truck”</em></p></blockquote><p><img src="/Pictures/DL/CNN/plot03.png" alt="img"></p><h2 id="训练分类器的步骤"><a href="#训练分类器的步骤" class="headerlink" title="训练分类器的步骤"></a>训练分类器的步骤</h2><ol><li>使用torchvision下载CIFAR10数据集</li><li>定义卷积神经网络</li><li>定义损失函数</li><li>在训练集上训练模型</li><li>在测试集上测试模型</li></ol><h2 id="构建神经网络的基本步骤"><a href="#构建神经网络的基本步骤" class="headerlink" title="构建神经网络的基本步骤"></a>构建神经网络的基本步骤</h2><ul><li>使用PyTorch构建神经网络，主要的工具都在<strong>torch.nn</strong>包中</li><li>nn依赖于autograd来定义模型，并对其自动求导</li></ul><p>主要步骤：</p><ol><li>定义一个拥有可学习参数的神经网络</li><li>遍历训练数据集</li><li>处理输入数据使其流向神经网络</li><li>计算损失值</li><li>将网络参数的梯度进行反向传递</li><li>以一定的规则更新网络的权重</li></ol><h2 id="下载数据集"><a href="#下载数据集" class="headerlink" title="下载数据集"></a>下载数据集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">import</span> torchvision.transforms <span class="hljs-keyword">as</span> transforms<br><br><span class="hljs-comment"># 下载数据集并对图片进行调整，因为torchvision数据集的输出是PILImage格式，数据域在[0, 1]。</span><br><span class="hljs-comment"># 我们将其转换为标准数据域[-1, 1]的张量格式</span><br>transform = transforms.Compose(<br>    [transforms.ToTensor(),<br>     transforms.Normalize((<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>), (<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>))])<br>trainset = torchvision.datasets.CIFAR10(root=<span class="hljs-string">&#x27;./data&#x27;</span>, train=<span class="hljs-literal">True</span>, download=<span class="hljs-literal">True</span>, transform=transform)<br><br>trainloader = torch.utils.data.DataLoader(trainset, batch_size=<span class="hljs-number">4</span>, shuffle=<span class="hljs-literal">True</span>, num_workers=<span class="hljs-number">2</span>)<br><br>testset = torchvision.datasets.CIFAR10(root=<span class="hljs-string">&#x27;./data&#x27;</span>, train=<span class="hljs-literal">False</span>, download=<span class="hljs-literal">True</span>, transform=transform)<br><br>testloader = torch.utils.data.DataLoader(testset, batch_size=<span class="hljs-number">4</span>, shuffle=<span class="hljs-literal">False</span>, num_workers=<span class="hljs-number">2</span>)<br><br>classes = (<span class="hljs-string">&#x27;plane&#x27;</span>, <span class="hljs-string">&#x27;automobile&#x27;</span>, <span class="hljs-string">&#x27;bird&#x27;</span>, <span class="hljs-string">&#x27;cat&#x27;</span>, <span class="hljs-string">&#x27;deer&#x27;</span>, <span class="hljs-string">&#x27;dog&#x27;</span>, <span class="hljs-string">&#x27;frog&#x27;</span>, <span class="hljs-string">&#x27;horse&#x27;</span>, <span class="hljs-string">&#x27;ship&#x27;</span>, <span class="hljs-string">&#x27;truck&#x27;</span>)<br></code></pre></td></tr></table></figure><p>对这段代码的解释：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">transform = transforms.Compose(<br>    [transforms.ToTensor(),<br>     transforms.Normalize((<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>), (<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>))])<br></code></pre></td></tr></table></figure><p>创建一个数据转换管道，使用 <em>transforms.Compose()。</em></p><p>它按顺序应用两个转换到输入图像：</p><ul><li>transforms.ToTensor(): 将PIL图像或numpy.ndarray转换为PyTorch张量。图像数据被转换为张量并标准化到范围[0, 1]。</li><li>transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)): 使用均值和标准差对张量图像进行归一化。这将使用每个通道（R、G、B）的均值和标准差值（0.5、0.5、0.5）对图像张量进行归一化。归一化公式为 $\frac{(input - mean)}{std}$</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">trainset = torchvision.datasets.CIFAR10(root=<span class="hljs-string">&#x27;./data&#x27;</span>, train=<span class="hljs-literal">True</span>, download=<span class="hljs-literal">True</span>, transform=transform)<br></code></pre></td></tr></table></figure><p>使用torchvision中的CIFAR-10数据集创建一个训练数据集对象（trainset）。它指定了以下参数：</p><ul><li>root&#x3D;’.&#x2F;data’: 指定数据集将被存储的目录。</li><li>train&#x3D;True: 表示这是训练集。</li><li>download&#x3D;True: 如果数据集尚未下载，则下载数据集。</li><li>transform&#x3D;transform: 对数据集应用前面定义的转换。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">trainloader = torch.utils.data.DataLoader(trainset, batch_size=<span class="hljs-number">4</span>, shuffle=<span class="hljs-literal">True</span>, num_workers=<span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure><p>创建一个用于训练数据集的数据加载器（trainloader）。它指定了以下参数：</p><ul><li>trainset: 要加载的数据集对象。</li><li>batch_size&#x3D;4: 将批次大小设置为4，这意味着在训练期间每次加载4张图像。</li><li>shuffle&#x3D;True: 在每个epoch之前对数据进行洗牌，以引入随机性并避免模型学习数据的顺序。</li><li>num_workers&#x3D;2: 用于数据加载的<strong>子进程数</strong>。在这里，将使用2个子进程加载数据。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">classes = (<span class="hljs-string">&#x27;plane&#x27;</span>, <span class="hljs-string">&#x27;automobile&#x27;</span>, <span class="hljs-string">&#x27;bird&#x27;</span>, <span class="hljs-string">&#x27;cat&#x27;</span>, <span class="hljs-string">&#x27;deer&#x27;</span>, <span class="hljs-string">&#x27;dog&#x27;</span>, <span class="hljs-string">&#x27;frog&#x27;</span>, <span class="hljs-string">&#x27;horse&#x27;</span>, <span class="hljs-string">&#x27;ship&#x27;</span>, <span class="hljs-string">&#x27;truck&#x27;</span>)<br></code></pre></td></tr></table></figure><p>此行定义了与CIFAR-10数据集中的10个类别相对应的类标签。稍后将使用这些标签进行预测和评估。</p><h2 id="定义卷积神经网络"><a href="#定义卷积神经网络" class="headerlink" title="定义卷积神经网络"></a>定义卷积神经网络</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><span class="hljs-comment"># 定义卷积神经网络</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Net</span>(nn.Module):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(Net, self).__init__()<br>        self.conv1 = nn.Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">6</span>, <span class="hljs-number">5</span>)<br>        self.pool = nn.MaxPool2d(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)<br>        self.conv2 = nn.Conv2d(<span class="hljs-number">6</span>, <span class="hljs-number">16</span>, <span class="hljs-number">5</span>)<br>        self.fc1 = nn.Linear(<span class="hljs-number">16</span>*<span class="hljs-number">5</span>*<span class="hljs-number">5</span>, <span class="hljs-number">120</span>)<br>        self.fc2 = nn.Linear(<span class="hljs-number">120</span>, <span class="hljs-number">84</span>)<br>        self.fc3 = nn.Linear(<span class="hljs-number">84</span>, <span class="hljs-number">10</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.pool(F.relu(self.conv1(x)))<br>        x = self.pool(F.relu(self.conv2(x)))<br>        x = self.view(-<span class="hljs-number">1</span>, <span class="hljs-number">16</span>*<span class="hljs-number">5</span>*<span class="hljs-number">5</span>)<br>        x = F.relu(self.fc1(x))<br>        x = F.relu(self.fc2(x))<br>        x = self.fc3(x)<br>        <span class="hljs-keyword">return</span> x<br></code></pre></td></tr></table></figure><h3 id="一些注释"><a href="#一些注释" class="headerlink" title="一些注释"></a>一些注释</h3><p>对于 <strong>init</strong> 函数：</p><ul><li>第一个卷积层 self.conv1 输入通道数为3（因为输入图像有3个通道，通常为RGB），输出通道数为6，卷积核大小为5x5。</li><li>第一个最大池化层 self.pool 使用2x2的池化窗口进行池化操作，步长为2。</li><li>第二个卷积层 self.conv2 输入通道数为6（即第一个卷积层的输出通道数），输出通道数为16，卷积核大小为5x5。</li><li>第一个全连接层 self.fc1 的输入大小为16x5x5，输出大小为120。</li><li>第二个全连接层 self.fc2 的输入大小为120，输出大小为84。</li><li>第三个全连接层 self.fc3 的输入大小为84，输出大小为10（因为通常在分类问题中，输出层的大小对应着类别的数量）。</li></ul><p>对于 forward 函数：</p><ul><li>首先将输入张量 x 传递给第一个卷积层 self.conv1，然后应用 ReLU 激活函数，并通过最大池化层 self.pool 进行池化操作。</li><li>接着将经过第一个池化层处理后的数据传递给第二个卷积层 self.conv2，然后再次应用 ReLU 激活函数，并再次通过最大池化层进行池化操作。</li><li>将经过两个卷积层和池化层处理后的数据 x 展平为一维张量。</li><li>将展平后的数据传递给第一个全连接层 self.fc1，并应用 ReLU 激活函数。</li><li>将第一个全连接层的输出传递给第二个全连接层 self.fc2，再次应用 ReLU 激活函数。</li><li>最后将第二个全连接层的输出传递给输出层</li></ul><h2 id="定义损失函数"><a href="#定义损失函数" class="headerlink" title="定义损失函数"></a>定义损失函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 定义损失函数</span><br>criterion = nn.CrossEntropyLoss()<br>optimizer = optim.SGD(net.parameters(), lr=<span class="hljs-number">0.001</span>, momentum=<span class="hljs-number">0.9</span>)<br></code></pre></td></tr></table></figure><p>采用交叉熵损失函数和梯度下降算法。</p><h2 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h2><ul><li>采用梯度下降的优化算法，都需要很多个轮次的迭代训练</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 在训练集上训练模型</span><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>):    <span class="hljs-comment"># 遍历两遍数据集</span><br>        running_loss = <span class="hljs-number">0.0</span><br>        <span class="hljs-keyword">for</span> i, data <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(trainloader, <span class="hljs-number">0</span>):<br>            <span class="hljs-comment"># data中包含输入图像张量inputs，标签张量labels</span><br>            inputs, labels = data<br>            <span class="hljs-comment"># 梯度归零</span><br>            optimizer.zero_grad()<br>            <span class="hljs-comment"># 输入图像张量进网络，得到输出张量outputs</span><br>            outputs = net(inputs)<br>            <span class="hljs-comment"># 利用网络的输出output和标签labels计算损失值</span><br>            loss = criterion(outputs, labels)<br>            <span class="hljs-comment"># 反向传播+参数更新</span><br>            loss.backward()<br>            optimizer.step()<br>            <span class="hljs-comment"># 打印轮次和损失值</span><br>            running_loss += loss.item()<br>            <span class="hljs-keyword">if</span> (i + <span class="hljs-number">1</span>) % <span class="hljs-number">2000</span> == <span class="hljs-number">0</span>:<br>                <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;[%d, %5d] loss: %.3f&#x27;</span> % (epoch + <span class="hljs-number">1</span>, i + <span class="hljs-number">1</span>, running_loss / <span class="hljs-number">2000</span>))<br>                running_loss = <span class="hljs-number">0.0</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Finished Training&#x27;</span>)<br>    <span class="hljs-comment"># 保存模型</span><br>    PATH = <span class="hljs-string">&#x27;./cifar10_net.pth&#x27;</span><br>    torch.save(net.state_dict(), PATH)<br></code></pre></td></tr></table></figure><p>训练结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">[1,  2000] loss: 2.235</span><br><span class="hljs-string">[1,  4000] loss: 1.860</span><br><span class="hljs-string">[1,  6000] loss: 1.651</span><br><span class="hljs-string">[1,  8000] loss: 1.573</span><br><span class="hljs-string">[1, 10000] loss: 1.513</span><br><span class="hljs-string">[1, 12000] loss: 1.477</span><br><span class="hljs-string">[2,  2000] loss: 1.395</span><br><span class="hljs-string">[2,  4000] loss: 1.369</span><br><span class="hljs-string">[2,  6000] loss: 1.333</span><br><span class="hljs-string">[2,  8000] loss: 1.325</span><br><span class="hljs-string">[2, 10000] loss: 1.311</span><br><span class="hljs-string">[2, 12000] loss: 1.295</span><br><span class="hljs-string">Finished Training</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure><h2 id="在测试集上测试模型"><a href="#在测试集上测试模型" class="headerlink" title="在测试集上测试模型"></a>在测试集上测试模型</h2><h3 id="第一步，展示测试集中的若干图片"><a href="#第一步，展示测试集中的若干图片" class="headerlink" title="第一步，展示测试集中的若干图片"></a>第一步，展示测试集中的若干图片</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 展示图片</span><br>dataiter = <span class="hljs-built_in">iter</span>(testloader)<br>images, labels = dataiter.<span class="hljs-built_in">next</span>()<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">imshow</span>(<span class="hljs-params">img</span>):<br>    img = img / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span><br>    npimg = img.numpy()<br>    plt.imshow(np.transpose(npimg, (<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>)))<br>    plt.show()<br><br><span class="hljs-comment"># 打印原始图片</span><br>imshow(torchvision.utils.make_grid(images))<br><span class="hljs-comment"># 打印真实标签</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;GroundTruth: &#x27;</span>, <span class="hljs-string">&#x27; &#x27;</span>.join(<span class="hljs-string">&#x27;%5s&#x27;</span> % classes[labels[j]] <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>)))<br></code></pre></td></tr></table></figure><p>代码解读：</p><ul><li><p>dataiter &#x3D; iter(testloader): 创建了一个迭代器 dataiter，用于迭代测试数据加载器 testloader，以便逐批获取测试数据。</p></li><li><p>images, labels &#x3D; next(dataiter): 使用 next() 函数从 dataiter 中获取下一批测试数据，其中 images 是一个包含了一批图像的张量，labels 是这批图像对应的真实标签。</p></li><li><p>def imshow(img): 定义了一个函数 imshow，用于展示图像。</p></li><li><p>img &#x3D; img &#x2F; 2 + 0.5: 对输入的图像数据进行处理，将其从标准化后的张量格式转换回原始图像的像素值范围，即从 [-1, 1] 转换为 [0, 1]。</p></li><li><p>npimg &#x3D; img.numpy(): 将张量类型的图像数据转换为 NumPy 数组，因为 matplotlib 库接受的是 NumPy 数组格式的图像数据。</p></li><li><p>plt.imshow(np.transpose(npimg, (1, 2, 0))): 使用 imshow 函数展示图像。</p></li></ul><p>(1, 2, 0): 这是一个元组，指定了数组的维度顺序。在这个元组中，每个数字表示了原始数组的一个维度在新数组中的位置。因此，(1, 2, 0) 意味着将原始数组的第 1 维移动到新数组的第 0 个位置，第 2 维移动到新数组的第 1 个位置，原始数组的第 0 维移动到新数组的第 2 个位置。</p><p>在图像处理中，一般图像数组的维度顺序是 (通道数, 高度, 宽度)，即 (channels, height, width)，其中 channels 表示图像的通道数，比如 RGB 图像中通常是 3。而 imshow 函数默认会将最后一个维度视为通道维度，所以需要用 np.transpose() 来调整数组的维度顺序以匹配 imshow 的预期输入格式，即 (height, width, channels)。</p><ul><li><p>plt.show(): 显示图像。</p></li><li><p>imshow(torchvision.utils.make_grid(images)): 调用 imshow 函数，将一批图像组合成一个网格并展示出来。</p></li><li><p>print(‘GroundTruth: ‘, ‘ ‘.join(‘%5s’ % classes[labels[j]] for j in range(4))): 打印出这批图像对应的真实标签。使用了列表推导式，将每个图像的真实标签转换为对应的类别名称，并使用空格连接起来，最后打印出来。</p></li></ul><p>输出结果：<br><img src="/Pictures/DL/CNN/plot04.png" alt="img"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">GroundTruth:    cat  ship  ship plane<br></code></pre></td></tr></table></figure><h3 id="第二步，加载模型对测试图片进行预测"><a href="#第二步，加载模型对测试图片进行预测" class="headerlink" title="第二步，加载模型对测试图片进行预测"></a>第二步，加载模型对测试图片进行预测</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">net = Net()<br><span class="hljs-comment"># 加载保存的状态字典</span><br>net.load_state_dict(torch.load(PATH))<br><span class="hljs-comment"># 进行预测</span><br>outputs = net(images)<br><span class="hljs-comment"># 采用计算出概率最大的为类别</span><br>_, predicted = torch.<span class="hljs-built_in">max</span>(outputs, <span class="hljs-number">1</span>)<br><span class="hljs-comment"># 打印结果</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Prediced: &#x27;</span>, <span class="hljs-string">&#x27; &#x27;</span>.join(<span class="hljs-string">&#x27;%5s&#x27;</span> % classes[predicted[j]] <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>)))<br></code></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">GroundTruth:    cat  ship  ship plane<br>Prediced:    cat automobile plane plane<br></code></pre></td></tr></table></figure><p>稍有误差。。。加大epoch！</p><p>全部测试集结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 跑一遍全部测试集</span><br>correct = <span class="hljs-number">0</span><br>total = <span class="hljs-number">0</span><br><span class="hljs-keyword">with</span> torch.no_grad():<br>    <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> testloader:<br>        images, labels = data<br>        outputs = net(images)<br>        _, predicted = torch.<span class="hljs-built_in">max</span>(outputs.data, <span class="hljs-number">1</span>)<br>        total += labels.size(<span class="hljs-number">0</span>)<br>        correct += (predicted == labels).<span class="hljs-built_in">sum</span>().item()<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Accuracy: %d %%&#x27;</span> % (<span class="hljs-number">100</span> * correct / total))<br></code></pre></td></tr></table></figure><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Accuracy</span>: <span class="hljs-number">54</span> %<br></code></pre></td></tr></table></figure><p>准确率为54%，说明模型初步具备分类能力，还有较大提升空间。</p><p>我们可以计算模型在哪些类别上表现更好，在哪些类别上表现更差，也可以分类别进行准确率计算，此处不再演示。</p><p>把学习率由 1e-3 修改为 1e-4, 并网络参数量增加如下代码所示:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ImageClassification</span>(nn.Module):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(ImageClassification, self).__init__()<br>        self.conv1 = nn.Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">32</span>, stride=<span class="hljs-number">1</span>, kernel_size=<span class="hljs-number">3</span>)<br>        self.pool1 = nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>)<br>        self.conv2 = nn.Conv2d(<span class="hljs-number">32</span>, <span class="hljs-number">128</span>, stride=<span class="hljs-number">1</span>, kernel_size=<span class="hljs-number">3</span>)<br>        self.pool2 = nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>)<br>        self.linear1 = nn.Linear(<span class="hljs-number">128</span> * <span class="hljs-number">6</span> * <span class="hljs-number">6</span>, <span class="hljs-number">2048</span>)<br>        self.linear2 = nn.Linear(<span class="hljs-number">2048</span>, <span class="hljs-number">2048</span>)<br>        self.out = nn.Linear(<span class="hljs-number">2048</span>, <span class="hljs-number">10</span>)<br><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = F.relu(self.conv1(x))<br>        x = self.pool1(x)<br>        x = F.relu(self.conv2(x))<br>        x = self.pool2(x)<br>        <span class="hljs-comment"># 由于最后一个批次可能不够 32，所以需要根据批次数量来 flatten</span><br>        x = x.reshape(x.size(<span class="hljs-number">0</span>), -<span class="hljs-number">1</span>)<br>        x = F.relu(self.linear1(x))<br>        x = F.dropout(x, p=<span class="hljs-number">0.5</span>)<br>        x = F.relu(self.linear2(x))<br>        x = F.dropout(x, p=<span class="hljs-number">0.5</span>)<br>        <span class="hljs-keyword">return</span> self.out(x)<br></code></pre></td></tr></table></figure><p>经过训练，模型在测试集的准确率由 0.57，提升到了 0.93。</p>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>BERT</title>
    <link href="/2024/03/18/BERT/"/>
    <url>/2024/03/18/BERT/</url>
    
    <content type="html"><![CDATA[<h1 id="BERT简述"><a href="#BERT简述" class="headerlink" title="BERT简述"></a>BERT简述</h1><p>BERT的全程为 <em>Bidirectional Encoder Representation from Transformers</em> ，是一个基于 Transformer 模型的预训练语言表征模型。</p><p>BERT强调不再采用传统的单向语言模型或者把两个单向语言模型进行浅层拼接的方法进行预训练，而是采用新的 <em>masked language model(MLM)</em> 以生成深度的双向语言表征。</p><h1 id="BERT的结构"><a href="#BERT的结构" class="headerlink" title="BERT的结构"></a>BERT的结构</h1><p>以往的预训练模型的结构会受到单向语言模型（从左到右或者从右到左）的限制，因而也限制了模型的表征能力，使其只能获取单方向的上下文信息。</p><p>而BERT利用MLM进行预训练并且采用深层的双向Transformer组件来构建整个模型，最终能够生成融合左右上下文信息的深层双向语言表征。</p><p><img src="/Pictures/DL/BERT/BERT.png" alt="BERT"></p><h2 id="输入结构"><a href="#输入结构" class="headerlink" title="输入结构"></a>输入结构</h2><p><img src="/Pictures/DL/BERT/input.png" alt="input"></p><p>BERT的输入为每一个token对应的表征（图中的粉红色块就是token，黄色块就是token对应的表征），并且单词字典是采用 <strong>WordPiece</strong> 算法来进行构建的。</p><p>为了完成具体的分类任务，除了单词的token之外，作者还在输入的每一个序列开头都插入特定的分类token（[CLS]），该分类token对应的最后一个Transformer层输出被用来起到聚集整个序列表征信息的作用。</p><p>分辨哪个范围是属于句子A，哪个范围是属于句子B呢？BERT采用了两种方法去解决：</p><ol><li><p>在序列tokens中把分割token（[SEP]）插入到每个句子后，以分开不同的句子tokens。</p></li><li><p>为每一个token表征都添加一个可学习的分割embedding来指示其属于句子A还是句子B。</p></li></ol><div class="note note-info">            <p>[CLS] token：<br>CLS token 是 “Classification” token 的缩写，它位于每个输入句子的开头。这个 token 的主要作用是为句子的分类任务提供一个整体的句子表示。在训练过程中，通常会将这个 token 的输出作为整个句子的表示，然后将它输入到分类器中进行分类。</p><p>[SEP] token：<br>SEP token 是 “Separation” token 的缩写，它用于分隔两个句子或者文本片段。在输入句子或文本片段之间需要插入一个 SEP token，以帮助模型更好地理解它们之间的关系。这对于BERT的双句子任务（如句对分类、问答等）是非常重要的。</p>          </div><p>对于每个Token对应的表征，我们将其分为三部分，分别是对应的Token，分割和Position Embeddings</p><p><img src="/Pictures/DL/BERT/features.png" alt="features"></p><p>此处的position embedding和Transformer模型中的一致，由公式给出：</p><p>$$ PE_{(pos,2i)} &#x3D; sin(pos &#x2F; 10000^{2i &#x2F; d})$$<br>$$ PE_{(pos,2i+1)} &#x3D; cos(pos &#x2F; 10000^{2i &#x2F; d})$$</p><p>在BERT模型中，位置嵌入是通过以下步骤生成的：</p><ol><li><p>位置编码矩阵生成<br>首先，BERT模型学习一个位置编码矩阵，其维度为 $\text{max_seq_length} \times \text{embedding_size}$ ，其中 $\text{max_seq_length}$ 是输入序列的最大长度， $\text{embedding_size}$ 是词嵌入的维度。</p></li><li><p>位置编码计算<br>对于输入序列中的每个位置 $pos$ 和每个维度 $i$，位置嵌入 $PE(pos, i)$ 计算如下：<br>$$<br>  [<br>  PE(pos, 2i) &#x3D; \sin\left(\frac{pos}{10000^{2i &#x2F; d_{\text{model}}}}\right)<br>  ]<br>  [<br>  PE(pos, 2i+1) &#x3D; \cos\left(\frac{pos}{10000^{2i &#x2F; d_{\text{model}}}}\right)<br>  ]<br>$$<br>  其中，$pos$ 是位置，$i$ 是维度， $d_{\text{model}}$ 是词嵌入的维度。</p></li><li><p>位置嵌入向量获取<br>对于输入序列中的每个词（或子词），通过位置编码矩阵中对应位置的值来获取位置嵌入向量。</p></li><li><p>位置嵌入与词嵌入相加<br>将位置嵌入向量与词嵌入向量相加，得到最终的输入向量。</p></li></ol><h2 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h2><p>从图中我们可以看出，BERT采用双向Encoder进行连接，舍弃了Decoder部分。</p><p><img src="/Pictures/DL/BERT/encoder.png" alt="encoder"></p><p>最后呈现的输出为：</p><p><img src="/Pictures/DL/BERT/output.png" alt="output"></p><p>$C$ 为分类token（[CLS]）对应最后一个Transformer的输出， $T_{i}$ 则代表其他token对应最后一个Transformer的输出。对于一些token级别的任务（如，序列标注和问答任务），就 $T_{i}$ 把输入到额外的输出层中进行预测。对于一些句子级别的任务（如，自然语言推断和情感分类任务），就把 $C$ 输入到额外的输出层中，这里也就解释了为什么要在每一个token序列前都要插入特定的分类token。</p><h1 id="BERT的预训练任务"><a href="#BERT的预训练任务" class="headerlink" title="BERT的预训练任务"></a>BERT的预训练任务</h1><p>BERT构建了两个预训练任务，分别是 <em>Masked Language Model</em> 和 <em>Next Sentence Prediction</em></p><h2 id="Masked-Language-Model-MLM"><a href="#Masked-Language-Model-MLM" class="headerlink" title="Masked Language Model(MLM)"></a>Masked Language Model(MLM)</h2><p>MLM是BERT能够不受单向语言模型所限制的原因。简单来说就是以15%的概率用mask token （[MASK]）随机地对每一个训练序列中的token进行替换，然后预测出[MASK]位置原有的单词。然而，由于[MASK]并不会出现在下游任务的微调（fine-tuning）阶段，因此预训练阶段和微调阶段之间产生了不匹配（这里很好解释，就是预训练的目标会令产生的语言表征对[MASK]敏感，但是却对其他token不敏感）。因此BERT采用了以下策略来解决这个问题：</p><p>首先在每一个训练序列中以15%的概率随机地选中某个token位置用于预测，假如是第i个token被选中，则会被替换成以下三个token之一</p><ol><li><p>80%的时候是[MASK]。如，my dog is hairy——&gt;my dog is [MASK]</p></li><li><p>10%的时候是随机的其他token。如，my dog is hairy——&gt;my dog is apple</p></li><li><p>10%的时候是原来的token（保持不变）。如，my dog is hairy——&gt;my dog is hairy</p></li></ol><p>再用该位置对应的 $T_{i}$ 去预测出原来的token（输入到全连接，然后用softmax输出每个token的概率，最后用交叉熵计算loss）。</p><h2 id="Next-Sentence-Prediction"><a href="#Next-Sentence-Prediction" class="headerlink" title="Next Sentence Prediction"></a>Next Sentence Prediction</h2><p>在NLP中有一类重要的问题比如QA(Quention-Answer), NLI(Natural Language Inference), 需要模型能够很好的理解两个句子之间的关系, 从而需要在模型的训练中引入对应的任务. 在BERT中引入的就是Next Sentence Prediction任务。采用的方式是输入句子对(A, B), 模型来预测句子B是不是句子A的真实的下一句话。</p><p>所有参与任务训练的语句都被选中作为句子A。</p><ol><li><p>其中50%的B是原始文本中真实跟随A的下一句话. (标记为IsNext, 代表正样本)</p></li><li><p>其中50%的B是原始文本中随机抽取的一句话. (标记为NotNext, 代表负样本)</p></li></ol><p>在任务二中, BERT模型可以在测试集上取得97%-98%的准确率。</p><h1 id="补充：NLP三大Subword模型"><a href="#补充：NLP三大Subword模型" class="headerlink" title="补充：NLP三大Subword模型"></a>补充：NLP三大Subword模型</h1><p>在NLP任务中，神经网络模型的训练和预测都需要借助词表来对句子进行表示。传统构造词表的方法，是先对各个句子进行分词，然后再统计并选出频数最高的前N个词组成词表。<br>这种方法构造的词表存在着如下的问题：</p><ul><li><p>实际应用中，模型预测的词汇是开放的，对于未在词表中出现的词(Out Of Vocabulary, OOV)，模型将无法处理及生成</p></li><li><p>词表中的低频词&#x2F;稀疏词在模型训练过程中无法得到充分训练，进而模型不能充分理解这些词的语义</p></li><li><p>一个单词因为不同的形态会产生不同的词，如由”look”衍生出的”looks”, “looking”, “looked”，显然这些词具有相近的意思，但是在词表中这些词会被当作不同的词处理，一方面增加了训练冗余，另一方面也造成了大词汇量问题</p></li></ul><h2 id="Byte-Pair-Encoding-BPE"><a href="#Byte-Pair-Encoding-BPE" class="headerlink" title="Byte Pair Encoding (BPE)"></a>Byte Pair Encoding (BPE)</h2><p>BPE获得Subword的步骤如下：</p><ol><li>准备足够大的训练语料，并确定期望的Subword词表大小；</li><li>将单词拆分为成最小单元。比如英文中26个字母加上各种符号，这些作为初始词表；</li><li>在语料上统计单词内相邻单元对的频数，选取频数最高的单元对合并成新的Subword单元；</li><li>重复第3步直到达到第1步设定的Subword词表大小或下一个最高频数为1.</li></ol><p>下面以例子说明。假设我们有这样一个语料：{‘low’:5,’lower’:2,’newest’:6,’widest’:3}<br>其中数字代表对应单词的出现频数。</p><ol><li>拆分单词成最小单元，并初始化词表。这里，最小单元为字符，因而，可得到</li></ol><p><img src="/Pictures/DL/BERT/step1.png" alt="step1"></p><p>需要注意的是，在将单词拆分成最小单元时，要在单词序列后加上“</w>”(具体实现上可以使用其它符号)来表示中止符。在子词解码时，中止符可以区分单词边界。</p><ol start="2"><li>在语料上统计相邻单元的频数。这里，最高频连续子词对”e”和”s”出现了6+3&#x3D;9次，将其合并成”es”，有</li></ol><p><img src="/Pictures/DL/BERT/step2.png" alt="step2"></p><p>由于语料中不存在’s’子词了，因此将其从词表中删除。同时加入新的子词’es’。一增一减，词表大小保持不变。</p><ol start="3"><li>继续统计相邻子词的频数。此时，最高频连续子词对”es”和”t”出现了6+3&#x3D;9次, 将其合并成”est”，有</li></ol><p><img src="/Pictures/DL/BERT/step3.png" alt="step3"></p><ol start="4"><li>继续上述迭代直到达到预设的Subword词表大小或下一个最高频的字节对出现频率为1</li></ol><p>从上面的示例可以知道，每次合并后词表大小可能出现3种变化：</p><ul><li>+1，表明加入合并后的新子词，同时原来的2个子词还保留（2个字词分开出现在语料中）。</li><li>+0，表明加入合并后的新子词，同时原来的2个子词中一个保留，一个被消解（一个子词完全随着另一个子词的出现而紧跟着出现）。</li><li>-1，表明加入合并后的新子词，同时原来的2个子词都被消解（2个字词同时连续出现）。</li></ul><p>在得到Subword词表后，针对每一个单词，我们可以采用如下的方式来进行编码：</p><ol><li>将词典中的所有子词按照长度由大到小进行排序；</li><li>对于单词w，依次遍历排好序的词典。查看当前子词是否是该单词的子字符串，如果是，则输出当前子词，并对剩余单词字符串继续匹配。</li><li>如果遍历完字典后，仍然有子字符串没有匹配，则将剩余字符串替换为特殊符号输出，如”<unk>”。</li><li>单词的表示即为上述所有输出子词。</li></ol><p>解码过程比较简单，如果相邻子词间没有中止符，则将两子词直接拼接，否则两子词之间添加分隔符。</p><h2 id="WordPiece"><a href="#WordPiece" class="headerlink" title="WordPiece"></a>WordPiece</h2><p>与BPE算法类似，WordPiece算法也是每次从词表中选出两个子词合并成新的子词。与BPE的最大区别在于，如何选择两个子词进行合并：BPE选择频数最高的相邻子词合并，而WordPiece选择能够提升语言模型概率最大的相邻子词加入词表。</p><p>我们假设句子 $S&#x3D;(t_{1}, t_{2}, \ldots , t_{n})$ 由 $n$ 个子词组成，各子词独立存在，则句子 $S$ 的语言模型似然值等价于所有子词概率的乘积：<br>$$\log{}{P}(S)&#x3D;\sum_{i&#x3D;1}^{n}\log{}{P}(t_{i})$$</p><p>假设把相邻位置的 $x$ 和 $y$ 两个子词进行合并，产生子词 $z$ ，那么此时句子 $S$ 的似然值可以表示为：<br>$$\log{}{P}(t_{z})-(\log{}{P}(t_{x})+\log{}{P}(t_{y}))&#x3D;\log{}{\frac{P(t_{z})}{P(t_{x}P(t_{y}))}}$$</p><p>似然值的变化就是两个子词之间的互信息。WordPiece每次选择合并的两个子词，他们具有最大的互信息值，也就是两子词在语言模型上具有较强的关联性，它们经常在语料中以相邻方式同时出现。</p><div class="note note-info">            <p>互信息（Mutual Information）是一种用于衡量两个事件之间相关性的统计指标，它可以用来衡量两个随机变量之间的信息共享程度。在WordPiece算法中，可以使用互信息来衡量两个相邻的子词单元之间的关联程度，以帮助决定是否将它们合并。</p><p>互信息的计算公式如下：<br>$$I(X;Y) &#x3D; \sum_{x \in X} \sum_{y \in Y} p(x,y) \log \left( \frac{p(x,y)}{p(x)p(y)} \right)$$</p>          </div><h2 id="Unigram-Language-Model-ULM"><a href="#Unigram-Language-Model-ULM" class="headerlink" title="Unigram Language Model (ULM)"></a>Unigram Language Model (ULM)</h2><p>Unigram Language Model则是减量法,即先初始化一个大词表，根据评估准则不断丢弃词表，直到满足限定条件。ULM算法考虑了句子的不同分词可能，因而能够输出带概率的多个子词分段。</p><hr><p>参考：</p><ol><li><a href="http://121.199.45.168:13008/06_mkdocs_pretrained_model/1%20BERT%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D.html">http://121.199.45.168:13008/06_mkdocs_pretrained_model/1%20BERT%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D.html</a></li><li><a href="https://zhuanlan.zhihu.com/p/98855346">https://zhuanlan.zhihu.com/p/98855346</a></li><li><a href="https://zhuanlan.zhihu.com/p/191648421">https://zhuanlan.zhihu.com/p/191648421</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Attention is all you need</title>
    <link href="/2024/03/06/Attention-is-all-you-need/"/>
    <url>/2024/03/06/Attention-is-all-you-need/</url>
    
    <content type="html"><![CDATA[<h1 id="注意力机制"><a href="#注意力机制" class="headerlink" title="注意力机制"></a>注意力机制</h1><p>我们观察事物时，之所以能够快速判断一种事物(当然允许判断是错误的), 是因为我们大脑能够很快把注意力放在事物最具有辨识度的部分从而作出判断，而并非是从头到尾的观察一遍事物后，才能有判断结果. 正是基于这样的理论，就产生了注意力机制.</p><blockquote><p>摘自论文原文：<br>An attention function can be described as mapping a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors. The output is computed as a weighted sum of the values, where the weight assigned to each value is computed by a compatibility function of the query with the corresponding key.</p></blockquote><p>注意力机制的核心公式为：</p><p>$$ Attention(Q, K, V) &#x3D; softmax(\frac{QK^{T}}{\sqrt d_{k}})V $$</p><p>对于注意力机制来说，我们需要三个基本的输入： $Q(query), K(key), V(value)$ 。</p><p>在Transformer中Encoder使用的$ Q, K, V $ ，其实都是从输入矩阵 $X$ 经过线性变化得来的。</p><p>简单来说就是：</p><p>$$\begin{cases}<br>Q &#x3D; XW^{Q} \\<br>K &#x3D; XW^{K} \\<br>V &#x3D; XW^{V}<br>\end{cases}$$</p><p><img src="/Pictures/DL/Attention/f2.png" alt="img"></p><p>在这张图中，$Q$ 与 $K^{T}$ 经过MatMul，生成了相似度矩阵。对相似度矩阵每个元素除以 $\sqrt d_{k}$，其为 $K$ 的维度大小。这个除法被称为Scale。</p><p>注意力的计算过程：</p><p><img src="/Pictures/DL/Attention/f3.png" alt="img"></p><ol><li>query 和 key 进行相似度计算，得到一个query 和 key 相关性的分值</li><li>将这个分值进行归一化(softmax)，得到一个注意力的分布</li><li>使用注意力分布和 value 进行计算，得到一个融合注意力的更好的 value 值</li></ol><p>为了增强拟合性能，Transformer对Attention继续扩展，提出了多头注意力（Multi-Head Attention）。</p><p><img src="/Pictures/DL/Attention/f4.png" alt="img"></p><p>对于同样的输入 $X$ ，我们定义多组不同的 $W^{Q}, W^{K}, W^{V}$ ，计算得到多组 $Q,K,V$ ，然后学习到不同的数据。</p><p>比如我们定义8组参数，同样的输入 $X$ ，将得到8个不同的输出 $Z_{0} ~ Z_{7}$ ，在输出到下一层前，我们需要将8个输出拼接到一起，进行一次线性变换，将维度降低到我们想要的维度。</p><h1 id="Self-Attention"><a href="#Self-Attention" class="headerlink" title="Self-Attention"></a>Self-Attention</h1><p>Self-attention就本质上是一种特殊的attention。</p><p>attention和self attention 其具体计算过程是一样的，只是计算对象发生了变化而已。</p><p>attention是source对target的attention，</p><p>而self attention 是source 对source的attention。</p><p>即输入的Q&#x3D;K&#x3D;V。</p><p>在翻译任务中，如果源句子≠目标句子，那么你用目标句子中的词去query源句子中的所有词的key，再做相应运算，这种方式就是Attention；如果你的需求不是翻译，而是对当前这句话中某几个词之间的关系更感兴趣，期望对他们进行计算，这种方式就是Self-Attention。</p><p>从范围上来讲，注意力机制是包含自注意力机制的。注意力机制给定K、Q、V，其中Q和V可以是任意的，而K往往等于V（不相等也可以）；而自注意力机制要求K&#x3D;Q&#x3D;V。</p><h1 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h1><p>Transformer模型基于Encoder-Decoder架构。一般地，在Encoder-Decoder中，Encoder部分将一部分信息抽取出来，生成中间编码信息，发送到Decoder中。</p><p><img src="/Pictures/DL/Attention/f1.png" alt="img"></p><p>我们可以将整个架构抽象为四个组成部分：</p><ol><li>输入部分</li><li>输出部分</li><li>编码器部分</li><li>解码器部分</li></ol><h2 id="输入部分"><a href="#输入部分" class="headerlink" title="输入部分"></a>输入部分</h2><p><img src="/Pictures/DL/Attention/f5.png" alt="img"></p><ul><li>源文本嵌入层及其位置编码器</li><li>目标文本嵌入层及其位置编码器</li></ul><p>关于位置编码器 Positional Encoding：</p><p>Transformer模型的输入为一系列词，词需要转化为词向量。一般的语言模型都需要使用Embedding层，用以将词转化为词向量。Transformer没有采用RNN的结构，不能利用单词的顺序信息，但顺序信息对于NLP任务来说非常重要。在此基础上，Transformer增加了位置编码（Positional Encoding）。</p><p>$$ PE_{(pos,2i)} &#x3D; sin(pos &#x2F; 10000^{2i &#x2F; d})$$<br>$$ PE_{(pos,2i+1)} &#x3D; cos(pos &#x2F; 10000^{2i &#x2F; d})$$</p><p>$pos$ 代表单词在句子中的位置， $d$ 表示词向量的维度， $2i$ 表示偶数维度， $2i+1$ 表示奇数维度。生成的是[−1,1]区间内的实数。</p><h3 id="Embedding层和Positional-Encoding层的代码实现："><a href="#Embedding层和Positional-Encoding层的代码实现：" class="headerlink" title="Embedding层和Positional Encoding层的代码实现："></a>Embedding层和Positional Encoding层的代码实现：</h3><p>x的大小为 (batch_size, sequence_length, embedding_dim)<br>pe的大小为 (max_len, embedding_dim)<br>这里的 sequence_length $\ne$ max_len，需要匹配形状。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> math<br><span class="hljs-keyword">from</span> torch.autograd <span class="hljs-keyword">import</span> Variable<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Embeddings</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, d_model, vocab</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        d_model: 指词嵌入的维度 </span><br><span class="hljs-string">        vocab: 指词表的大小</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>(Embeddings, self).__init__()<br>        <span class="hljs-comment"># 调用nn中的预定义层Embedding, 获得一个词嵌入对象self.lut</span><br>        self.lut = nn.Embedding(vocab, d_model)<br>        self.d_model = d_model<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># 乘以缩放因子，通常为词嵌入的维度开根号</span><br>        <span class="hljs-keyword">return</span> self.lut(x) * math.sqrt(self.d_model)<br> <br><span class="hljs-keyword">class</span> <span class="hljs-title class_">PositionalEncoding</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, d_model, dropout, max_len=<span class="hljs-number">5000</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        d_model: 词嵌入维度, </span><br><span class="hljs-string">        dropout: 置0比率, max_len: 每个句子的最大长度</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>(PositionalEncoding, self).__init__()<br>        <span class="hljs-comment"># 实例化nn中预定义的Dropout层, 并将dropout传入其中, 获得对象self.dropout</span><br>        self.dropout = nn.Dropout(p=dropout)<br>        <span class="hljs-comment"># 初始化一个位置编码矩阵, 它是一个0阵，矩阵的大小是max_len x d_model.</span><br>        pe = torch.zeros(max_len, d_model)<br><br>        <span class="hljs-comment"># 初始化一个绝对位置矩阵，用它的索引去表示词汇的绝对位置。</span><br>        <span class="hljs-comment"># 首先使用arange方法获得一个连续自然数向量，然后使用unsqueeze方法拓展向量维度使其成为矩阵 </span><br>        position = torch.arange(<span class="hljs-number">0</span>, max_len).unsqueeze(<span class="hljs-number">1</span>)<br><br>        <span class="hljs-comment"># 对应公式，将奇数维度和偶数维度分别对应初始化。</span><br>        div_term = torch.exp(torch.arange(<span class="hljs-number">0</span>, d_model, <span class="hljs-number">2</span>) *<br>                             -(math.log(<span class="hljs-number">10000.0</span>) / d_model))<br>        pe[:, <span class="hljs-number">0</span>::<span class="hljs-number">2</span>] = torch.sin(position * div_term)<br>        pe[:, <span class="hljs-number">1</span>::<span class="hljs-number">2</span>] = torch.cos(position * div_term)<br><br>        <span class="hljs-comment"># 使用unsqueeze拓展维度。</span><br>        pe = pe.unsqueeze(<span class="hljs-number">0</span>)<br><br>        <span class="hljs-comment"># 最后把pe位置编码矩阵注册成模型的buffer</span><br>        self.register_buffer(<span class="hljs-string">&#x27;pe&#x27;</span>, pe)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># 适配张量大小</span><br>        x = x + self.pe[:, :x.size(<span class="hljs-number">1</span>)].detach()<br>        <span class="hljs-keyword">return</span> self.dropout(x)<br></code></pre></td></tr></table></figure><h2 id="编码器部分"><a href="#编码器部分" class="headerlink" title="编码器部分"></a>编码器部分</h2><ul><li>由N个编码器层堆叠而成</li><li>每个编码器层由两个子层连接结构组成</li><li>第一个子层连接结构包括一个多头自注意力子层和规范化层以及一个残差连接</li><li>第二个子层连接结构包括一个前馈全连接子层和规范化层以及一个残差连接</li></ul><p>Add &amp; Norm层由 Add 和 Norm 两部分组成。Add 类似 ResNet 提出的残差连接，以解决深层网络训练不稳定的问题。Norm 为归一化层，即 <em>Layer Normalization</em> ，通常用于 RNN 结构。</p><p>Feed Forward层由两个全连接层构成，第一层的激活函数为 ReLu，第二层不使用激活函数。</p><p>Multi-Head Attention 采用了 Mask 操作，即掩码张量,因为在翻译的过程中是顺序翻译的，即翻译完第 i 个单词，才可以翻译第i+1 个单词。</p><p><img src="/Pictures/DL/Attention/f7.png" alt="Mask"></p><p>0到4即代表按顺序的前5个单词。</p><h3 id="Mask"><a href="#Mask" class="headerlink" title="Mask"></a>Mask</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">subsequent_mask</span>(<span class="hljs-params">size</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    size是掩码张量最后两个维度的大小,形成一个方阵</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    attn_shape = (<span class="hljs-number">1</span>, size, size)<br><br>    <span class="hljs-comment"># 然后使用np.ones方法向这个形状中添加1元素,形成上三角阵 </span><br>    <span class="hljs-comment"># 再使其中的数据类型变为无符号8位整形unit8 </span><br>    subsequent_mask = np.triu(np.ones(attn_shape), k=<span class="hljs-number">1</span>).astype(<span class="hljs-string">&#x27;uint8&#x27;</span>)<br><br>    <span class="hljs-comment"># 最后将numpy类型转化为torch中的tensor, 内部做一个1 - 的操作, 即将上三角转为下三角。</span><br>    <span class="hljs-keyword">return</span> torch.from_numpy(<span class="hljs-number">1</span> - subsequent_mask)<br></code></pre></td></tr></table></figure><h3 id="注意力的计算实现"><a href="#注意力的计算实现" class="headerlink" title="注意力的计算实现"></a>注意力的计算实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">attention</span>(<span class="hljs-params">query, key, value, mask=<span class="hljs-literal">None</span>, dropout=<span class="hljs-literal">None</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    输入分别是query, key, value</span><br><span class="hljs-string">    mask: 掩码张量, </span><br><span class="hljs-string">    dropout：置零</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 取query的最后一维的大小, 等同于词嵌入维度</span><br>    d_k = query.size(-<span class="hljs-number">1</span>)<br>    <span class="hljs-comment"># 按照注意力公式得到注意力得分张量scores</span><br>    scores = torch.matmul(query, key.transpose(-<span class="hljs-number">2</span>, -<span class="hljs-number">1</span>)) / math.sqrt(d_k)<br><br>    <span class="hljs-comment"># 判断是否使用掩码张量</span><br>    <span class="hljs-keyword">if</span> mask <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        <span class="hljs-comment"># 使用tensor的masked_fill方法, 将掩码张量和scores张量每个位置一一比较, 如果掩码张量处为0则对应的scores张量用-1e9这个值来替换</span><br>        scores = scores.masked_fill(mask == <span class="hljs-number">0</span>, -<span class="hljs-number">1e9</span>)<br><br>    <span class="hljs-comment"># 进行softmax操作</span><br>    p_attn = F.softmax(scores, dim = -<span class="hljs-number">1</span>)<br><br>    <span class="hljs-comment"># 之后判断是否使用dropout进行随机置0</span><br>    <span class="hljs-keyword">if</span> dropout <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        p_attn = dropout(p_attn)<br><br>    <span class="hljs-comment"># 最后, 根据公式将p_attn与value张量相乘获得最终的query注意力表示, 同时返回注意力张量</span><br>    <span class="hljs-keyword">return</span> torch.matmul(p_attn, value), p_attn<br></code></pre></td></tr></table></figure><h3 id="多头注意力机制实现"><a href="#多头注意力机制实现" class="headerlink" title="多头注意力机制实现"></a>多头注意力机制实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> copy<br><br><span class="hljs-comment"># 首先需要定义克隆函数, 因为在多头注意力机制的实现中, 用到多个结构相同的线性层.</span><br><span class="hljs-comment"># 我们将使用clone函数将他们一同初始化在一个网络层列表对象中。</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">clones</span>(<span class="hljs-params">module, N</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    用于生成相同网络层的克隆函数, 它的参数module表示要克隆的目标网络层, N代表需要克隆的数量&quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 在函数中, 我们通过for循环对module进行N次深度拷贝, 使其每个module成为独立的层,</span><br>    <span class="hljs-comment"># 然后将其放在nn.ModuleList类型的列表中存放.</span><br>    <span class="hljs-keyword">return</span> nn.ModuleList([copy.deepcopy(module) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N)])<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MultiHeadedAttention</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, head, embedding_dim, dropout=<span class="hljs-number">0.1</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        head——头数</span><br><span class="hljs-string">        embedding_dim——词嵌入的维度， </span><br><span class="hljs-string">        dropout——置0比率，默认是0.1</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>(MultiHeadedAttention, self).__init__()<br><br>        <span class="hljs-comment"># 判断h是否能被d_model整除</span><br>        <span class="hljs-comment"># 这是因为我们之后要给每个头分配等量的词特征.也就是embedding_dim/head个.</span><br>        <span class="hljs-keyword">assert</span> embedding_dim % head == <span class="hljs-number">0</span><br><br>        <span class="hljs-comment"># 得到每个头获得的分割词向量维度d_k</span><br>        self.d_k = embedding_dim // head<br>        self.head = head<br><br>        <span class="hljs-comment"># 然后获得线性层对象，通过nn的Linear实例化，它的内部变换矩阵是embedding_dim x embedding_dim，然后使用clones函数克隆四个，</span><br>        <span class="hljs-comment"># 在多头注意力中，Q，K，V各需要一个，拼接的矩阵还需要一个，一共是四个.</span><br>        self.linears = clones(nn.Linear(embedding_dim, embedding_dim), <span class="hljs-number">4</span>)<br><br>        <span class="hljs-comment"># self.attn为None，它代表最后得到的注意力张量，现在还没有结果所以为None.</span><br>        self.attn = <span class="hljs-literal">None</span><br>        self.dropout = nn.Dropout(p=dropout)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, query, key, value, mask=<span class="hljs-literal">None</span></span>):<br><br>        <span class="hljs-keyword">if</span> mask <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            mask = mask.unsqueeze(<span class="hljs-number">0</span>)<br><br>        batch_size = query.size(<span class="hljs-number">0</span>)<br><br><br>        <span class="hljs-comment"># [model(x).view(batch_size, -1, self.head, self.d_k).transpose(1, 2) for ...]: 在每次迭代中，首先使用 model(x) 对输入进行线性变换。然后使用 view 方法将结果重塑为 (batch_size, -1, self.head, self.d_k) 的形状，其中 batch_size 表示批处理大小，-1 表示自动计算该维度大小，self.head 表示头的数量，self.d_k 表示每个头的维度。这样就将线性变换后的结果按照头的数量进行了分割。</span><br><br>        <span class="hljs-comment"># transpose(1, 2): 最后，使用 transpose 方法将第1和第2维进行转置。在多头注意力中，这样做是为了使代表句子长度和词向量维度的维度能够相邻，以便后续的注意力计算可以正确处理输入数据。具体地，该操作将形状从 (batch_size, seq_length, head, d_k) 转换为 (batch_size, head, seq_length, d_k)。</span><br><br>        query, key, value = \<br>        [model(x).view(batch_size, -<span class="hljs-number">1</span>, self.head, self.d_k).transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>                     <span class="hljs-keyword">for</span> model, x <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(self.linears, (query, key, value))]<br><br><br>        x, self.attn = attention(query, key, value, mask=mask, dropout=self.dropout)<br><br>        <span class="hljs-comment"># 先将维度复原，再由多头转为单头。</span><br>        x = x.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>).contiguous().view(batch_size, -<span class="hljs-number">1</span>, self.head * self.d_k)<br><br>        <span class="hljs-comment"># 最后使用线性层列表中的最后一个线性层对输入进行线性变换得到最终的多头注意力结构的输出.</span><br>        <span class="hljs-keyword">return</span> self.linears[-<span class="hljs-number">1</span>](x)<br></code></pre></td></tr></table></figure><div class="note note-info">            <p>contiguous() 是 PyTorch 中的一个方法，用于返回一个具有连续内存的新张量，即将张量的存储重新排列为连续的内存块，使得张量的元素在内存中的布局是连续的。<br>在上面，由于转置操作，储存内存变得不连续了，所以需要重新规划。</p>          </div><h3 id="前馈全连接层"><a href="#前馈全连接层" class="headerlink" title="前馈全连接层"></a>前馈全连接层</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">PositionwiseFeedForward</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, d_model, d_ff, dropout=<span class="hljs-number">0.1</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        d_model——线性层的输入维度，也是第二个线性层的输出维度</span><br><span class="hljs-string">        d_ff——第二个线性层的输入维度和第一个线性层的输出维度</span><br><span class="hljs-string">        dropout=0.1</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>(PositionwiseFeedForward, self).__init__()<br><br>        <span class="hljs-comment"># 首先按照我们预期使用nn实例化了两个线性层对象，self.w1和self.w2</span><br>        <span class="hljs-comment"># 它们的参数分别是d_model, d_ff和d_ff, d_model</span><br>        self.w1 = nn.Linear(d_model, d_ff)<br>        self.w2 = nn.Linear(d_ff, d_model)<br><br>        self.dropout = nn.Dropout(dropout)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># 首先经过第一个线性层，然后使用Funtional中relu函数进行激活,</span><br>        <span class="hljs-comment"># 之后再使用dropout进行随机置0，最后通过第二个线性层w2，返回最终结果.</span><br>        <span class="hljs-keyword">return</span> self.w2(self.dropout(F.relu(self.w1(x))))<br></code></pre></td></tr></table></figure><h3 id="规范化层"><a href="#规范化层" class="headerlink" title="规范化层"></a>规范化层</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">LayerNorm</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, features, eps=<span class="hljs-number">1e-6</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        features——表示词嵌入的维度,</span><br><span class="hljs-string">        eps——它是一个足够小的数, 在规范化公式的分母中出现,防止分母为0.默认是1e-6.</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>(LayerNorm, self).__init__()<br>        self.a2 = nn.Parameter(torch.ones(features))<br>        self.b2 = nn.Parameter(torch.zeros(features))<br>        self.eps = eps<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        mean = x.mean(-<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>)<br>        std = x.std(-<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>)<br>        <span class="hljs-keyword">return</span> self.a2 * (x - mean) / (std + self.eps) + self.b2<br></code></pre></td></tr></table></figure><div class="note note-info">            <p>self.a2 是一个用 nn.Parameter 封装的可学习参数张量，它的形状为 (features,)，其中 features 表示输入特征的维度。这个参数控制归一化后的结果的缩放比例。在初始化时，我们将其初始化为一个全为1的张量，表示初始时不进行缩放。</p><p>self.b2 同样是一个用 nn.Parameter 封装的可学习参数张量，形状也为 (features,)。这个参数控制归一化后的结果的平移偏移。在初始化时，我们将其初始化为一个全为0的张量，表示初始时不进行平移。</p><p>在进行 Layer Normalization 过程中，我们先计算输入张量 x 沿着最后一个维度的均值和标准差，然后对输入进行归一化。归一化的结果为 (x - mean) &#x2F; (std + eps)，其中 eps 是一个足够小的数，用于防止分母为0的情况。然后，我们将归一化后的结果乘以 self.a2（缩放）并加上 self.b2（平移），得到最终的归一化结果。</p>          </div><h3 id="子层连接结构-Add"><a href="#子层连接结构-Add" class="headerlink" title="子层连接结构(Add)"></a>子层连接结构(Add)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SublayerConnection</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, size, dropout=<span class="hljs-number">0.1</span></span>):<br><br>        <span class="hljs-built_in">super</span>(SublayerConnection, self).__init__()<br>        <span class="hljs-comment"># 实例化了规范化对象self.norm</span><br>        self.norm = LayerNorm(size)<br>        <span class="hljs-comment"># 又使用nn中预定义的droupout实例化一个self.dropout对象.</span><br>        self.dropout = nn.Dropout(p=dropout)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, sublayer</span>):<br>        <span class="hljs-keyword">return</span> x + self.dropout(sublayer(self.norm(x)))<br></code></pre></td></tr></table></figure><h3 id="编码器"><a href="#编码器" class="headerlink" title="编码器"></a>编码器</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-keyword">class</span> <span class="hljs-title class_">EncoderLayer</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, size, self_attn, feed_forward, dropout</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        size，词嵌入维度的大小，它也将作为编码器层的大小</span><br><span class="hljs-string">        self_attn，多头自注意力子层实例化对象,自注意力机制 </span><br><span class="hljs-string">        feed_froward,前馈全连接层实例化对象</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>(EncoderLayer, self).__init__()<br><br>        <span class="hljs-comment"># 首先将self_attn和feed_forward传入其中.</span><br>        self.self_attn = self_attn<br>        self.feed_forward = feed_forward<br><br>        <span class="hljs-comment"># 如图所示, 编码器层中有两个子层连接结构, 所以使用clones函数进行克隆</span><br>        self.sublayer = clones(SublayerConnection(size, dropout), <span class="hljs-number">2</span>)<br>        <span class="hljs-comment"># 把size传入其中</span><br>        self.size = size<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, mask</span>):<br><br>        x = self.sublayer[<span class="hljs-number">0</span>](x, <span class="hljs-keyword">lambda</span> x: self.self_attn(x, x, x, mask))<br>        <span class="hljs-keyword">return</span> self.sublayer[<span class="hljs-number">1</span>](x, self.feed_forward)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Encoder</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, layer, N</span>):<br><br>        <span class="hljs-built_in">super</span>(Encoder, self).__init__()<br>        <span class="hljs-comment"># 首先使用clones函数克隆N个编码器层放在self.layers中</span><br>        self.layers = clones(layer, N)<br>        <span class="hljs-comment"># 再初始化一个规范化层, 它将用在编码器的最后面.</span><br>        self.norm = LayerNorm(layer.size)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, mask</span>):<br>        <span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> self.layers:<br>            x = layer(x, mask)<br>        <span class="hljs-keyword">return</span> self.norm(x)<br></code></pre></td></tr></table></figure><h2 id="解码器部分"><a href="#解码器部分" class="headerlink" title="解码器部分"></a>解码器部分</h2><ul><li>由N个解码器层堆叠而成</li><li>每个解码器层由三个子层连接结构组成</li><li>第一个子层连接结构包括一个多头自注意力子层和规范化层以及一个残差连接</li><li>第二个子层连接结构包括一个多头注意力子层和规范化层以及一个残差连接</li><li>第三个子层连接结构包括一个前馈全连接子层和规范化层以及一个残差连接</li></ul><h3 id="解码器层"><a href="#解码器层" class="headerlink" title="解码器层"></a>解码器层</h3><p>Decoder Block 的第一个 Multi-Head Attention 采用了 Mask 操作，第二个 Multi-Head Attention 主要的区别在于 Attention 的 K, V 矩阵不是来自上一个 Decoder Block 的输出计算的，而是来自Encoder的编码信息矩阵C。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">DecoderLayer</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, size, self_attn, src_attn, feed_forward, dropout</span>):<br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        size——词嵌入的维度大小，解码器的尺寸</span><br><span class="hljs-string">        self_attn——多头自注意力对象（Q=K=V）</span><br><span class="hljs-string">        src_attn——多头注意力对象（Q!=K=V）</span><br><span class="hljs-string">        feed_forward——前馈全连接层</span><br><span class="hljs-string">        dropout——置零比率</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        <span class="hljs-built_in">super</span>(DecoderLayer, self).__init__()<br>        self.size = size<br>        self.self_attn = self_attn<br>        self.src_attn = src_attn<br>        self.feed_forward = feed_forward<br>        <span class="hljs-comment"># 克隆三个子层连接对象</span><br>        self.sublayer = clones(SublayerConnection(size, dropout), <span class="hljs-number">3</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, memory, source_mask, target_mask</span>):<br>        <span class="hljs-comment"># memory——来自编码器层的语义存储变量</span><br><br>        <span class="hljs-comment"># 第一层——自注意力机制</span><br>        x = self.sublayer[<span class="hljs-number">0</span>](x, <span class="hljs-keyword">lambda</span> x: self.self_attn(x, x, x, target_mask))<br>        <span class="hljs-comment"># 第二层——常规注意力机制</span><br>        x = self.sublayer[<span class="hljs-number">1</span>](x, <span class="hljs-keyword">lambda</span> x: self.src_attn(x, memory, memory, target_mask))<br>        <span class="hljs-comment"># 第三层——前馈全连接层</span><br>        <span class="hljs-keyword">return</span> self.sublayer[<span class="hljs-number">2</span>](x, self.feed_forward)<br></code></pre></td></tr></table></figure><h3 id="解码器"><a href="#解码器" class="headerlink" title="解码器"></a>解码器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Decoder</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, layer, N</span>):<br>        <span class="hljs-built_in">super</span>(Decoder, self).__init__()<br>        self.layers = clones(layer, N)<br>        self.norm = LayerNorm(layer.size)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, memory, source_mask, target_mask</span>):<br>        <span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> self.layers:<br>            x = layer(x, memory, source_mask, target_mask)<br>        <span class="hljs-keyword">return</span> self.norm(x)<br><br></code></pre></td></tr></table></figure><h2 id="输出部分"><a href="#输出部分" class="headerlink" title="输出部分"></a>输出部分</h2><p><img src="/Pictures/DL/Attention/f6.png" alt="output"></p><h3 id="线性层-softmax层"><a href="#线性层-softmax层" class="headerlink" title="线性层&amp;softmax层"></a>线性层&amp;softmax层</h3><p>通过对上一步的线性变化得到指定维度的输出,并将向量进行归一化操作。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Generator</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, d_model, vocab_size</span>):<br>        <span class="hljs-built_in">super</span>(Generator, self).__init__()<br>        self.project = nn.Linear(d_model, vocab_size)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">return</span> F.log_softmax(self.project(x), dim=-<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><h2 id="最终模型构建"><a href="#最终模型构建" class="headerlink" title="最终模型构建"></a>最终模型构建</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">make_model</span>(<span class="hljs-params">source_vocab, target_vocab, N=<span class="hljs-number">6</span>, </span><br><span class="hljs-params">               d_model=<span class="hljs-number">512</span>, d_ff=<span class="hljs-number">2048</span>, head=<span class="hljs-number">8</span>, dropout=<span class="hljs-number">0.1</span></span>):<br><br>    c = copy.deepcopy<br>    attn = MultiHeadedAttention(head, d_model)<br>    ff = PositionwiseFeedForward(d_model, d_ff, dropout)<br>    position = PositionalEncoding(d_model, dropout)<br><br>    model = EncoderDecoder(<br>        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),<br>        Decoder(DecoderLayer(d_model, c(attn), c(attn), <br>                             c(ff), dropout), N),<br>        nn.Sequential(Embeddings(d_model, source_vocab), c(position)),<br>        nn.Sequential(Embeddings(d_model, target_vocab), c(position)),<br>        Generator(d_model, target_vocab))<br><br>    <span class="hljs-comment"># 模型结构完成后，接下来就是初始化模型中的参数，比如线性层中的变换矩阵</span><br>    <span class="hljs-comment"># 这里一但判断参数的维度大于1，则会将其初始化成一个服从均匀分布的矩阵，</span><br>    <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> model.parameters():<br>        <span class="hljs-keyword">if</span> p.dim() &gt; <span class="hljs-number">1</span>:<br>            nn.init.xavier_uniform(p)<br>    <span class="hljs-keyword">return</span> model<br></code></pre></td></tr></table></figure><div class="note note-info">            <p>nn.Sequential 是 PyTorch 中的一个容器，用于按顺序组合多个神经网络模块（如层、激活函数等），形成一个整体的神经网络模型。它可以简化模型的构建过程，使代码更加简洁易读。</p><p>具体地，nn.Sequential 接受一个包含多个神经网络模块的列表或序列作为参数，然后将这些模块按顺序组合在一起，形成一个完整的神经网络模型。当输入数据进入 nn.Sequential 时，它会按照列表中模块的顺序依次进行前向传播，将每个模块的输出作为下一个模块的输入，直到所有模块都被处理完毕，最终得到整个模型的输出。</p>          </div><p>最终我们得到的模型(下方较长)：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><code class="hljs routeros">EncoderDecoder(<br>  (encoder): Encoder(<br>    (layers): ModuleList(<br>      (0-5): 6 x EncoderLayer(<br>        (self_attn): MultiHeadedAttention(<br>          (linears): ModuleList(<br>            (0-3): 4 x Linear(<span class="hljs-attribute">in_features</span>=512, <span class="hljs-attribute">out_features</span>=512, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">True</span>)<br>          )<br>          (dropout): Dropout(<span class="hljs-attribute">p</span>=0.1, <span class="hljs-attribute">inplace</span>=<span class="hljs-literal">False</span>)<br>        )<br>        (feed_forward): PositionwiseFeedForward(<br>          (w1): Linear(<span class="hljs-attribute">in_features</span>=512, <span class="hljs-attribute">out_features</span>=2048, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">True</span>)<br>          (w2): Linear(<span class="hljs-attribute">in_features</span>=2048, <span class="hljs-attribute">out_features</span>=512, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">True</span>)<br>          (dropout): Dropout(<span class="hljs-attribute">p</span>=0.1, <span class="hljs-attribute">inplace</span>=<span class="hljs-literal">False</span>)<br>        )<br>        (sublayer): ModuleList(<br>          (0-1): 2 x SublayerConnection(<br>            (norm): LayerNorm()<br>            (dropout): Dropout(<span class="hljs-attribute">p</span>=0.1, <span class="hljs-attribute">inplace</span>=<span class="hljs-literal">False</span>)<br>          )<br>        )<br>      )<br>    )<br>    (norm): LayerNorm()<br>  )<br>  (decoder): Decoder(<br>    (layers): ModuleList(<br>      (0-5): 6 x DecoderLayer(<br>        (self_attn): MultiHeadedAttention(<br>          (linears): ModuleList(<br>            (0-3): 4 x Linear(<span class="hljs-attribute">in_features</span>=512, <span class="hljs-attribute">out_features</span>=512, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">True</span>)<br>          )<br>          (dropout): Dropout(<span class="hljs-attribute">p</span>=0.1, <span class="hljs-attribute">inplace</span>=<span class="hljs-literal">False</span>)<br>        )<br>        (src_attn): MultiHeadedAttention(<br>          (linears): ModuleList(<br>            (0-3): 4 x Linear(<span class="hljs-attribute">in_features</span>=512, <span class="hljs-attribute">out_features</span>=512, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">True</span>)<br>          )<br>          (dropout): Dropout(<span class="hljs-attribute">p</span>=0.1, <span class="hljs-attribute">inplace</span>=<span class="hljs-literal">False</span>)<br>        )<br>        (feed_forward): PositionwiseFeedForward(<br>          (w1): Linear(<span class="hljs-attribute">in_features</span>=512, <span class="hljs-attribute">out_features</span>=2048, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">True</span>)<br>          (w2): Linear(<span class="hljs-attribute">in_features</span>=2048, <span class="hljs-attribute">out_features</span>=512, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">True</span>)<br>          (dropout): Dropout(<span class="hljs-attribute">p</span>=0.1, <span class="hljs-attribute">inplace</span>=<span class="hljs-literal">False</span>)<br>        )<br>        (sublayer): ModuleList(<br>          (0-2): 3 x SublayerConnection(<br>            (norm): LayerNorm()<br>            (dropout): Dropout(<span class="hljs-attribute">p</span>=0.1, <span class="hljs-attribute">inplace</span>=<span class="hljs-literal">False</span>)<br>          )<br>        )<br>      )<br>    )<br>    (norm): LayerNorm()<br>  )<br>  (src_embed): Sequential(<br>    (0): Embeddings(<br>      (lut): Embedding(11, 512)<br>    )<br>    (1): PositionalEncoding(<br>      (dropout): Dropout(<span class="hljs-attribute">p</span>=0.1, <span class="hljs-attribute">inplace</span>=<span class="hljs-literal">False</span>)<br>    )<br>  )<br>  (tgt_embed): Sequential(<br>    (0): Embeddings(<br>      (lut): Embedding(11, 512)<br>    )<br>    (1): PositionalEncoding(<br>      (dropout): Dropout(<span class="hljs-attribute">p</span>=0.1, <span class="hljs-attribute">inplace</span>=<span class="hljs-literal">False</span>)<br>    )<br>  )<br>  (generator): Generator(<br>    (project): Linear(<span class="hljs-attribute">in_features</span>=512, <span class="hljs-attribute">out_features</span>=11, <span class="hljs-attribute">bias</span>=<span class="hljs-literal">True</span>)<br>  )<br>)<br></code></pre></td></tr></table></figure><hr><p>参考：</p><ol><li><a href="https://lulaoshi.info/deep-learning/attention/transformer-attention.html#self-attention%E4%B8%AD%E7%9A%84q%E3%80%81k%E3%80%81v">https://lulaoshi.info/deep-learning/attention/transformer-attention.html#self-attention%E4%B8%AD%E7%9A%84q%E3%80%81k%E3%80%81v</a></li><li><a href="https://juejin.cn/post/7125629962769399838">https://juejin.cn/post/7125629962769399838</a></li><li><a href="http://121.199.45.168:13008/04_mkdocs_transformer/3%20%E8%BE%93%E5%85%A5%E9%83%A8%E5%88%86%E5%AE%9E%E7%8E%B0.html">http://121.199.45.168:13008/04_mkdocs_transformer/3%20%E8%BE%93%E5%85%A5%E9%83%A8%E5%88%86%E5%AE%9E%E7%8E%B0.html</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>RNN——循环神经网络</title>
    <link href="/2024/03/04/RNN/"/>
    <url>/2024/03/04/RNN/</url>
    
    <content type="html"><![CDATA[<h1 id="RNN概述"><a href="#RNN概述" class="headerlink" title="RNN概述"></a>RNN概述</h1><p>当我们在理解一句话意思时，孤立的理解这句话的每个词是不够的，我们需要处理这些词连接起来的整个序列；当我们处理视频的时候，我们也不能只单独的去分析每一帧，而要分析这些帧连接起来的整个序列。</p><p>首先看一个简单的循环神经网络如，它由输入层、一个隐藏层和一个输出层组成：</p><p><img src="/Pictures/DL/RNN/plot01.png" alt="img"></p><p>其中，$O$ 是一个向量，代表输出层的值；$V$ 是隐藏层到输出层的权重矩阵，$U$ 是输入层到隐藏层的权重矩阵。</p><p>循环神经网络的隐藏层的值S不仅仅取决于当前这次的输入 $X$ ，还取决于上一次隐藏层的值 $S’$ 。权重矩阵 $W$ 就是隐藏层上一次的值作为这一次的输入的权重。</p><p>按时间线展开，我们可以得到下图：</p><p><img src="/Pictures/DL/RNN/plot03.png" alt="img"></p><p>不考虑bias的情况下，公式可以简化为：</p><p>$$\begin{cases}<br>O_{t} &#x3D; g(V \ldotp S_{t}) \\<br>S_{t} &#x3D; f(U \ldotp X_{t}+W \ldotp S_{t-1})<br>\end{cases}$$</p><p>举个例子：<br>第一步: 用户输入了”What time is it ?”, 我们首先需要对它进行基本的分词, 因为RNN是按照顺序工作的, 每次只接收一个单词进行处理.</p><p>第二步: 首先将单词”What”输送给RNN, 它将产生一个输出 $O_{1}$.</p><p>第三步: 继续将单词”time”输送给RNN, 但此时RNN不仅仅利用”time”来产生输出 $O_{2}$ , 还会使用来自上一层隐层输出 $O_{1}$ 作为输入信息.</p><p>第四步: 重复这样的步骤, 直到处理完所有的单词.</p><p>第五步: 最后，将最终的隐层输出 $O_{5}$ 进行处理来解析用户意图.</p><h1 id="RNN模型的分类"><a href="#RNN模型的分类" class="headerlink" title="RNN模型的分类"></a>RNN模型的分类</h1><p>按照输入和输出的结构进行分类:</p><ul><li>N vs N - RNN：输入和输出序列是等长的。</li><li>N vs 1 - RNN：输出是一个单独的值而不是序列。</li><li>1 vs N - RNN：输入不是序列而输出为序列</li><li>N vs M - RNN：不限输入输出长度的RNN结构，由编码器和解码器两部分组成, 两者的内部结构都是某类RNN, 它也被称为seq2seq架构。输入数据首先通过编码器, 最终输出一个隐含变量c, 之后最常用的做法是使用这个隐含变量c作用在解码器进行解码的每一步上, 以保证输入信息被有效利用。</li></ul><p>按照RNN的内部构造进行分类:</p><ul><li>传统RNN</li><li>LSTM</li><li>Bi-LSTM</li><li>GRU</li><li>Bi-GRU</li></ul><h2 id="传统RNN"><a href="#传统RNN" class="headerlink" title="传统RNN"></a>传统RNN</h2><p><img src="/Pictures/DL/RNN/plot04.png" alt="img"><br><img src="/Pictures/DL/RNN/plot05.png" alt="img"></p><blockquote><p>接下来使用h(t)来代表隐藏层的输出</p></blockquote><p>我们把目光集中在中间的方块部分, 它的输入有两部分, 分别是 $h(t-1)$ 以及 $x(t)$, 代表上一时间步的隐层输出, 以及此时间步的输入, 它们进入RNN结构体后, 会”融合”到一起, 这种融合我们根据结构解释可知, 是将二者进行拼接, 形成新的张量 $[x(t), h(t-1)]$ , 之后这个新的张量将通过一个全连接层(线性层), 该层使用 $tanh$ 作为激活函数, 最终得到该时间步的输出 $h(t)$, 它将作为下一个时间步的输入和 $x(t+1)$ 一起进入结构体，以此类推。</p><p>$$h_{t} &#x3D; tanh(W_{t}[X_{t},h_{t-1}]+b_{t})$$</p><p>使用PyTorch构建模型：通过torch.nn.RNN可调用</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 导入工具包</span><br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-meta">&gt;&gt;&gt; </span>rnn = nn.RNN(<span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">1</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">input</span> = torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">5</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>h0 = torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">6</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>output, hn = rnn(<span class="hljs-built_in">input</span>, h0)<br><span class="hljs-meta">&gt;&gt;&gt; </span>output<br>tensor([[[ <span class="hljs-number">0.4282</span>, -<span class="hljs-number">0.8475</span>, -<span class="hljs-number">0.0685</span>, -<span class="hljs-number">0.4601</span>, -<span class="hljs-number">0.8357</span>,  <span class="hljs-number">0.1252</span>],<br>         [ <span class="hljs-number">0.5758</span>, -<span class="hljs-number">0.2823</span>,  <span class="hljs-number">0.4822</span>, -<span class="hljs-number">0.4485</span>, -<span class="hljs-number">0.7362</span>,  <span class="hljs-number">0.0084</span>],<br>         [ <span class="hljs-number">0.9224</span>, -<span class="hljs-number">0.7479</span>, -<span class="hljs-number">0.3682</span>, -<span class="hljs-number">0.5662</span>, -<span class="hljs-number">0.9637</span>,  <span class="hljs-number">0.4938</span>]]],<br>       grad_fn=&lt;StackBackward&gt;)<br><br><span class="hljs-meta">&gt;&gt;&gt; </span>hn<br>tensor([[[ <span class="hljs-number">0.4282</span>, -<span class="hljs-number">0.8475</span>, -<span class="hljs-number">0.0685</span>, -<span class="hljs-number">0.4601</span>, -<span class="hljs-number">0.8357</span>,  <span class="hljs-number">0.1252</span>],<br>         [ <span class="hljs-number">0.5758</span>, -<span class="hljs-number">0.2823</span>,  <span class="hljs-number">0.4822</span>, -<span class="hljs-number">0.4485</span>, -<span class="hljs-number">0.7362</span>,  <span class="hljs-number">0.0084</span>],<br>         [ <span class="hljs-number">0.9224</span>, -<span class="hljs-number">0.7479</span>, -<span class="hljs-number">0.3682</span>, -<span class="hljs-number">0.5662</span>, -<span class="hljs-number">0.9637</span>,  <span class="hljs-number">0.4938</span>]]],<br>       grad_fn=&lt;StackBackward&gt;)<br></code></pre></td></tr></table></figure><p>input_size: 输入张量 $X$ 中特征维度的大小<br>hidden_size: 隐层张量 $h$ 中特征维度的大小<br>num_layers: 隐含层的数量<br>nonlinearity: 激活函数的选择, 默认是 $tanh$</p><p>传统RNN在解决长序列之间的关联时, 通过实践，证明经典RNN表现很差, 原因是在进行反向传播的时候, 过长的序列导致梯度的计算异常, 发生梯度消失或爆炸。</p><h2 id="LSTM模型"><a href="#LSTM模型" class="headerlink" title="LSTM模型"></a>LSTM模型</h2><p>LSTM（Long Short-Term Memory）也称长短时记忆结构, 它是传统RNN的变体, 与经典RNN相比能够有效捕捉长序列之间的语义关联, 缓解梯度消失或爆炸现象. 同时LSTM的结构更复杂, 它的核心结构可以分为四个部分去解析:</p><ol><li>遗忘门</li><li>输入门</li><li>细胞状态</li><li>输出门</li></ol><h3 id="遗忘门"><a href="#遗忘门" class="headerlink" title="遗忘门"></a>遗忘门</h3><p>与传统RNN的内部结构计算非常相似, 首先将当前时间步输入 $x(t)$ 与上一个时间步隐含状态 $h(t-1)$ 拼接, 得到 $[x(t), h(t-1)]$, 然后通过一个全连接层做变换, 最后通过 $sigmoid$ 函数进行激活得到 $f(t)$, 我们可以将 $f(t)$ 看作是门值, 好比一扇门开合的大小程度, 门值都将作用在通过该扇门的张量, 遗忘门门值将作用的上一层的细胞状态上, 代表遗忘过去的多少信息, 又因为遗忘门门值是由 $x(t), h(t-1)$ 计算得来的, 因此整个公式意味着根据当前时间步输入和上一个时间步隐含状态 $ h(t-1)$ 来决定遗忘多少上一层的细胞状态所携带的过往信息.<br><img src="/Pictures/DL/RNN/plot06.png" alt="img"><br><img src="/Pictures/DL/RNN/RNN01.gif" alt="img"></p><p>利用sigmoid函数将值压缩在0和1之间。</p><h3 id="输入门和细胞状态"><a href="#输入门和细胞状态" class="headerlink" title="输入门和细胞状态"></a>输入门和细胞状态</h3><p>输入门的计算公式有两个, 第一个就是产生输入门门值的公式, 它和遗忘门公式几乎相同, 区别只是在于它们之后要作用的目标上. 这个公式意味着输入信息有多少需要进行过滤. 输入门的第二个公式是与传统RNN的内部结构计算相同. 对于LSTM来讲, 它得到的是当前的细胞状态, 而不是像经典RNN一样得到的是隐含状态.</p><p><img src="/Pictures/DL/RNN/plot07.png" alt="img"><br><img src="/Pictures/DL/RNN/RNN02.gif" alt="img"></p><p>细胞更新的结构与计算公式非常容易理解, 这里没有全连接层, 只是将刚刚得到的遗忘门门值与上一个时间步得到的 $C(t-1)$ 相乘, 再加上输入门门值与当前时间步得到的未更新 $C(t)$ 相乘的结果. 最终得到更新后的 $C(t)$ 作为下一个时间步输入的一部分. 整个细胞状态更新过程就是对遗忘门和输入门的应用.</p><p><img src="/Pictures/DL/RNN/plot08.png" alt="img"><br><img src="/Pictures/DL/RNN/RNN03.gif" alt="img"></p><h3 id="输出门"><a href="#输出门" class="headerlink" title="输出门"></a>输出门</h3><p>输出门部分的公式也是两个, 第一个即是计算输出门的门值, 它和遗忘门，输入门计算方式相同. 第二个即是使用这个门值产生隐含状态 $h(t)$, 他将作用在更新后的细胞状态 $C(t)$ 上, 并做 $tanh$ 激活, 最终得到 $h(t)$ 作为下一时间步输入的一部分. 整个输出门的过程, 就是为了产生隐含状态 $h(t)$ .</p><p><img src="/Pictures/DL/RNN/RNN04.gif" alt="img"></p><h2 id="Bi-LSTM介绍"><a href="#Bi-LSTM介绍" class="headerlink" title="Bi-LSTM介绍"></a>Bi-LSTM介绍</h2><p>Bi-LSTM，即双向LSTM, 它没有改变LSTM本身任何的内部结构, 只是将LSTM应用两次且方向不同, 再将两次得到的LSTM结果进行拼接作为最终输出.</p><p><img src="/Pictures/DL/RNN/plot09.png" alt="img"></p><p>PyTorch构建LSTM模型：通过torch.nn.LSTM可调用。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-comment"># 定义LSTM的参数含义: (input_size, hidden_size, num_layers)</span><br><span class="hljs-comment"># 定义输入张量的参数含义: (sequence_length, batch_size, input_size)</span><br><span class="hljs-comment"># 定义隐藏层初始张量和细胞初始状态张量的参数含义:</span><br><span class="hljs-comment"># (num_layers * num_directions, batch_size, hidden_size)</span><br><br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch<br><span class="hljs-meta">&gt;&gt;&gt; </span>rnn = nn.LSTM(<span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">2</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">input</span> = torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">5</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>h0 = torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">6</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>c0 = torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">6</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>output, (hn, cn) = rnn(<span class="hljs-built_in">input</span>, (h0, c0))<br><span class="hljs-meta">&gt;&gt;&gt; </span>output<br>tensor([[[ <span class="hljs-number">0.0447</span>, -<span class="hljs-number">0.0335</span>,  <span class="hljs-number">0.1454</span>,  <span class="hljs-number">0.0438</span>,  <span class="hljs-number">0.0865</span>,  <span class="hljs-number">0.0416</span>],<br>         [ <span class="hljs-number">0.0105</span>,  <span class="hljs-number">0.1923</span>,  <span class="hljs-number">0.5507</span>, -<span class="hljs-number">0.1742</span>,  <span class="hljs-number">0.1569</span>, -<span class="hljs-number">0.0548</span>],<br>         [-<span class="hljs-number">0.1186</span>,  <span class="hljs-number">0.1835</span>, -<span class="hljs-number">0.0022</span>, -<span class="hljs-number">0.1388</span>, -<span class="hljs-number">0.0877</span>, -<span class="hljs-number">0.4007</span>]]],<br>       grad_fn=&lt;StackBackward&gt;)<br><span class="hljs-meta">&gt;&gt;&gt; </span>hn<br>tensor([[[ <span class="hljs-number">0.4647</span>, -<span class="hljs-number">0.2364</span>,  <span class="hljs-number">0.0645</span>, -<span class="hljs-number">0.3996</span>, -<span class="hljs-number">0.0500</span>, -<span class="hljs-number">0.0152</span>],<br>         [ <span class="hljs-number">0.3852</span>,  <span class="hljs-number">0.0704</span>,  <span class="hljs-number">0.2103</span>, -<span class="hljs-number">0.2524</span>,  <span class="hljs-number">0.0243</span>,  <span class="hljs-number">0.0477</span>],<br>         [ <span class="hljs-number">0.2571</span>,  <span class="hljs-number">0.0608</span>,  <span class="hljs-number">0.2322</span>,  <span class="hljs-number">0.1815</span>, -<span class="hljs-number">0.0513</span>, -<span class="hljs-number">0.0291</span>]],<br><br>        [[ <span class="hljs-number">0.0447</span>, -<span class="hljs-number">0.0335</span>,  <span class="hljs-number">0.1454</span>,  <span class="hljs-number">0.0438</span>,  <span class="hljs-number">0.0865</span>,  <span class="hljs-number">0.0416</span>],<br>         [ <span class="hljs-number">0.0105</span>,  <span class="hljs-number">0.1923</span>,  <span class="hljs-number">0.5507</span>, -<span class="hljs-number">0.1742</span>,  <span class="hljs-number">0.1569</span>, -<span class="hljs-number">0.0548</span>],<br>         [-<span class="hljs-number">0.1186</span>,  <span class="hljs-number">0.1835</span>, -<span class="hljs-number">0.0022</span>, -<span class="hljs-number">0.1388</span>, -<span class="hljs-number">0.0877</span>, -<span class="hljs-number">0.4007</span>]]],<br>       grad_fn=&lt;StackBackward&gt;)<br><span class="hljs-meta">&gt;&gt;&gt; </span>cn<br>tensor([[[ <span class="hljs-number">0.8083</span>, -<span class="hljs-number">0.5500</span>,  <span class="hljs-number">0.1009</span>, -<span class="hljs-number">0.5806</span>, -<span class="hljs-number">0.0668</span>, -<span class="hljs-number">0.1161</span>],<br>         [ <span class="hljs-number">0.7438</span>,  <span class="hljs-number">0.0957</span>,  <span class="hljs-number">0.5509</span>, -<span class="hljs-number">0.7725</span>,  <span class="hljs-number">0.0824</span>,  <span class="hljs-number">0.0626</span>],<br>         [ <span class="hljs-number">0.3131</span>,  <span class="hljs-number">0.0920</span>,  <span class="hljs-number">0.8359</span>,  <span class="hljs-number">0.9187</span>, -<span class="hljs-number">0.4826</span>, -<span class="hljs-number">0.0717</span>]],<br><br>        [[ <span class="hljs-number">0.1240</span>, -<span class="hljs-number">0.0526</span>,  <span class="hljs-number">0.3035</span>,  <span class="hljs-number">0.1099</span>,  <span class="hljs-number">0.5915</span>,  <span class="hljs-number">0.0828</span>],<br>         [ <span class="hljs-number">0.0203</span>,  <span class="hljs-number">0.8367</span>,  <span class="hljs-number">0.9832</span>, -<span class="hljs-number">0.4454</span>,  <span class="hljs-number">0.3917</span>, -<span class="hljs-number">0.1983</span>],<br>         [-<span class="hljs-number">0.2976</span>,  <span class="hljs-number">0.7764</span>, -<span class="hljs-number">0.0074</span>, -<span class="hljs-number">0.1965</span>, -<span class="hljs-number">0.1343</span>, -<span class="hljs-number">0.6683</span>]]],<br>       grad_fn=&lt;StackBackward&gt;)<br></code></pre></td></tr></table></figure><p>input_size: 输入张量x中特征维度的大小.<br>hidden_size: 隐层张量h中特征维度的大小.<br>num_layers: 隐含层的数量.<br>bidirectional: 是否选择使用双向LSTM, 如果为True, 则使用; 默认不使用.<br>input: 输入张量x.<br>h0: 初始化的隐层张量h.<br>c0: 初始化的细胞状态张量c.</p><p>由于内部结构相对较复杂, 因此训练效率在同等算力下较传统RNN低很多.</p><h2 id="GRU模型"><a href="#GRU模型" class="headerlink" title="GRU模型"></a>GRU模型</h2><p>GRU（Gated Recurrent Unit）也称门控循环单元结构, 它也是传统RNN的变体, 同LSTM一样能够有效捕捉长序列之间的语义关联, 缓解梯度消失或爆炸现象. 同时它的结构和计算要比LSTM更简单, 它的核心结构可以分为两个部分去解析:</p><ol><li>更新门</li><li>重置门</li></ol><p><img src="/Pictures/DL/RNN/plot10.png" alt="img"></p><p><img src="/Pictures/DL/RNN/plot11.png" alt="img"></p><p>和之前分析过的LSTM中的门控一样, 首先计算更新门和重置门的门值, 分别是 $z(t)$ 和 $r(t)$<br>计算方法就是使用 $X(t)$ 与 $h(t-1)$ 拼接进行线性变换, 再经过sigmoid激活.<br>之后重置门门值作用在了 $h(t-1)$ 上, 代表控制上一时间步传来的信息有多少可以被利用.<br>接着就是使用这个重置后的 $h(t-1)$ 进行基本的RNN计算, 即与 $x(t)$ 拼接进行线性变化, 经过 $tanh$ 激活, 得到新的 $h(t)$ .<br>最后更新门的门值会作用在新的 $h(t)$ ，而 $1-$ 门值会作用在 $h(t-1)$ 上, 随后将两者的结果相加, 得到最终的隐含状态输出 $h(t)$ , 这个过程意味着更新门有能力保留之前的结果, 当门值趋于1时, 输出就是新的 $h(t)$ , 而当门值趋于0时, 输出就是上一时间步的 $h(t-1)$ .</p><p>使用Pytorch构建GRU模型：通过torch.nn.GRU可调用.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-meta">&gt;&gt;&gt; </span>rnn = nn.GRU(<span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">2</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">input</span> = torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">5</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>h0 = torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">6</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>output, hn = rnn(<span class="hljs-built_in">input</span>, h0)<br><span class="hljs-meta">&gt;&gt;&gt; </span>output<br>tensor([[[-<span class="hljs-number">0.2097</span>, -<span class="hljs-number">2.2225</span>,  <span class="hljs-number">0.6204</span>, -<span class="hljs-number">0.1745</span>, -<span class="hljs-number">0.1749</span>, -<span class="hljs-number">0.0460</span>],<br>         [-<span class="hljs-number">0.3820</span>,  <span class="hljs-number">0.0465</span>, -<span class="hljs-number">0.4798</span>,  <span class="hljs-number">0.6837</span>, -<span class="hljs-number">0.7894</span>,  <span class="hljs-number">0.5173</span>],<br>         [-<span class="hljs-number">0.0184</span>, -<span class="hljs-number">0.2758</span>,  <span class="hljs-number">1.2482</span>,  <span class="hljs-number">0.5514</span>, -<span class="hljs-number">0.9165</span>, -<span class="hljs-number">0.6667</span>]]],<br>       grad_fn=&lt;StackBackward&gt;)<br><span class="hljs-meta">&gt;&gt;&gt; </span>hn<br>tensor([[[ <span class="hljs-number">0.6578</span>, -<span class="hljs-number">0.4226</span>, -<span class="hljs-number">0.2129</span>, -<span class="hljs-number">0.3785</span>,  <span class="hljs-number">0.5070</span>,  <span class="hljs-number">0.4338</span>],<br>         [-<span class="hljs-number">0.5072</span>,  <span class="hljs-number">0.5948</span>,  <span class="hljs-number">0.8083</span>,  <span class="hljs-number">0.4618</span>,  <span class="hljs-number">0.1629</span>, -<span class="hljs-number">0.1591</span>],<br>         [ <span class="hljs-number">0.2430</span>, -<span class="hljs-number">0.4981</span>,  <span class="hljs-number">0.3846</span>, -<span class="hljs-number">0.4252</span>,  <span class="hljs-number">0.7191</span>,  <span class="hljs-number">0.5420</span>]],<br><br>        [[-<span class="hljs-number">0.2097</span>, -<span class="hljs-number">2.2225</span>,  <span class="hljs-number">0.6204</span>, -<span class="hljs-number">0.1745</span>, -<span class="hljs-number">0.1749</span>, -<span class="hljs-number">0.0460</span>],<br>         [-<span class="hljs-number">0.3820</span>,  <span class="hljs-number">0.0465</span>, -<span class="hljs-number">0.4798</span>,  <span class="hljs-number">0.6837</span>, -<span class="hljs-number">0.7894</span>,  <span class="hljs-number">0.5173</span>],<br>         [-<span class="hljs-number">0.0184</span>, -<span class="hljs-number">0.2758</span>,  <span class="hljs-number">1.2482</span>,  <span class="hljs-number">0.5514</span>, -<span class="hljs-number">0.9165</span>, -<span class="hljs-number">0.6667</span>]]],<br>       grad_fn=&lt;StackBackward&gt;)<br></code></pre></td></tr></table></figure><p>GRU和LSTM作用相同, 在捕捉长序列语义关联时, 能有效抑制梯度消失或爆炸, 效果都优于传统RNN且计算复杂度相比LSTM要小.</p><p>但GRU仍然不能完全解决梯度消失问题, 同时其作用RNN的变体, 有着RNN结构本身的一大弊端, 即不可并行计算, 这在数据量和模型体量逐步增大的未来, 是RNN发展的关键瓶颈.</p><hr><p>参考：</p><ol><li><a href="http://121.199.45.168:13008/03_mkdocs_RNN/4%20GRU%E6%A8%A1%E5%9E%8B.html">http://121.199.45.168:13008/03_mkdocs_RNN/4%20GRU%E6%A8%A1%E5%9E%8B.html</a></li><li><a href="https://zhuanlan.zhihu.com/p/30844905">https://zhuanlan.zhihu.com/p/30844905</a></li><li><a href="http://121.199.45.168:13008/03_mkdocs_RNN/3%20LSTM%E6%A8%A1%E5%9E%8B.html">http://121.199.45.168:13008/03_mkdocs_RNN/3%20LSTM%E6%A8%A1%E5%9E%8B.html</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Fabulous の CS~61b 奇妙⭐冒险记</title>
    <link href="/2024/02/29/CS61B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <url>/2024/02/29/CS61B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="Testing"><a href="#Testing" class="headerlink" title="Testing"></a>Testing</h1><p>在工程中，为自己编写UnitTest时刻检测代码的正确性是十分重要且必要的。</p><p>假设我们现在有这样一个类，它实现对一个int类型的数组进行排序：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Sort</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">swap</span><span class="hljs-params">(<span class="hljs-type">int</span>[] arr, <span class="hljs-type">int</span> i, <span class="hljs-type">int</span> j)</span> &#123;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">tmp</span> <span class="hljs-operator">=</span> arr[i];<br>        arr[i] = arr[j];<br>        arr[j] = tmp;<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">sort</span><span class="hljs-params">(<span class="hljs-type">int</span>[] x)</span> &#123;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">minIndex</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; x.length - <span class="hljs-number">1</span>; i++) &#123;<br>            minIndex = i;<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">j</span> <span class="hljs-operator">=</span> i + <span class="hljs-number">1</span>; j &lt; x.length; j++) &#123;<br>                <span class="hljs-keyword">if</span> (x[j] &lt; x[minIndex]) &#123;<br>                    minIndex = j;<br>                &#125;<br>            &#125;<br>            swap(x, i, minIndex);<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>我们可以编写一个SortTest类，来测试排序是否满足要求，假设我们要求将数组升序排序：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">TestSort</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">testsort</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-type">boolean</span> <span class="hljs-variable">isSuccess</span> <span class="hljs-operator">=</span> <span class="hljs-literal">true</span>;<br>        <span class="hljs-type">int</span>[] input = &#123;<span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">7</span>, <span class="hljs-number">2</span>, <span class="hljs-number">6</span>, <span class="hljs-number">3</span>, <span class="hljs-number">8</span>&#125;;<br>        <span class="hljs-type">int</span>[] expected = &#123;<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>&#125;;<br>        Sort.sort(input);<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; input.length; i +=<span class="hljs-number">1</span>)<br>        &#123;<br>            <span class="hljs-keyword">if</span> (!(input[i] == expected[i]))<br>            &#123;<br>                System.out.println(<span class="hljs-string">&quot;Mismatch in position &quot;</span> + i + <span class="hljs-string">&quot;, expected: &quot;</span> + expected[i] + <span class="hljs-string">&quot;, but got: &quot;</span> + input[i] + <span class="hljs-string">&quot;.&quot;</span>);<br>                isSuccess = <span class="hljs-literal">false</span>;<br>                <span class="hljs-keyword">break</span>;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">if</span>(isSuccess)<br>        &#123;<br>            System.out.println(<span class="hljs-string">&quot;Success!No case failed!&quot;</span>);<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> &#123;<br>        testsort();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>这是一种近乎最原始的测试方式，但是可以直接有效的测试我们代码的可行性。</p><h2 id="JUnit-Testing"><a href="#JUnit-Testing" class="headerlink" title="JUnit Testing"></a>JUnit Testing</h2><p>org.junit 库提供了许多有用的方法和有用的功能来简化测试的编写。例如，我们可以将上面的简单临时测试替换为：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">testSort</span><span class="hljs-params">()</span> &#123;<br>    <span class="hljs-type">int</span>[] input = &#123;<span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">7</span>, <span class="hljs-number">2</span>, <span class="hljs-number">6</span>, <span class="hljs-number">3</span>, <span class="hljs-number">8</span>&#125;;<br>    <span class="hljs-type">int</span>[] expected = &#123;<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>&#125;;<br>    Sort.sort(input);<br>    org.junit.Assert.assertArrayEquals(expected, input);<br>&#125;<br></code></pre></td></tr></table></figure><p>此方法测试 expected 和 actual 是否相等，如果不相等，则终止程序并显示详细错误消息。</p><h1 id="Lists"><a href="#Lists" class="headerlink" title="Lists"></a>Lists</h1><h2 id="The-Mystery-of-the-Walrus"><a href="#The-Mystery-of-the-Walrus" class="headerlink" title="The Mystery of the Walrus"></a>The Mystery of the Walrus</h2><p>现在有两段代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-type">Walrus</span> <span class="hljs-variable">a</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Walrus</span>(<span class="hljs-number">1000</span>, <span class="hljs-number">8.3</span>);<br>Walrus b;<br>b = a;<br>b.weight = <span class="hljs-number">5</span>;<br>System.out.println(a);<br>System.out.println(b);<br><br><span class="hljs-type">int</span> <span class="hljs-variable">x</span> <span class="hljs-operator">=</span> <span class="hljs-number">5</span>;<br><span class="hljs-type">int</span> y;<br>y = x;<br>x = <span class="hljs-number">2</span>;<br>System.out.println(<span class="hljs-string">&quot;x is: &quot;</span> + x);<br>System.out.println(<span class="hljs-string">&quot;y is: &quot;</span> + y);<br></code></pre></td></tr></table></figure><p>对于第一段代码，我们输出结果能够发现a与b指向了同一个对象，而在第二段代码中，x和y却是不同的数值。</p><p>在java中，声明变量（基础类型的8种）并不会进行初始化。</p><p>这就意味着，如果有这样一行代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-type">int</span> x;<br></code></pre></td></tr></table></figure><p>如果不对x进行赋值，我们将无法使用变量x，即未完成实例化。</p><p>除开基础类型以外，其他的所有内容（包括数组）都不是原始类型，而是reference type。</p><p>当我们声明任何引用类型时，Java都会分配一个64bits的空间，无论对象是什么类型。</p><p>关键字new会将创建出的对象实例的<strong>地址</strong>传给左侧声明的对象。</p><p>赋值符号 “&#x3D;”  表示将右侧变量的bits传给左侧对象。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-type">Dog</span> <span class="hljs-variable">a</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Dog</span>(<span class="hljs-number">10</span>);<br><span class="hljs-type">Dog</span> <span class="hljs-variable">b</span> <span class="hljs-operator">=</span> a;<br></code></pre></td></tr></table></figure><p>第一行表示声明一个Dog变量a，创建一个“10”的Dog实例并将其的地址传递给a，所以第二行表示将此实例的地址同样的拷贝传递给b，因此a和b实际上指向同一实例。</p><p>也就是说，对于基础类型，Java采用值传递的方式；而对于引用类型（reference type），Java采用引用传递的类型，这导致传递之后两个变量实际上指向同一个地址。</p><p>如上所述，储存数组的变量也是一种引用类型。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-type">int</span>[] x;<br>x = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[]&#123;<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>&#125;;<br>x = <span class="hljs-literal">null</span>;<br></code></pre></td></tr></table></figure><p>第一行声明了一个int类型的数组x，但是并没有进行初始化，也就是说x内部为null。第二行则是创建了一个实例并将其绑定到数组x上，但是当第三行执行完毕后，我们将永远丢失数组{1, 2, 3}。</p><h2 id="First-taste-of-IntLists"><a href="#First-taste-of-IntLists" class="headerlink" title="First taste of IntLists"></a>First taste of IntLists</h2><p>我们可以尝试构建一个自己的int链表，包括获取大小、获取数据方法的实现（我最喜欢recursion了，我爱说实话）：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">IntList</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> first;<br>    <span class="hljs-keyword">public</span> Intlist rest;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">IntList</span><span class="hljs-params">(<span class="hljs-type">int</span> f, IntList r)</span> &#123;<br>        first = f;<br>        rest = r;<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">size</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">if</span>(rest == <span class="hljs-literal">null</span>) &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> + <span class="hljs-built_in">this</span>.rest.size()<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">get</span><span class="hljs-params">(<span class="hljs-type">int</span> i)</span> &#123;<br>        <span class="hljs-keyword">if</span> (i == <span class="hljs-number">0</span>) &#123;<br>            <span class="hljs-keyword">return</span> first;<br>        &#125;<br>        <span class="hljs-keyword">return</span> rest.get(i-<span class="hljs-number">1</span>);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="The-SLList"><a href="#The-SLList" class="headerlink" title="The SLList"></a>The SLList</h2><p>在上面的链表实现中，用户可以直接看到内部的数据结构，这种 <em>naked</em> 的效果显然不是我们所期待的。</p><p>因此，我们将链表再次包装一层，避免裸露的数据结构，形成嵌套结构。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">IntNode</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> item;<br>    <span class="hljs-keyword">public</span> IntNode next;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">IntNode</span><span class="hljs-params">(<span class="hljs-type">int</span> i, IntNode n)</span> &#123;<br>        item = i;<br>        next = n;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>之后，我们创建一个名为 <em>SLList</em> 的单独类，用户将与之交互。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">SLList</span> &#123;<br>    <span class="hljs-keyword">public</span> IntNode first;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">SLList</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span> &#123;<br>        first = <span class="hljs-keyword">new</span> <span class="hljs-title class_">IntNode</span>(x, <span class="hljs-literal">null</span>);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>接下来是一些基础方法的实现，包括：addFirst, getFirst, addLast, size</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">SLList</span> &#123;<br>    <span class="hljs-keyword">private</span> IntNode first;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">SLList</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span> &#123;<br>        first = <span class="hljs-keyword">new</span> <span class="hljs-title class_">IntNode</span>(x, <span class="hljs-literal">null</span>);<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">addFirst</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span> &#123;<br>        first = <span class="hljs-keyword">new</span> <span class="hljs-title class_">IntNode</span>(x, first);<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">getFirst</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">return</span> first.item;<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">addLast</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span> &#123;<br>        <span class="hljs-type">IntNode</span> <span class="hljs-variable">p</span> <span class="hljs-operator">=</span> first;<br>        <span class="hljs-keyword">while</span>(p.next != <span class="hljs-literal">null</span>) &#123;<br>            p = p.next;<br>        &#125;<br>        p.next = <span class="hljs-keyword">new</span> <span class="hljs-title class_">IntNode</span>(x, <span class="hljs-literal">null</span>);<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">size</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-type">IntNode</span> <span class="hljs-variable">p</span> <span class="hljs-operator">=</span> first;<br>        <span class="hljs-keyword">if</span>(p.next == <span class="hljs-literal">null</span>) &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;<br>        &#125;<br>        p = p.next;<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> + p.size();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>直观比较两个数据结构的区别：</p><p><img src="/Pictures/CS61b/02/IntList_vs_SLList.png" alt="img"></p><p>本质上，SLList 类充当列表用户和裸递归数据结构之间的中间人。正如上面在 IntList 版本中所建议的，IntList 用户可能拥有指向 IntList 中间的变量。进一步，我们还可以将属性改为<em>private</em>。</p><h3 id="Nested-Classes"><a href="#Nested-Classes" class="headerlink" title="Nested Classes"></a>Nested Classes</h3><p>对于SLList而言，IntNode是其中的嵌套类。</p><p>这种嵌套关系我们一般称之为 <em>“has-a”</em> 关系。</p><p>如果嵌套类不需要使用SLList的任何实例方法或变量，则可以声明为 <em>static</em> ，这意味着静态类中的方法无法访问封闭类的任何成员，节省内存。</p><h3 id="Improvement"><a href="#Improvement" class="headerlink" title="Improvement"></a>Improvement</h3><p>对 <em>size()</em> 方法进行分析，我们不难发现时间复杂度为 <em>O(n)</em> 。对于较大的列表来说，时间较长，所以我们考虑直接添加一个变量来跟踪当前链表的长度，这样时间复杂度变为了 *O(1)*。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs java">...<br><span class="hljs-keyword">private</span> <span class="hljs-type">int</span> size;<br><br><span class="hljs-keyword">public</span> <span class="hljs-title function_">SLList</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span> &#123;<br>    ...<br>    size = <span class="hljs-number">1</span>;<br>&#125;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">addFirst</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span> &#123;<br>    ...<br>    size += <span class="hljs-number">1</span>;<br>&#125;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">addLast</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span> &#123;<br>    ...<br>    size += <span class="hljs-number">1</span>;<br>&#125;<br><br><span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">size</span><span class="hljs-params">()</span> &#123;<br>    <span class="hljs-keyword">return</span> size;<br>&#125;<br></code></pre></td></tr></table></figure><p>此外，我们发现初始创建空链表时，对其进行addLast方法会导致错误，这是因为 first 是 null ，因此尝试访问下面 while (p.next !&#x3D; null) 中的 p.next 会导致空指针异常。</p><p>我们考虑加入不变的头节点(head)，在此课程中称为 <em>Sentinel Node</em> 。</p><p>重构之后的代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">SLList</span> &#123;<br>    <span class="hljs-keyword">private</span> <span class="hljs-type">int</span> size;<br>    <span class="hljs-keyword">private</span> IntNode sentinel;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">SLList</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span> &#123;<br>        sentinel = IntNode(<span class="hljs-number">10</span>, <span class="hljs-literal">null</span>);<br>        sentinel.next = <span class="hljs-keyword">new</span> <span class="hljs-title class_">IntNode</span>(x, <span class="hljs-literal">null</span>);<br>        size = <span class="hljs-number">1</span>;<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">SLList</span><span class="hljs-params">()</span> &#123;<br>        sentinel = IntNode(<span class="hljs-number">10</span>, <span class="hljs-literal">null</span>);<br>        size = <span class="hljs-number">0</span>;<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">addFirst</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span> &#123;<br>        sentinel.next = <span class="hljs-keyword">new</span> <span class="hljs-title class_">IntNode</span>(x, first);<br>        size += <span class="hljs-number">1</span>;<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">getFirst</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">return</span> sentinel.next.item;<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">addLast</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span> &#123;<br>        <span class="hljs-type">IntNode</span> <span class="hljs-variable">p</span> <span class="hljs-operator">=</span> sentinel.next;<br>        <span class="hljs-keyword">while</span>(p.next != <span class="hljs-literal">null</span>) &#123;<br>            p = p.next;<br>        &#125;<br>        p.next = <span class="hljs-keyword">new</span> <span class="hljs-title class_">IntNode</span>(x, <span class="hljs-literal">null</span>);<br>        size += <span class="hljs-number">1</span>;<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">size</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">return</span> size;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="The-DLList"><a href="#The-DLList" class="headerlink" title="The DLList"></a>The DLList</h2><p>对于SLList来说，向前搜索是十分困难的，当我们想获取最后一个节点时，不可避免的需要遍历整个链表。</p><p>因此我们考虑构造双向链表，每个节点都保存了前一个节点和后一个节点的信息。</p><p>主要有两种实现方式：循环链表(单个sentinel)和双向链表(双sentinel)。</p><p><img src="/Pictures/CS61b/02/dllist_circular_sentinel_size_2.png" alt="img"></p><p><img src="/Pictures/CS61b/02/dllist_double_sentinel_size_2.png" alt="img"></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">DLList</span> &#123;<br>    <span class="hljs-keyword">private</span> IntNode sentinel;<br>    <span class="hljs-keyword">private</span> <span class="hljs-type">int</span> size;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">IntNode</span> &#123;<br>        <span class="hljs-keyword">public</span> IntNode prev;<br>        <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> item;<br>        <span class="hljs-keyword">public</span> IntNode next;<br>        ...<br>    &#125;<br>    ...<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="First-try-of-Generic-Model"><a href="#First-try-of-Generic-Model" class="headerlink" title="First try of Generic Model"></a>First try of Generic Model</h3><p>在Java中，我们可以通过泛型编程来实现对不同数据类型数据的存储。</p><p>基本语法是：在类声明中的类名之后，在尖括号内使用任意占位符 &lt;&gt; ,然后在任何使用任意类型的地方都使用该占位符。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">DLList</span>&lt;TypeName&gt; &#123;<br>    <span class="hljs-keyword">private</span> IntNode sentinel;<br>    <span class="hljs-keyword">private</span> <span class="hljs-type">int</span> size;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">IntNode</span> &#123;<br>        <span class="hljs-keyword">public</span> IntNode prev;<br>        <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> item;<br>        <span class="hljs-keyword">public</span> IntNode next;<br>        ...<br>    &#125;<br>    ...<br>&#125;<br></code></pre></td></tr></table></figure><p>在实例化时，需要指明类型名。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs java">DLList&lt;String&gt; d2 = <span class="hljs-keyword">new</span> <span class="hljs-title class_">DLList</span>&lt;&gt;(<span class="hljs-string">&quot;hello&quot;</span>);<br>d2.addLast(<span class="hljs-string">&quot;world&quot;</span>);<br></code></pre></td></tr></table></figure><h2 id="Arrays"><a href="#Arrays" class="headerlink" title="Arrays"></a>Arrays</h2><p>创建数组有三种有效的方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-type">int</span>[] x = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[<span class="hljs-number">3</span>];    <span class="hljs-comment">//x = &#123;0, 0, 0&#125;</span><br><span class="hljs-type">int</span>[] y = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[]&#123;<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>&#125;;<br><span class="hljs-type">int</span>[] z = &#123;<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>&#125;;<br></code></pre></td></tr></table></figure><p>Java中内置了一些与数组操作相关的方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-type">int</span>[] x = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[<span class="hljs-number">3</span>];<br><span class="hljs-type">int</span> <span class="hljs-variable">len</span> <span class="hljs-operator">=</span> x.lenght;    <span class="hljs-comment">//获取长度</span><br><span class="hljs-type">int</span>[] b = &#123;<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>&#125;;<br>System.arraycopy(b,<span class="hljs-number">0</span>,x,<span class="hljs-number">3</span>,<span class="hljs-number">2</span>);    <br><span class="hljs-comment">/**复制数组，参数为源数组、开始坐标、目标数组、开始坐标、个数</span><br><span class="hljs-comment">等同于Python中的 x[3:5]=b[0:2]*/</span><br></code></pre></td></tr></table></figure><p>在Java中，多维数组中的每个子数组可以有不同的长度。这种情况下，这些数组被称为不规则多维数组。Java中的多维数组实际上是数组的数组，因此每个子数组可以独立地具有不同的长度。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs java">pascalsTriangle = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[<span class="hljs-number">4</span>][];<br>pascalsTriangle[<span class="hljs-number">0</span>] = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[]&#123;<span class="hljs-number">1</span>&#125;;<br>pascalsTriangle[<span class="hljs-number">1</span>] = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[]&#123;<span class="hljs-number">1</span>, <span class="hljs-number">1</span>&#125;;<br>pascalsTriangle[<span class="hljs-number">2</span>] = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[]&#123;<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>&#125;;<br>pascalsTriangle[<span class="hljs-number">3</span>] = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[]&#123;<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>&#125;;<br></code></pre></td></tr></table></figure><h2 id="The-AList"><a href="#The-AList" class="headerlink" title="The AList"></a>The AList</h2><p>对于链表来说，获取第i个节点元素需要从前向后遍历i次，这说明时间复杂度为 <em>O(n)</em> 。而在现代计算机上访问数组的第i个元素所需要的时间是恒定的，即 <em>O(1)</em> 。</p><p>A naive solution:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">AList</span>&lt;T&gt; &#123;<br>    <span class="hljs-keyword">private</span> T[] items;<br>    <span class="hljs-keyword">private</span> <span class="hljs-type">int</span> size;<br><br>    <span class="hljs-comment">/** Creates an empty list. */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">AList</span><span class="hljs-params">()</span> &#123;<br>        items = (T []) <span class="hljs-keyword">new</span> <span class="hljs-title class_">Object</span>[<span class="hljs-number">100</span>];<br>        size = <span class="hljs-number">0</span>;<br>    &#125;<br><br>    <span class="hljs-comment">/** Inserts X into the back of the list. */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">addLast</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span> &#123;<br>        items[size] = x;<br>        size = size + <span class="hljs-number">1</span>;<br>    &#125;<br><br>    <span class="hljs-comment">/** Returns the item from the back of the list. */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">getLast</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">return</span> items[size - <span class="hljs-number">1</span>];<br>    &#125;<br>    <span class="hljs-comment">/** Gets the ith item in the list (0 is the front). */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">get</span><span class="hljs-params">(<span class="hljs-type">int</span> i)</span> &#123;<br>        <span class="hljs-keyword">return</span> items[i];<br>    &#125;<br><br>    <span class="hljs-comment">/** Returns the number of items in the list. */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">size</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">return</span> size;<br>    &#125;<br><br>    <span class="hljs-comment">/** Deletes item from back of the list and</span><br><span class="hljs-comment">      * returns deleted item. */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">removeLast</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">x</span> <span class="hljs-operator">=</span> getLast();<br>        size = size - <span class="hljs-number">1</span>;<br>        <span class="hljs-keyword">return</span> x;<br>    &#125;<br>&#125; <br></code></pre></td></tr></table></figure><p>对于这个方案，我们不难发现：数组的大小在一开始便固定下来了，这会导致我们在使用的过程中总会有空间浪费或空间不足的情况出现。</p><p>考虑性能，我们采用算法计算出最优化的数组大小并动态更新。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">resize</span><span class="hljs-params">(<span class="hljs-type">int</span> capacity)</span> &#123;<br>    T[] tmp = (T []) <span class="hljs-keyword">new</span> <span class="hljs-title class_">Object</span>[capacity];<br>    System.arraycopy(items,<span class="hljs-number">0</span>,tmp,<span class="hljs-number">0</span>,size);<br>    items = tmp;<br>&#125;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">insertBack</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span> &#123;<br>    <span class="hljs-keyword">if</span> (size == items.length) &#123;<br>        resize(size * RFACTOR);<br>    &#125;<br>    items[size] = x;<br>    size += <span class="hljs-number">1</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h1 id="Inheritance-Implements"><a href="#Inheritance-Implements" class="headerlink" title="Inheritance &amp; Implements"></a>Inheritance &amp; Implements</h1><h2 id="Hypernyms-Hyponyms-and-Interfaces-Inheritance"><a href="#Hypernyms-Hyponyms-and-Interfaces-Inheritance" class="headerlink" title="Hypernyms, Hyponyms, and Interfaces Inheritance"></a>Hypernyms, Hyponyms, and Interfaces Inheritance</h2><p>具有 <em>“is-a”</em> 关系的词语之间互相为上位词与下位词。</p><p>例如：狗是贵宾犬、雪橇犬、哈士奇等的上位词。相反，贵宾犬、雪橇犬和哈士奇是狗的下位词。</p><p>换种说法，贵宾犬、雪橇犬、哈士奇都是狗的子类，而狗是贵宾犬、雪橇犬、哈士奇等的超类。</p><p>在Java中，为了表达这种层次结构，我们需要做两件事：</p><ol><li>定义上位词的类型</li><li>指定下位词</li></ol><p>我们定义出来的上位词类型便是所谓的接口（interface），它本质上只定义类所需要的功能，并不提供具体的实现方法，这一点可以看作C++中的抽象基类。</p><p>如果我们为之前创建的列表定义一个接口，那么应该是这样的：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">interface</span> <span class="hljs-title class_">List61B</span>&lt;Item&gt; &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">addFirst</span><span class="hljs-params">(Item x)</span>;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">addLast</span><span class="hljs-params">(Item y)</span>;<br>    <span class="hljs-keyword">public</span> Item <span class="hljs-title function_">getFirst</span><span class="hljs-params">()</span>;<br>    <span class="hljs-keyword">public</span> Item <span class="hljs-title function_">getLast</span><span class="hljs-params">()</span>;<br>    <span class="hljs-keyword">public</span> Item <span class="hljs-title function_">removeLast</span><span class="hljs-params">()</span>;<br>    <span class="hljs-keyword">public</span> Item <span class="hljs-title function_">get</span><span class="hljs-params">(<span class="hljs-type">int</span> i)</span>;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">insert</span><span class="hljs-params">(Item x, <span class="hljs-type">int</span> position)</span>;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">size</span><span class="hljs-params">()</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>接下来，我们把AList和SLList指定为List61B的下位词，需要用到 <em>implement</em> 关键字：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">AList</span>&lt;Item&gt; <span class="hljs-keyword">implements</span> <span class="hljs-title class_">List61B</span>&lt;Item&gt; &#123;<br>    ...<br>&#125;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">SLList</span>&lt;Item&gt; <span class="hljs-keyword">implements</span> <span class="hljs-title class_">List61B</span>&lt;Item&gt; &#123;<br>    ...<br>&#125;<br></code></pre></td></tr></table></figure><p>由于在接口中，我们仅仅声明了类中所包含的一些方法，并没有给出具体的实现过程，因此在子类中，我们需要对函数进行重写覆盖。在子类中实现所需的函数时，在方法签名的顶部包含 <em>@Override</em> 标记很有用。实际上，即使不包含标签，我们依旧在进行重写（Overriding）。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">addFirst</span><span class="hljs-params">(Item x)</span> &#123;<br>    insert(x, <span class="hljs-number">0</span>);<br>&#125;<br></code></pre></td></tr></table></figure><p>和C++中一样，在Java中，接口类型的对象可以接受子类的对象。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> &#123;<br>    List61B&lt;String&gt; someList = <span class="hljs-keyword">new</span> <span class="hljs-title class_">SLList</span>&lt;String&gt;();<br>    someList.addFirst(<span class="hljs-string">&quot;elk&quot;</span>);<br>&#125;<br></code></pre></td></tr></table></figure><p>当它运行时，SLList 被创建，它的地址存储在 someList 变量中。然后字符串“elk”被插入到addFirst引用的SLList中。</p><p>在interface中，我们仅仅定义了方法头但并没有具体的实现。如果我们需要在接口中进行函数的实现并继承到子类中，我们可以在函数前加上 <em>default</em> 关键字。如果子类中没有重写，则会调用default方法，如果子类进行了重写，则会使用子类中的重写方法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">default</span> <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">print</span><span class="hljs-params">()</span> &#123;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; size(); i += <span class="hljs-number">1</span>) &#123;<br>        System.out.print(get(i) + <span class="hljs-string">&quot; &quot;</span>);<br>    &#125;<br>    System.out.println();<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="Interface-Inheritance-vs-Implementation-Inheritance"><a href="#Interface-Inheritance-vs-Implementation-Inheritance" class="headerlink" title="Interface Inheritance vs Implementation Inheritance"></a>Interface Inheritance vs Implementation Inheritance</h3><ul><li>Interface Inheritance（接口继承）：<br>接口继承是通过接口来定义的，一个接口可以扩展另一个接口。<br>通过接口继承，子接口可以继承父接口的抽象方法，但不继承任何具体的实现。<br>子接口可以定义新的抽象方法，或者通过默认方法提供方法的默认实现。<br>类实现一个接口时，必须提供接口中所有抽象方法的实现。</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">interface</span> <span class="hljs-title class_">Animal</span> &#123;<br>    <span class="hljs-keyword">void</span> <span class="hljs-title function_">eat</span><span class="hljs-params">()</span>;<br>&#125;<br><br><span class="hljs-keyword">interface</span> <span class="hljs-title class_">Mammal</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">Animal</span> &#123;<br>    <span class="hljs-keyword">void</span> <span class="hljs-title function_">sleep</span><span class="hljs-params">()</span>;<br>&#125;<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Dog</span> <span class="hljs-keyword">implements</span> <span class="hljs-title class_">Mammal</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">eat</span><span class="hljs-params">()</span> &#123;<br>        System.out.println(<span class="hljs-string">&quot;Dog is eating&quot;</span>);<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">sleep</span><span class="hljs-params">()</span> &#123;<br>        System.out.println(<span class="hljs-string">&quot;Dog is sleeping&quot;</span>);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>Implementation Inheritance（实现继承）：<br>实现继承是通过类来定义的，一个类可以继承另一个类。<br>通过实现继承，子类继承了父类的所有属性和方法，包括具体的实现。<br>子类可以通过方法重写（override）来改变或扩展父类的方法的行为。<br>Java中一个类只能继承一个父类，即使是多重继承也只能通过接口实现。</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Shape</span> &#123;<br>    <span class="hljs-keyword">void</span> <span class="hljs-title function_">draw</span><span class="hljs-params">()</span> &#123;<br>        System.out.println(<span class="hljs-string">&quot;Drawing shape&quot;</span>);<br>    &#125;<br>&#125;<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Circle</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">Shape</span> &#123;<br>    <span class="hljs-keyword">void</span> <span class="hljs-title function_">draw</span><span class="hljs-params">()</span> &#123;<br>        System.out.println(<span class="hljs-string">&quot;Drawing circle&quot;</span>);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="Externs-Casting-Higher-Order-Functions"><a href="#Externs-Casting-Higher-Order-Functions" class="headerlink" title="Externs, Casting, Higher Order Functions"></a>Externs, Casting, Higher Order Functions</h2><p>我们使用 <em>implements</em> 关键字定义了类与接口之间的关系，对于类和类之间、接口与接口之间的继承关系，我们可以使用关键字 <em>extends</em> 进行定义。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">RotatingSLList</span>&lt;Item&gt; <span class="hljs-keyword">extends</span> <span class="hljs-title class_">SLList</span>&lt;Item&gt;&#123;&#125;<br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">VengefulSLList</span>&lt;Item&gt; <span class="hljs-keyword">extends</span> <span class="hljs-title class_">SLList</span>&lt;Item&gt;&#123;&#125;<br></code></pre></td></tr></table></figure><p>子类可以继承父类中的所有实例和静态变量，所有方法以及所有嵌套类。注意构造函数不是继承的，私有成员不能被子类直接访问。</p><p>虽然构造函数不是继承的，但 Java 要求所有构造函数都必须从调用其超类的构造函数之一开始。如果我们选择不这样做，Java 将自动为我们调用超类的<strong>无参构造函数</strong>。请注意，如果super class中的构造函数是有参的，那么要求在子类中显式地调用此构造函数。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-title function_">VengefulSLList</span><span class="hljs-params">()</span> &#123;<br>    <span class="hljs-built_in">super</span>();<br>    deletedItems = <span class="hljs-keyword">new</span> <span class="hljs-title class_">SLList</span>&lt;Item&gt;();<br>&#125;<br></code></pre></td></tr></table></figure><p>Java 中的每个类都是 <strong>Object</strong> 类或 <strong>extends Object</strong> 类的后代。即使类中没有显式 extends 的类仍然隐式扩展 <strong>Object</strong> 类。</p><p>Object 类提供了每个 Object 都应该能够执行的操作，例如 <em>.equals(Object obj)</em> 、 <em>.hashCode()</em> 和 <em>toString()</em> 。</p><p>有界类型参数：<br>在Java中，有界类型参数（bounded type parameters）是指在泛型类或泛型方法中对类型参数进行限制，使其必须是某种特定类型或其子类型。有界类型参数通常用于提高泛型的灵活性和安全性。</p><p>有界类型参数有两种：上界限定（upper bounded）和下界限定（lower bounded）。</p><ol><li>上界限定：使用 extends 关键字指定类型参数必须是某个类或接口的子类。例如：</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Myclass</span>&lt;T <span class="hljs-keyword">extends</span> <span class="hljs-title class_">Number</span>&gt; &#123;<br>    ...<br>&#125;<br></code></pre></td></tr></table></figure><div class="note note-info">            <p>在这个例子中，类型参数 T 必须是 Number 类或其子类，这意味着可以传递 Integer、Double、Float 等类型作为 T。</p>          </div><ol start="2"><li>下界限定：使用 super 关键字指定类型参数必须是某个类的超类。例如：</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyClass</span>&lt;T <span class="hljs-built_in">super</span> Integer&gt; &#123;<br>    ...<br>&#125;<br></code></pre></td></tr></table></figure><div class="note note-info">            <p>在这个例子中，类型参数 T 必须是 Number 类或其子类，这意味着可以传递 Integer、Double、Float 等类型作为 T。</p>          </div><h3 id="Encapsulation"><a href="#Encapsulation" class="headerlink" title="Encapsulation"></a>Encapsulation</h3><p>在编写代码的过程中，维持代码的 <em>Abstraction Barriers</em> 是非常重要的！（梦回61a）</p><p>在Java中，我们可以轻易地实现抽象障碍，比如使用private关键字。</p><p>但是继承可以破坏这种封装。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">bark</span><span class="hljs-params">()</span> &#123;<br>    barkMany(<span class="hljs-number">1</span>);<br>&#125;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">barkMany</span><span class="hljs-params">(<span class="hljs-type">int</span> N)</span> &#123;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; N; i += <span class="hljs-number">1</span>) &#123;<br>        System.out.println(<span class="hljs-string">&quot;bark&quot;</span>);<br>    &#125;<br>&#125;<br><br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">barkMany</span><span class="hljs-params">(<span class="hljs-type">int</span> N)</span> &#123;<br>    System.out.println(<span class="hljs-string">&quot;As a dog, I say: &quot;</span>);<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; N; i += <span class="hljs-number">1</span>) &#123;<br>        bark();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>前两个是基类，第三个则是子类中的部分。</p><p>调用子类中的函数，程序陷入无限循环。对 bark() 的调用将调用 barkMany(1) ，后者又调用 bark() ，无限次地重复该过程。</p><h3 id="Casting"><a href="#Casting" class="headerlink" title="Casting"></a>Casting</h3><p>Java 有一种特殊的语法，您可以告诉编译器特定的表达式具有特定的编译时类型。</p><p>例如，我们有下面这个类：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">A</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">A</span><span class="hljs-params">()</span> &#123;&#125;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">dosomething</span><span class="hljs-params">()</span> &#123;&#125;<br>    <span class="hljs-keyword">public</span> A <span class="hljs-title function_">func</span><span class="hljs-params">(A a)</span> &#123;<span class="hljs-keyword">return</span> a;&#125;<br>&#125;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">B</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">A</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">B</span><span class="hljs-params">()</span> &#123;&#125;<br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">dosometing</span><span class="hljs-params">()</span> &#123;<br>        System.out.println(<span class="hljs-string">&quot;Haha!&quot;</span>)<br>    &#125;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">donothing</span><span class="hljs-params">()</span> &#123;&#125;<br>    <span class="hljs-keyword">public</span> B <span class="hljs-title function_">func</span><span class="hljs-params">(B b)</span> &#123;<span class="hljs-keyword">return</span> b;&#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> &#123;<br>        <span class="hljs-type">B</span> <span class="hljs-variable">testb</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">B</span>();<br>        <span class="hljs-type">A</span> <span class="hljs-variable">testa</span> <span class="hljs-operator">=</span> testb;<br>        testa.dosomething();<br>        testa.donothing();<br>        <span class="hljs-type">B</span> <span class="hljs-variable">b</span> <span class="hljs-operator">=</span> testa.func(testb);<br><br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>根据动态方法选择，调用dosomething时，检测到子类重写了这个方法，所以testa执行B中的dosomething函数。但编译器根据对象的静态类型确定某些内容是否有效，A中并没有donothing，所以会出错。</p><p>同样，func返回的是A类对象，不能用子类B类的对象直接接收。</p><p>我们使用casting解决。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-type">B</span> <span class="hljs-variable">b</span> <span class="hljs-operator">=</span> (B) testa.func(testb);<br></code></pre></td></tr></table></figure><h3 id="Higher-Order-Function"><a href="#Higher-Order-Function" class="headerlink" title="Higher Order Function"></a>Higher Order Function</h3><p>Python中，高阶函数是一个很有用的工具</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">tenX</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">10</span>*x<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">do_twice</span>(<span class="hljs-params">f,x</span>):<br>    <span class="hljs-keyword">return</span> f(f(x))<br></code></pre></td></tr></table></figure><p>在Java中，我们可以利用接口继承实现高阶函数：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">interface</span> <span class="hljs-title class_">IntUnaryFunction</span> &#123;<br>    <span class="hljs-type">int</span> <span class="hljs-title function_">apply</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span>;<br>&#125;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">tenX</span> <span class="hljs-keyword">implements</span> <span class="hljs-title class_">IntUnaryFunction</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">apply</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">10</span> * x;<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">do_twice</span><span class="hljs-params">(IntUnaryFunction f, <span class="hljs-type">int</span> x)</span> &#123;<br>        <span class="hljs-keyword">return</span> f.apply(f.apply(x));<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>有点类似于函数对象（谓词，伪函数）的实现。</p><h2 id="Subtype-Polymorphism"><a href="#Subtype-Polymorphism" class="headerlink" title="Subtype Polymorphism"></a>Subtype Polymorphism</h2><p>在Java中，多态性是指对象可以具有多种形式或类型。在OOP中，多态性涉及如何将对象视为其自身的实例、其超类的实例、其超类的超类的实例。</p><p>借由多态和接口继承，我们可以尝试实现运算符重载，尽管在Java中没有专门的操作。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">interface</span> <span class="hljs-title class_">OurComparable</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">compareTo</span><span class="hljs-params">(Object o)</span>;<br>&#125;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Dog</span> <span class="hljs-keyword">implements</span> <span class="hljs-title class_">OurComparable</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> weight;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">Dog</span><span class="hljs-params">(<span class="hljs-type">int</span> w)</span> &#123;<br>        weight = w;<br>    &#125;<br><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">compareTo</span><span class="hljs-params">(Object o)</span> &#123;<br>        <span class="hljs-type">Dog</span> <span class="hljs-variable">another</span> <span class="hljs-operator">=</span> (Dog) o;<br>        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">this</span>.weight &lt; another.weight) &#123;<br>            <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span>;<br>        &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (<span class="hljs-built_in">this</span>.weight = another.weight) &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>这样进行操作后，假设我们有其他类，也可以这样进行比较。如进行Dog和Cat之间的比较。</p><p>但是这样依然有缺陷，即强制类型转换时，可能会出错。这时我们考虑使用泛型。</p><p>java中已经为我们提供了接口 Comparable，故我们只需要实现</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Dog</span> <span class="hljs-keyword">implements</span> <span class="hljs-title class_">Comparable</span>&lt;Dog&gt; &#123;<br>    ...<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">compareTo</span><span class="hljs-params">(Dog another)</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">this</span>.weight - another.weight;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h1 id="Exceptions-Iterators-Object-Methods"><a href="#Exceptions-Iterators-Object-Methods" class="headerlink" title="Exceptions, Iterators, Object Methods"></a>Exceptions, Iterators, Object Methods</h1><h2 id="Lists-Sets-ArraySet"><a href="#Lists-Sets-ArraySet" class="headerlink" title="Lists, Sets, ArraySet"></a>Lists, Sets, ArraySet</h2><p>Java为我们提供了内置的List接口和多种实现，例如Arraylist。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java">java.util.List&lt;Integer&gt; L = <span class="hljs-keyword">new</span> <span class="hljs-title class_">java</span>.util.ArrayList&lt;&gt;();<br></code></pre></td></tr></table></figure><p>集合是唯一元素的集合，每个元素只能有一个副本，也没有顺序。Java 具有 Set 接口以及实现，例如 HashSet 。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">import</span> java.util.Set;<br><span class="hljs-keyword">import</span> java.util.HashSet;<br>Set&lt;String&gt; s = <span class="hljs-keyword">new</span> <span class="hljs-title class_">HashSet</span>&lt;&gt;();<br></code></pre></td></tr></table></figure><p>我们的目标是使用以下方法制作我们自己的集合 ArraySet ：</p><p>add(value) ：将值添加到集合中（如果尚不存在）</p><p>contains(value) ：检查 ArraySet 是否包含该值</p><p>size() ：返回大小</p><p>下面是一个框架：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">import</span> java.util.Iterator;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">ArraySet</span>&lt;T&gt; <span class="hljs-keyword">implements</span> <span class="hljs-title class_">Iterable</span>&lt;T&gt; &#123;<br>    <span class="hljs-keyword">private</span> T[] items;<br>    <span class="hljs-keyword">private</span> <span class="hljs-type">int</span> size; <span class="hljs-comment">// the next item to be added will be at position size</span><br><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">ArraySet</span><span class="hljs-params">()</span> &#123;<br>        items = (T[]) <span class="hljs-keyword">new</span> <span class="hljs-title class_">Object</span>[<span class="hljs-number">100</span>];<br>        size = <span class="hljs-number">0</span>;<br>    &#125;<br><br>    <span class="hljs-comment">/* Returns true if this map contains a mapping for the specified key.</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">contains</span><span class="hljs-params">(T x)</span> &#123;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; size; i += <span class="hljs-number">1</span>) &#123;<br>            <span class="hljs-keyword">if</span> (items[i].equals(x)) &#123;<br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>    &#125;<br><br>    <span class="hljs-comment">/* Associates the specified value with the specified key in this map. */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">add</span><span class="hljs-params">(T x)</span> &#123;<br>        <span class="hljs-keyword">if</span> (contains(x)) &#123;<br>            <span class="hljs-keyword">return</span>;<br>        &#125;<br>        items[size] = x;<br>        size += <span class="hljs-number">1</span>;<br>    &#125;<br><br>    <span class="hljs-comment">/* Returns the number of key-value mappings in this map. */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">size</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">return</span> size;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="Throwing-Exceptions"><a href="#Throwing-Exceptions" class="headerlink" title="Throwing Exceptions"></a>Throwing Exceptions</h2><p>上面的框架中有一个错误，当我们将 null 添加到 ArraySet 时，我们会得到一个 NullPointerException。</p><p>问题在于 contains 方法，我们在其中检查 items[i].equals(x) 。如果 items[i] 处的值为 null，则我们将调用 null.equals(x) -&gt; NullPointerException。</p><p>在Java中，我们使用关键字 throw 来抛出异常，语法格式：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">ExceptionObject</span>(parameter1, ...)<br></code></pre></td></tr></table></figure><p>更新后的add方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">add</span><span class="hljs-params">(T x)</span> &#123;<br>    <span class="hljs-keyword">if</span> (x == <span class="hljs-literal">null</span>) &#123;<br>        <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">IllegalArgumentException</span>(<span class="hljs-string">&quot;Can&#x27;t add null&quot;</span>);<br>    &#125;<br>    <span class="hljs-keyword">if</span> (contains(x)) &#123;<br>        <span class="hljs-keyword">return</span>;<br>    &#125;<br>    items[size] = x;<br>    size += <span class="hljs-number">1</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>和C++一样，我们也可以使用try、catch 语句来进行异常的捕获（此处略）</p><h2 id="Iteration"><a href="#Iteration" class="headerlink" title="Iteration"></a>Iteration</h2><p>for each 循环：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">for</span> (object : container) &#123;<br>    <span class="hljs-comment">// body of loop</span><br>&#125;<br></code></pre></td></tr></table></figure><p>这种循环是将container中的每个object进入循环体中执行语句，支持这种循环的关键是迭代器。</p><p>在Java中，通过实现内置的 Iterable 接口，我们可以实现自己的迭代器。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">interface</span> <span class="hljs-title class_">Iterator</span>&lt;T&gt; &#123;<br>    Iterator&lt;T&gt; <span class="hljs-title function_">iterator</span><span class="hljs-params">()</span>;<br>    <span class="hljs-type">boolean</span> <span class="hljs-title function_">hasNext</span><span class="hljs-params">()</span>;<br>    T <span class="hljs-title function_">next</span><span class="hljs-params">()</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>支持迭代器的 ArraySet 如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">import</span> java.util.Iterator;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">ArraySet</span>&lt;T&gt; <span class="hljs-keyword">implements</span> <span class="hljs-title class_">Iterable</span>&lt;T&gt; &#123;<br>    <span class="hljs-keyword">private</span> T[] items;<br>    <span class="hljs-keyword">private</span> <span class="hljs-type">int</span> size; <span class="hljs-comment">// the next item to be added will be at position size</span><br><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">ArraySet</span><span class="hljs-params">()</span> &#123;<br>        items = (T[]) <span class="hljs-keyword">new</span> <span class="hljs-title class_">Object</span>[<span class="hljs-number">100</span>];<br>        size = <span class="hljs-number">0</span>;<br>    &#125;<br><br>    <span class="hljs-comment">/* Returns true if this map contains a mapping for the specified key.</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">contains</span><span class="hljs-params">(T x)</span> &#123;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; size; i += <span class="hljs-number">1</span>) &#123;<br>            <span class="hljs-keyword">if</span> (items[i].equals(x)) &#123;<br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>    &#125;<br><br>    <span class="hljs-comment">/* Associates the specified value with the specified key in this map.</span><br><span class="hljs-comment">       Throws an IllegalArgumentException if the key is null. */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">add</span><span class="hljs-params">(T x)</span> &#123;<br>        <span class="hljs-keyword">if</span> (x == <span class="hljs-literal">null</span>) &#123;<br>            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">IllegalArgumentException</span>(<span class="hljs-string">&quot;can&#x27;t add null&quot;</span>);<br>        &#125;<br>        <span class="hljs-keyword">if</span> (contains(x)) &#123;<br>            <span class="hljs-keyword">return</span>;<br>        &#125;<br>        items[size] = x;<br>        size += <span class="hljs-number">1</span>;<br>    &#125;<br><br>    <span class="hljs-comment">/* Returns the number of key-value mappings in this map. */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">size</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">return</span> size;<br>    &#125;<br><br>    <span class="hljs-comment">/** returns an iterator (a.k.a. seer) into ME */</span><br>    <span class="hljs-keyword">public</span> Iterator&lt;T&gt; <span class="hljs-title function_">iterator</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">ArraySetIterator</span>();<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">ArraySetIterator</span> <span class="hljs-keyword">implements</span> <span class="hljs-title class_">Iterator</span>&lt;T&gt; &#123;<br>        <span class="hljs-keyword">private</span> <span class="hljs-type">int</span> wizPos;<br><br>        <span class="hljs-keyword">public</span> <span class="hljs-title function_">ArraySetIterator</span><span class="hljs-params">()</span> &#123;<br>            wizPos = <span class="hljs-number">0</span>;<br>        &#125;<br><br>        <span class="hljs-keyword">public</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">hasNext</span><span class="hljs-params">()</span> &#123;<br>            <span class="hljs-keyword">return</span> wizPos &lt; size;<br>        &#125;<br><br>        <span class="hljs-keyword">public</span> T <span class="hljs-title function_">next</span><span class="hljs-params">()</span> &#123;<br>            <span class="hljs-type">T</span> <span class="hljs-variable">returnItem</span> <span class="hljs-operator">=</span> items[wizPos];<br>            wizPos += <span class="hljs-number">1</span>;<br>            <span class="hljs-keyword">return</span> returnItem;<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> &#123;<br>        ArraySet&lt;Integer&gt; aset = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ArraySet</span>&lt;&gt;();<br>        aset.add(<span class="hljs-number">5</span>);<br>        aset.add(<span class="hljs-number">23</span>);<br>        aset.add(<span class="hljs-number">42</span>);<br><br>        <span class="hljs-comment">//iteration</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i : aset) &#123;<br>            System.out.println(i);<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="Object-Methods"><a href="#Object-Methods" class="headerlink" title="Object Methods"></a>Object Methods</h2><p>所有类都继承自总体 Object 类。继承的方法如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs java">String <span class="hljs-title function_">toString</span><span class="hljs-params">()</span><br><span class="hljs-type">boolean</span> <span class="hljs-title function_">equals</span><span class="hljs-params">(Object obj)</span><br>Class &lt;?&gt; getClass()<br><span class="hljs-type">int</span> <span class="hljs-title function_">hashCode</span><span class="hljs-params">()</span><br><span class="hljs-keyword">protected</span> <span class="hljs-title function_">Objectclone</span><span class="hljs-params">()</span><br><span class="hljs-keyword">protected</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">finalize</span><span class="hljs-params">()</span><br><span class="hljs-keyword">void</span> <span class="hljs-title function_">notify</span><span class="hljs-params">()</span><br><span class="hljs-keyword">void</span> <span class="hljs-title function_">notifyAll</span><span class="hljs-params">()</span><br><span class="hljs-keyword">void</span> <span class="hljs-title function_">wait</span><span class="hljs-params">()</span><br><span class="hljs-keyword">void</span> <span class="hljs-title function_">wait</span><span class="hljs-params">(<span class="hljs-type">long</span> timeout)</span><br><span class="hljs-keyword">void</span> <span class="hljs-title function_">wait</span><span class="hljs-params">(<span class="hljs-type">long</span> timeout, <span class="hljs-type">int</span> nanos)</span><br></code></pre></td></tr></table></figure><p>我们可以对这些方法进行重写。</p><h1 id="Lecture-12-notes-Preview-of-Project-2"><a href="#Lecture-12-notes-Preview-of-Project-2" class="headerlink" title="Lecture 12 notes: Preview of Project 2"></a>Lecture 12 notes: Preview of Project 2</h1><h2 id="Command-Line-Compliation"><a href="#Command-Line-Compliation" class="headerlink" title="Command Line Compliation"></a>Command Line Compliation</h2><p>The standard tools for executing java programs use to step process:<br>Hello.java &#x3D;&#x3D;&gt; javac (Compiler) &#x3D;&#x3D;&gt; Hello.class &#x3D;&#x3D;&gt; java (Interpreter) &#x3D;&#x3D;&gt; code</p><h2 id="psvm"><a href="#psvm" class="headerlink" title="psvm"></a>psvm</h2><p>Java中的main函数的基本形式：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> &#123;<br>    ...<br>&#125;<br></code></pre></td></tr></table></figure><p>其中，args储存了命令行参数。例如，我们有这样一个类：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Hello</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> &#123;<br>        System.out.println(args[<span class="hljs-number">0</span>]);<br>        System.out.println(args[<span class="hljs-number">1</span>]);<br>        System.out.println(args[<span class="hljs-number">2</span>]);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>当我们在命令行内执行</p><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs crystal"><span class="hljs-variable">$ </span>javac Hello<br><span class="hljs-variable">$ </span>java Hello x y z<br></code></pre></td></tr></table></figure><p>我们将会得到输出x y z。</p><h2 id="Git：A-Command-Line-Tool"><a href="#Git：A-Command-Line-Tool" class="headerlink" title="Git：A Command Line Tool"></a>Git：A Command Line Tool</h2><p>git是一个用C语言编写的command line program</p><p>git提供了一个便捷的 Version Control 工具。</p><p>学习Git 找到一个网站：<a href="https://learngitbranching.js.org/?demo=&locale=zh_CN">https://learngitbranching.js.org/?demo=&amp;locale=zh_CN</a></p><p>当我们每次提交(commit changes)时，git都储存了一个整个repository的copy并保存在隐藏文件夹 .git 下。</p><p>我们假设一个程序员经历了下面三个步骤：</p><ol><li>V1：Create readme.md</li><li>V2: Create some files, modify readme.md</li><li>V3: Modify some files, change readme.md to V1 version</li></ol><p>最自然的想法是在每次提交时都保存一份当前状态的副本，但是这种方法的缺点也是显而易见的。</p><p>稍加改进，我们发现每次提交时，并不是所有文件都会被修改，因此在下一次提交时，我们可以检查上一次保存的副本中是否含有相同的文件，并将本次保存的副本的相关文件用指针指向上一次的相同文件，这样就避免了同一份文件保存多次（指针只是形象的说明，Java没有指针 :P）。</p><p>在Java中，这种指向的一对一的键值对关系可以用map来保存。map的键为保存的文件，值记为版本号。</p><p>例如:</p><p>V1: X.java -&gt; v1, Y.java -&gt; v1<br>V2: X.java -&gt; v1, Y.java -&gt; v2<br>V3: X.java -&gt; v1, Y.java -&gt; v2, Z.java -&gt; v3<br>V4: X.java -&gt; v4, Y.java -&gt; v2, Z.java -&gt; v3, A.java -&gt; v4</p><p>这表示在V4中，X.java使用v4当中修改的版本，Y.java使用v2中修改的版本，以此类推。在这里，我们保存的并不是文件的内容信息，而是“Y.java V4具有和V2相同内容”这一信息。</p><p>接下来我们考虑下面的情景：</p><p>A和B同时从V3开始修改，A修改了Horse.java 而B修改了Fish.java，两人都进行了提交，这时V4应该是什么呢？</p><p>为了解决这一问题，git中的版本号使用提交时间来定义，这大大降低了版本冲突的问题，但仍然存在多人同时提交的可能性。</p><p>所以git使用基于内容确定的SHA-1 hash值作为版本号，对于同一个值，对应的Hash值也相同，本质上是一个单值函数。</p><p>第一步，git计算出 SHA-1 hash值<br>Hello.java &#x3D;&gt; 66ccdc645…<br>第二步，git创建一个文件夹，以前两个数字为标识<br>.git&#x2F;objects&#x2F;66<br>第三步，git储存内容在除去前两个数之后剩下部分(ccdc645…)命名的zlib文件中。</p><p>当文档的内容改变时，hash值也会改变，避免了版本名冲突。</p><p>每一个commit都包含了hash值、作者、时间和message。我们可以使用Serializable接口来实现对文件的操作。</p><p>在git中，我们拥有不同的分支以便储存不同的内容。在现实中，两个团队可能从同一个初始状态开始实现不同的功能，那么用不同的分支进行分隔是必要的。</p><p><img src="/Pictures/CS61b/02/branching.png" alt="img"></p><p>在完成之后，我们可以使用merge命令对分支进行合并。在这一过程中，我们用到了Graph的数据结构</p><p><img src="/Pictures/CS61b/02/merge.png" alt="img"></p><p>在git中，运用到了一些特殊的数据结构知识，下面是一个简短的preview</p><ul><li>Maps</li><li>Hashing</li><li>File I&#x2F;O</li><li>Graphs</li></ul><h2 id="File"><a href="#File" class="headerlink" title="File"></a>File</h2><p>使用File构造函数在Java中创造出一个File对象，并传入文件路径</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-type">File</span> <span class="hljs-variable">f</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">File</span>(<span class="hljs-string">&quot;dummy.txt&quot;</span>);<br><span class="hljs-comment">// Create a new file</span><br>f.createNewFile();<br><span class="hljs-comment">// Check if exists</span><br>f.exists();<br><span class="hljs-comment">// Use utils.java to write a String to a file</span><br>Utils.writeContents(f, <span class="hljs-string">&quot;Hello world!&quot;</span>);<br></code></pre></td></tr></table></figure><p>创建一个代表目录的File对象</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-type">File</span> <span class="hljs-variable">d</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">File</span>(<span class="hljs-string">&quot;dummy&quot;</span>);<br>d.mkdir();<br></code></pre></td></tr></table></figure><h2 id="Serializable"><a href="#Serializable" class="headerlink" title="Serializable"></a>Serializable</h2><p>实现Serializable接口的类表明它们可以被序列化，即可以将对象转换为字节序列，以便在网络上传输或保存到持久存储中，也可以将字节序列重新转换回对象。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">import</span> java.io.Serializable;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Model</span> <span class="hljs-keyword">implements</span> <span class="hljs-title class_">Serializable</span> &#123;<br>    ...<br>&#125;<br></code></pre></td></tr></table></figure><p>该接口没有方法；它只是为了一些特殊的 Java 类在对象上执行 I&#x2F;O 的好处而标记其子类型。例如</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-type">Model</span> <span class="hljs-variable">m</span> <span class="hljs-operator">=</span> ....;<br><span class="hljs-type">File</span> <span class="hljs-variable">outFile</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">File</span>(saveFileName);<br><span class="hljs-keyword">try</span> &#123;<br>    <span class="hljs-type">ObjectOutputStream</span> <span class="hljs-variable">out</span> <span class="hljs-operator">=</span><br>        <span class="hljs-keyword">new</span> <span class="hljs-title class_">ObjectOutputStream</span>(<span class="hljs-keyword">new</span> <span class="hljs-title class_">FileOutputStream</span>(outFile));<br>    out.writeObject(m);<br>    out.close();<br>&#125; <span class="hljs-keyword">catch</span> (IOException excp) &#123;<br>    ...<br>&#125;<br></code></pre></td></tr></table></figure><p>会将 m 转换为字节流并将其存储在名称存储在 saveFileName 中的文件中。然后可以使用诸如以下的代码序列来重建该对象:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs java">Model m;<br><span class="hljs-type">File</span> <span class="hljs-variable">inFile</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">File</span>(saveFileName);<br><span class="hljs-keyword">try</span> &#123;<br>    <span class="hljs-type">ObjectInputStream</span> <span class="hljs-variable">inp</span> <span class="hljs-operator">=</span><br>        <span class="hljs-keyword">new</span> <span class="hljs-title class_">ObjectInputStream</span>(<span class="hljs-keyword">new</span> <span class="hljs-title class_">FileInputStream</span>(inFile));<br>    m = (Model) inp.readObject();<br>    inp.close();<br>&#125; <span class="hljs-keyword">catch</span> (IOException | ClassNotFoundException excp) &#123;<br>    ...<br>    m = <span class="hljs-literal">null</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>利用 utils.java 重写代码可以使代码更加简洁</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs java">Model m;<br><span class="hljs-type">File</span> <span class="hljs-variable">outFile</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">File</span>(saveFileName);<br><span class="hljs-comment">// Serializing the Model object</span><br>writeObject(outFile, m);<br><br>Model m;<br><span class="hljs-type">File</span> <span class="hljs-variable">inFile</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">File</span>(saveFileName);<br><span class="hljs-comment">// Deserializing the Model object</span><br>m = readObject(inFile, Model.class);<br></code></pre></td></tr></table></figure><h1 id="Efficient-Programming"><a href="#Efficient-Programming" class="headerlink" title="Efficient Programming"></a>Efficient Programming</h1><h2 id="ADT"><a href="#ADT" class="headerlink" title="ADT"></a>ADT</h2><p>ADT（抽象数据结构）是由其行为而不是其实现定义的高级类型。</p><p>Proj1 中的 Deque 是一个具有某些行为（addFirst、addLast 等）的 ADT。但是，我们实际用来实现它的数据结构是 ArrayDeque 和 LinkedListDeque</p><ul><li>数据封装： ADT 将数据和操作封装在一起，使得数据的内部结构对外部是不可见的。</li><li>操作定义： ADT 定义了数据类型支持的操作，并描述了这些操作的行为。</li><li>独立性： ADT 的实现可以独立于使用它的程序。</li></ul><p>一些常用的 ADT 是：</p><ul><li><p>Stacks:支持元素后进先出检索的结构<br>push(int x) ：将 x 放入堆栈顶部<br>int pop() ：取出栈顶元素</p></li><li><p>Lists：一组有序的元素<br>add(int i) ：添加一个元素<br>int get(int i) ：获取索引 i 处的元素</p></li><li><p>Sets:一组无序的唯一元素（无重复）<br>add(int i) ：添加一个元素<br>contains(int i) ：返回一个布尔值，表示集合是否包含该值</p></li><li><p>Maps: 键&#x2F;值对的集合<br>put(K key, V value) ：将键值对放入映射中<br>V get(K key) ：获取key对应的值</p></li></ul><h2 id="API"><a href="#API" class="headerlink" title="API"></a>API</h2><p>ADT 的 API（应用程序编程接口）是构造函数和方法的列表以及每个构造函数和方法的简短描述。</p><p>API由句法和语义规范组成。</p><ul><li>规范性： API 提供了一组规范，定义了如何使用软件组件或服务。</li><li>抽象性： API 屏蔽了底层实现细节，使开发者可以专注于使用而不是实现细节。</li><li>互操作性： API 促进了不同软件系统之间的互操作性和集成。</li></ul><h2 id="Asymptotics"><a href="#Asymptotics" class="headerlink" title="Asymptotics"></a>Asymptotics</h2><p>主要概念：</p><ol><li><p>时间复杂度： 时间复杂度描述了算法执行所需时间与输入规模之间的关系。通常以大 O 表示法来表示，表示算法的渐进上界。例如，如果一个算法的时间复杂度为 O(n)，则表示算法的运行时间与输入规模成线性关系。</p></li><li><p>空间复杂度： 空间复杂度描述了算法在执行过程中所需的内存空间与输入规模之间的关系。也通常以大 O 表示法来表示。</p></li><li><p>渐进分析： 渐进分析是指对算法性能进行预测时，主要考虑随着输入规模的增长，算法的运行时间或空间占用的变化趋势。在这种分析中，我们更关注算法的增长率而不是确切的运行时间或空间。</p></li><li><p>最坏情况复杂度： 最坏情况复杂度描述了算法在最坏情况下的时间或空间开销。这给出了算法性能的一个保证，即算法在任何情况下都不会比最坏情况更差。</p></li><li><p>平均情况复杂度： 平均情况复杂度描述了算法在平均情况下的时间或空间开销。这需要考虑所有可能输入的概率分布，并计算平均性能。</p></li><li><p>最优算法： 最优算法是指在给定问题上具有最低时间复杂度或空间复杂度的算法。找到最优算法通常是解决特定问题的目标之一。</p></li></ol><p>这章主要介绍了时间复杂度和空间复杂度的计算，以及一些经典算法的时间复杂度分析方法，如小o、大O法等，此处不再举例说明。</p><h1 id="Disjoint-Sets"><a href="#Disjoint-Sets" class="headerlink" title="Disjoint Sets"></a>Disjoint Sets</h1><p>不相交集的定义：如果两个集合没有共同元素，则它们被称为不相交集合。该数据结构有两个操作：</p><ol><li>connect(x, y):连接x和y，也被称为union</li><li>isConnected(x, y):返回x和y是否连接</li></ol><p>不相交集数据结构具有固定数量的元素，每个元素都从自己的子集中开始。通过对某些元素 x 和 y 调用 connect(x, y) ，我们将子集合并在一起。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">interface</span> <span class="hljs-title class_">DisjointSets</span> &#123;<br>    <span class="hljs-comment">/** connects two items P and Q */</span><br>    <span class="hljs-keyword">void</span> <span class="hljs-title function_">connect</span><span class="hljs-params">(<span class="hljs-type">int</span> p, <span class="hljs-type">int</span> q)</span>;<br><br>    <span class="hljs-comment">/** checks to see if two items are connected */</span><br>    <span class="hljs-type">boolean</span> <span class="hljs-title function_">isConnected</span><span class="hljs-params">(<span class="hljs-type">int</span> p, <span class="hljs-type">int</span> q)</span>; <br>&#125;<br></code></pre></td></tr></table></figure><h2 id="Quick-Find"><a href="#Quick-Find" class="headerlink" title="Quick Find"></a>Quick Find</h2><p>直观上，我们可能首先考虑将不相交集表示为集合列表:<br>[{0}, {1}, {2}, {3}, {4}, {5}, {6}]<br>但这样如果我们进行connect操作，需要遍历List，时间复杂度为 $O(n)$ 。</p><p>所以我们考虑使用数组表示：</p><ul><li>数组的索引代表我们集合的元素。</li><li>索引处的值是它所属的集合编号。</li></ul><p>例如，我们将 {0, 1, 2, 4}, {3, 5}, {6} 表示为：</p><p><img src="/Pictures/CS61b/02/arrayset.png" alt="img"></p><p>执行connect操作就是把对应序号的值改为集合的编号</p><p>执行isConnected操作即检查序号的值是否相等。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">QuickFindDS</span> <span class="hljs-keyword">implements</span> <span class="hljs-title class_">DisjointSets</span> &#123;<br>    <span class="hljs-keyword">private</span> <span class="hljs-type">int</span>[] id;<br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">QuickFindDS</span><span class="hljs-params">(<span class="hljs-type">int</span> N)</span>&#123;<br>        id = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[N];<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; N; i++)&#123;<br>            id[i] = i;<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">connect</span><span class="hljs-params">(<span class="hljs-type">int</span> p, <span class="hljs-type">int</span> q)</span>&#123;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">pid</span> <span class="hljs-operator">=</span> id[p];<br>        <span class="hljs-type">int</span> <span class="hljs-variable">qid</span> <span class="hljs-operator">=</span> id[q];<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; id.length; i++)&#123;<br>            <span class="hljs-keyword">if</span> (id[i] == pid)&#123;<br>                id[i] = qid;<br>            &#125;<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">public</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">isConnected</span><span class="hljs-params">(<span class="hljs-type">int</span> p, <span class="hljs-type">int</span> q)</span>&#123;<br>        <span class="hljs-keyword">return</span> (id[p] == id[q]);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="Quick-Union"><a href="#Quick-Union" class="headerlink" title="Quick Union"></a>Quick Union</h2><p>在Quick Find中，如果我们想要快速的将多个集合connect是非常困难的。</p><p>这时，我们考虑为每个项目分配其父集的索引编号而不是id，如果一个集合没有父项，我们为其赋值为-1.</p><p>这种方法支持我们将每个集合想象成一棵树。例如，我们将 {0, 1, 2, 4}, {3, 5}, {6} 表示为：</p><p><img src="/Pictures/CS61b/02/QuickUnion.png" alt="img"></p><p>对于 QuickUnion，我们定义了一个辅助函数 find(int item) ，它返回 item 所在树的根。例如，对于上面的集合， find(4) &#x3D;&#x3D; 0 、 find(1) &#x3D;&#x3D; 0 、 find(5) &#x3D;&#x3D; 3 等。每个元素都有一个唯一的root.</p><p>当我们想要连接两个集合时，我们只需要将A集的root连接到B集的root上，即把A集作为B集的一个branch。</p><p>检查两个集合是否为相连的，我们只需要检查两个集合是否具有相同的root。</p><p>在性能方面，利用树可以使连接变得十分简单，但相应的，当我们想要查找某一个元素时，我们需要遍历树的各个branch，时间复杂度为 $O(n)$</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">QuickUnionDS</span> <span class="hljs-keyword">implements</span> <span class="hljs-title class_">DisjointSets</span> &#123;<br>    <span class="hljs-keyword">private</span> <span class="hljs-type">int</span>[] parent;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">QuickUnionDS</span><span class="hljs-params">(<span class="hljs-type">int</span> num)</span> &#123;<br>        parent = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[num];<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; num; i++) &#123;<br>            parent[i] = i;<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-type">int</span> <span class="hljs-title function_">find</span><span class="hljs-params">(<span class="hljs-type">int</span> p)</span> &#123;<br>        <span class="hljs-keyword">while</span> (parent[p] &gt;= <span class="hljs-number">0</span>) &#123;<br>            p = parent[p];<br>        &#125;<br>        <span class="hljs-keyword">return</span> p;<br>    &#125;<br><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">connect</span><span class="hljs-params">(<span class="hljs-type">int</span> p, <span class="hljs-type">int</span> q)</span> &#123;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> find(p);<br>        <span class="hljs-type">int</span> j= find(q);<br>        parent[i] = j;<br>    &#125;<br><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">isConnected</span><span class="hljs-params">(<span class="hljs-type">int</span> p, <span class="hljs-type">int</span> q)</span> &#123;<br>        <span class="hljs-keyword">return</span> find(p) == find(q);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="Weighted-Quick-Union-WQU"><a href="#Weighted-Quick-Union-WQU" class="headerlink" title="Weighted Quick Union (WQU)"></a>Weighted Quick Union (WQU)</h2><p>Quick Union 的改进依赖于一个关键的思路：每当我们调用 find 时，我们都必须找到树的根部。因此，树越短，速度就越快。</p><p>所以在我们将两个树相连时，我们选择将较小的树作为子树连接到较大的树上。</p><p>如何衡量树的大小？在这里，我们用树包含的元素的数量作为树的Weight。</p><p>基于这种方法，我们所获得的树的最大高度将会为 $logN$ ，其中 $N$ 为树所包含元素的数量。</p><p>我们假设有树 $T_{1},T_{2}$ ，其中 $T_{1}$ 包含了元素 $x$ ， $size(T_{2}) \ge size(T_{1})$ 。当我们合并两个tree时，我们将 $T_{1}$ 连接到 $T_{2}$ 下，这个操作使 $x$ 的深度增加1，而整个合并的树大小至少为 $T_{1}$ 的两倍，也就是说 $2^{h} &#x3D; N$ ，最大高度 $h &#x3D; \log_{2}{N}$</p><h2 id="Weighted-Quick-Union-with-Path-Compression"><a href="#Weighted-Quick-Union-with-Path-Compression" class="headerlink" title="Weighted Quick Union with Path Compression"></a>Weighted Quick Union with Path Compression</h2><p>在上面的方法中，每次我们调用 find(x) 时，我们必须遍历从x到root 的路径，因此在这个过程中，我们可以将访问的所有项目连接到它们的root，无需额外的渐进成本。</p><p>这称为摊销运行时间，我们通过这种方式使树变得更短。</p><h1 id="Binary-Search-Trees"><a href="#Binary-Search-Trees" class="headerlink" title="Binary Search Trees"></a>Binary Search Trees</h1><blockquote><p>Now we are going to learn about perhaps the most important data structure ever. –Josh Hug, CS61b</p></blockquote><p>对于搜索项目而言，有序数据结构如链表一般效率较高。但即使是已排序的列表，对于搜索项目的时间复杂度依旧为 $O(n)$ 。</p><p>对于数组，我们可以使用二分查找来更快的找到元素。</p><h2 id="Binary-Search"><a href="#Binary-Search" class="headerlink" title="Binary Search"></a>Binary Search</h2><p>使用二分查找的条件：</p><ol><li>数据结构必须是有序的</li><li>访问数据结构的任何元素都需要恒定时间</li></ol><p>二分查找的一般步骤：</p><p>在二分查找算法中，通过查找中间索引 “mid” 将搜索空间分为两半</p><p>如果mid不是我们需要的，选择元素存在的一侧继续进行二分查找，知道找到或者空间耗尽。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">import</span> java.io.*;<br> <br><span class="hljs-keyword">class</span> <span class="hljs-title class_">BinarySearch</span> &#123;<br>    <span class="hljs-comment">// Returns index of x if it is present in arr[].</span><br>    <span class="hljs-type">int</span> <span class="hljs-title function_">binarySearch</span><span class="hljs-params">(<span class="hljs-type">int</span> arr[], <span class="hljs-type">int</span> x)</span><br>    &#123;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">l</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>, r = arr.length - <span class="hljs-number">1</span>;<br>        <span class="hljs-keyword">while</span> (l &lt;= r) &#123;<br>            <span class="hljs-type">int</span> <span class="hljs-variable">m</span> <span class="hljs-operator">=</span> l + (r - l) / <span class="hljs-number">2</span>;<br> <br>            <span class="hljs-comment">// Check if x is present at mid</span><br>            <span class="hljs-keyword">if</span> (arr[m] == x)<br>                <span class="hljs-keyword">return</span> m;<br> <br>            <span class="hljs-comment">// If x greater, ignore left half</span><br>            <span class="hljs-keyword">if</span> (arr[m] &lt; x)<br>                l = m + <span class="hljs-number">1</span>;<br> <br>            <span class="hljs-comment">// If x is smaller, ignore right half</span><br>            <span class="hljs-keyword">else</span><br>                r = m - <span class="hljs-number">1</span>;<br>        &#125;<br> <br>        <span class="hljs-comment">// If we reach here, then element was</span><br>        <span class="hljs-comment">// not present</span><br>        <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span>;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>基于有序链表，我们实现BST的步骤一般如下：</p><ol><li>将哨兵节点指向链表的中间，并更改链表之间的指向</li><li>判断要搜索的元素位于哪一侧</li><li>在一侧递归上述过程</li></ol><h2 id="Tree"><a href="#Tree" class="headerlink" title="Tree"></a>Tree</h2><p>下面我们给出严格的树定义。<br>树由节点以及连接节点的这些边组成。</p><blockquote><p>注意：任意两个节点之间有且仅有一条路径，即不形成回路，没有连支。</p></blockquote><p>没有父节点的节点称为root，根节点。在拓扑学中，根节点实际上存在多种可能性，这里我们只任意选取一种。</p><p>没有子节点的节点称为叶子（leaf）</p><p>将其与我们之前提出的原始树结构联系起来，我们现在可以向已经存在的约束引入新的约束。这会创建更具体类型的树。</p><ul><li>Binary Trees：二叉树，规定每个节点最多只有2个子节点</li><li>Binary Search Trees<br>二叉搜索树，是一种二叉树，对于树中的每个节点X：</li></ul><ol><li>左子树中的每个键都小于X的键</li><li>右子树中的每个键都大于X的键</li></ol><p>基于这种特殊的性质，我们得以将二分搜索应用于这种数据结构上。</p><p>对于二叉搜索树的插入操作，我们基于以下的思路：</p><ul><li>首先我们搜索该节点，如果该节点已经存在，则不需要插入</li><li>如果我们没有找到该节点，实际上我们停止搜索的位置正好就是应该插入的位置的父节点，此时我们可以将新的leaf添加到节点的左侧或右侧。</li></ul><p>对于二叉树的删除方法，我们需要考虑三种情况：</p><ol><li>删除一片叶子</li><li>删除一个有一个子节点的节点d</li><li>删除一个有两个子节点的节点</li></ol><p>对于叶子，我们直接删除父节点和叶子之间的边即可<br>对于一个子节点，我们只需要将该节点的父节点的指针指向该节点的子节点即可<br>对于两个子节点，我们用右子树最左侧的节点（最小值）代替删除的节点或用左子树最右侧的节点（最大值）代替该节点。</p><p>一个简单的实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">private</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">BST</span>&lt;Key&gt; &#123;<br>    <span class="hljs-keyword">private</span> Key key;<br>    <span class="hljs-keyword">private</span> BST left;<br>    <span class="hljs-keyword">private</span> BST right;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">BST</span><span class="hljs-params">(Key key, BST left, BST Right)</span> &#123;<br>        <span class="hljs-built_in">this</span>.key = key;<br>        <span class="hljs-built_in">this</span>.left = left;<br>        <span class="hljs-built_in">this</span>.right = right;<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">BST</span><span class="hljs-params">(Key key)</span> &#123;<br>        <span class="hljs-built_in">this</span>.key = key;<br>    &#125;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> BST <span class="hljs-title function_">find</span><span class="hljs-params">(BST T, Key key)</span> &#123;<br>        <span class="hljs-keyword">if</span>(T == <span class="hljs-literal">null</span>) &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">null</span>;<br>        &#125;<br>        <span class="hljs-keyword">if</span>(T.key == key) &#123;<br>            <span class="hljs-keyword">return</span> T;<br>        &#125;<br>        <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(T.key &lt; key) &#123;<br>            <span class="hljs-keyword">return</span> find(T.right, key);<br>        &#125;<br>        <span class="hljs-keyword">else</span> &#123;<br>            <span class="hljs-keyword">return</span> find(T.left, key);<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> BST <span class="hljs-title function_">insert</span><span class="hljs-params">(BST T, Key ik)</span> &#123;<br>        <span class="hljs-keyword">if</span> (T == <span class="hljs-literal">null</span>) &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">BST</span>(ik);<br>        &#125;<br>        <span class="hljs-keyword">if</span> (ik &lt; T.key) &#123;<br>            T.left = insert(T.left, ik);<br>        &#125;<br>        <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (ik &gt; T.key) &#123;<br>            T.right = insert(T.right, ik);<br>        &#125;<br>        <span class="hljs-keyword">return</span> T;<br>    &#125;<br>    <span class="hljs-comment">// A possible version, has not been tested yet.</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> BST <span class="hljs-title function_">delete</span><span class="hljs-params">(BST T, Key dk)</span> &#123;<br>        <span class="hljs-keyword">if</span> (T == <span class="hljs-literal">null</span>) &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">null</span>;<br>        &#125;<br>        <span class="hljs-keyword">if</span> (dk.equals(T.key)) &#123;<br>            <span class="hljs-comment">// Case 1: Node to be deleted has no children</span><br>            <span class="hljs-keyword">if</span> (T.left == <span class="hljs-literal">null</span> &amp;&amp; T.right == <span class="hljs-literal">null</span>) &#123;<br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">null</span>;<br>            &#125;<br>            <span class="hljs-comment">// Case 2: Node to be deleted has only one child</span><br>            <span class="hljs-keyword">if</span> (T.left == <span class="hljs-literal">null</span>) &#123;<br>                <span class="hljs-keyword">return</span> T.right;<br>            &#125;<br>            <span class="hljs-keyword">if</span> (T.right == <span class="hljs-literal">null</span>) &#123;<br>                <span class="hljs-keyword">return</span> T.left;<br>            &#125;<br>            <span class="hljs-comment">// Case 3: Node to be deleted has two children</span><br>            <span class="hljs-type">Key</span> <span class="hljs-variable">minKey</span> <span class="hljs-operator">=</span> findMin(T.right);<br>            T.key = minKey;<br>            T.right = delete(T.right, minKey);<br>        &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (dk &lt; T.key) &#123;<br>            T.left = delete(T.left, dk);<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            T.right = delete(T.right, dk);<br>        &#125;<br>        <span class="hljs-keyword">return</span> T;<br>    &#125;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> Key <span class="hljs-title function_">findMin</span><span class="hljs-params">(BST T)</span> &#123;<br>        <span class="hljs-keyword">while</span> (T.left != <span class="hljs-literal">null</span>) &#123;<br>            T = T.left;<br>        &#125;<br>        <span class="hljs-keyword">return</span> T.key;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="Tree-traversal"><a href="#Tree-traversal" class="headerlink" title="Tree traversal"></a>Tree traversal</h2><p>对于树，我们有这样四种遍历的方式</p><ol><li>前序遍历（根优先遍历，即对于每个树和子树，按照根-左树-右树的顺序遍历）</li><li>中序遍历（左树-根-右树）</li><li>后序遍历（左树-右树-根）</li><li>层次遍历（具有相同深度的称为一层）</li></ol><p>这里我们实现中序遍历:</p><p>我们在迭代器中使用一个栈来辅助遍历。在将元素压入栈中的过程中，我们需要注意以下几点：</p><ol><li><p>找到左子树的最左节点：首先，我们需要找到当前节点的左子树的最左节点。这个节点是中序遍历中的第一个要访问的节点。</p></li><li><p>将节点压入栈中：一旦找到了左子树的最左节点，我们将该节点压入栈中。</p></li><li><p>更新当前节点：然后，我们将当前节点移动到其右子树。如果右子树不为空，我们继续重复步骤 1 和 2。</p></li><li><p>重复直到完成：我们重复执行上述步骤，直到栈为空。当栈为空时，说明 BST 中的所有节点都已经遍历完成。</p></li></ol><p>下面是一个例子：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs markdown"><span class="hljs-code">    5</span><br><span class="hljs-code">   / \</span><br><span class="hljs-code">  3   8</span><br><span class="hljs-code"> / \ / \</span><br><span class="hljs-code">2  4 7  9</span><br></code></pre></td></tr></table></figure><p>首先，我们将根节点 5 压入栈中，并且将根节点的左子树全部压入栈中，直到左子树的最左节点 2。此时，栈中的元素为 [2, 3, 5]。</p><p>接着，我们开始执行迭代器的 next() 方法。在 next() 方法中，我们首先弹出栈顶节点 2，然后将其右子节点 null 压入栈中。此时，栈中的元素为 [3, 5]。</p><p>继续执行 next() 方法，我们弹出栈顶节点 3，返回 3。然后，将其右子节点 4 压入栈中。此时，栈中的元素为 [4, 5]。</p><p>再次执行 next() 方法，我们弹出栈顶节点 4，返回 4。此时，栈中的元素为 [5]。</p><p>继续执行 next() 方法，我们弹出栈顶节点 5，返回 5。然后，将其右子节点 8 压入栈中，并将右子树的所有左子节点全部压入栈中，直到左子树的最左节点 7。此时，栈中的元素为 [7, 8]。</p><p>继续执行 next() 方法，我们弹出栈顶节点 7，返回 7。然后，将其右子节点 null 压入栈中。此时，栈中的元素为 [8]。</p><p>最后，我们弹出栈顶节点 8，返回 8。然后，将其右子节点 9 压入栈中，并且将右子节点的所有左子节点全部压入栈中，直到左子树的最左节点 9。此时，栈中的元素为 [9]。</p><p>最终，我们执行 next() 方法，弹出栈顶节点 9，返回 9。此时，栈为空，遍历结束。</p><p>通过这个过程，我们按照中序遍历的顺序遍历了二叉搜索树中的所有节点，迭代器的 next() 方法成功返回了所有节点的键值。</p><h2 id="Tree-Height"><a href="#Tree-Height" class="headerlink" title="Tree Height"></a>Tree Height</h2><p>在最好情况下，search操作的时间为 $\Theta (\log{}{N})$ ，但最差情况下可以达到 $\Theta (n)$ 。</p><ul><li>depth: 节点与根之间的链接数</li><li>height: 树的最低深度（深度最大）</li><li>average depth：平均深度<br>树的高度决定了最坏情况下的运行时间，因为在最坏情况下我们需要的节点在树的底部。<br>平均深度决定了平均运行时间。</li></ul><h2 id="B-Trees"><a href="#B-Trees" class="headerlink" title="B-Trees"></a>B-Trees</h2><p>当我们插入新数据时，我们总是会将新数据插入到原来的叶子上，这样便造成了树的高度增加。更严重的是，当我们的数据呈现出连续的特点时，我们会沿着一条路线不断向下，导致整棵树的结构试去平衡，也使算法效率降低。</p><p>于是我们便有了这样一个想法：当我们添加节点时，永远不要添加叶节点，而是将原有的叶节点扩充，即一个节点依次存放多于一个数据。</p><p>这样做的确使结构平衡，减小了高度，但是在新添加的数据量级较大时，并没有降低复杂度。</p><p>于是我们将添加的数据继续分离，将中间的一部分沿树枝向上添加到父节点中，使得整个树更加平衡。这样，对于每一个节点，我们都可以拥有含有两个元素的子节点，并保持节点之间的有序排列，这便是B树的定义。</p><p>我们主要讨论 2-3 树，即一个节点可以最多包含两个元素，三个子节点。</p><p>B树的主要特点包括：</p><ol><li>每个节点最多有m个子节点。</li><li>除了根节点和叶节点外，每个节点至少有⌈m&#x2F;2⌉个子节点。</li><li>根节点至少有两个子节点，除非它是一个叶节点。</li><li>所有叶节点都出现在同一层级。</li><li>一个非叶节点如果有k个子节点，那么它包含k-1个键。每个内部节点的键作为分隔值，将其子树分开。</li></ol><h3 id="B-Tree-Deletion"><a href="#B-Tree-Deletion" class="headerlink" title="B-Tree Deletion"></a>B-Tree Deletion</h3><p><strong>CASE1：</strong>邻近的兄弟节点有多个Key<br><img src="/Pictures/CS61b/02/case1A.png" alt="case1"></p><p>这种情况下，我们用父节点填充删除节点，用邻近兄弟节点的较小Key填充父节点.</p><p><img src="/Pictures/CS61b/02/1Asolve.png" alt="solution"></p><p><strong>CASE2：</strong>父节点含有两个Key，邻近的兄弟节点只有一个。</p><p><img src="/Pictures/CS61b/02/case2.png" alt="case2"></p><p>在这种情况下，父节点的左值分配到左孩子，右值分配到右孩子，中间的子节点的两个孙节点分别分配到其余节点下。</p><p><img src="/Pictures/CS61b/02/2solution.png" alt="solution"></p><p><strong>CASE3：</strong>父节点和邻近兄弟节点均只有一个Key</p><p><img src="/Pictures/CS61b/02/case3.png" alt="case3"></p><h3 id="Tree-Rotation"><a href="#Tree-Rotation" class="headerlink" title="Tree Rotation"></a>Tree Rotation</h3><p>在上面的算法中，我们多次用到了CASE1中类似于“旋转”的操作。接下来我们就来正式的定义这种操作并用算法实现。</p><p>The formal definition of rotation is:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">BTree</span> &#123;<br>    <span class="hljs-keyword">private</span> Node <span class="hljs-title function_">rotateRight</span><span class="hljs-params">(Node h)</span> &#123;<br>        <span class="hljs-comment">// assert (h != null) &amp;&amp; isRed(h.left);</span><br>        <span class="hljs-type">Node</span> <span class="hljs-variable">x</span> <span class="hljs-operator">=</span> h.left;<br>        h.left = x.right;<br>        x.right = h;<br>        <span class="hljs-keyword">return</span> x;<br>    &#125;<br><br><span class="hljs-comment">// make a right-leaning link lean to the left</span><br>    <span class="hljs-keyword">private</span> Node <span class="hljs-title function_">rotateLeft</span><span class="hljs-params">(Node h)</span> &#123;<br>        <span class="hljs-comment">// assert (h != null) &amp;&amp; isRed(h.right);</span><br>        <span class="hljs-type">Node</span> <span class="hljs-variable">x</span> <span class="hljs-operator">=</span> h.right;<br>        h.right = x.left;<br>        x.left = h;<br>        <span class="hljs-keyword">return</span> x;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p><img src="/Pictures/CS61b/02/rotation.png" alt="rotation"></p><p>通过基础的旋转操作，我们可以实现简单的节点重构。</p><h2 id="Red-Black-Tree"><a href="#Red-Black-Tree" class="headerlink" title="Red-Black Tree"></a>Red-Black Tree</h2><p>2-3 树的想法非常好，但实际上很难实现，于是我们考虑创建一种同时使用BST和2-3树的结构的新的树。</p><p>我们首先考虑如何将2-3树转换为BST。</p><p>对于只有两个子节点的2-3树，我们已经有了BST结构，因此不需要进行修改；但是对于有三个子节点的树，我们首先要做的便是创建一个“粘合节点”，它不保存任何信息，仅用于表明它的两个子节点实际上时一个节点的一部分。</p><p>然而，这是一个非常不优雅的解决方案，因为我们占用了更多的空间，而且代码也很难看。因此，我们将使用粘合链接而不是使用粘合节点！</p><p>我们选择使左侧元素成为右侧元素的子元素。这会产生一棵左倾树。我们通过将链接设为红色来表明它是粘合链接。正常链接是黑色的。因此，我们将这些结构称为左倾红黑树(LLRB)。</p><p>2-3树和LLRB之间存在一一对应的双射关系。</p><p><img src="/Pictures/CS61b/02/LLRB.png" alt="LLRB"></p><p>注意：要构成有效的红黑树，需要满足以下条件：</p><ol><li>每个节点只能有不多于一个红色链接</li><li>每条从leaf 到 root 的路径具有相同的黑色链接数量。</li><li>若原本2-3树的高度为 $H$ ，LLRB的高度不超过 $2H+1$ 。</li></ol><h3 id="Tree-Insertion"><a href="#Tree-Insertion" class="headerlink" title="Tree Insertion"></a>Tree Insertion</h3><p>向红黑树中插入节点，需要解决以下几个问题：</p><ol><li>插入的颜色：在2-3树中，我们总是通过添加到叶节点来插入，所以我们添加的链接应该是红色链接。</li></ol><p><img src="/Pictures/CS61b/02/insert_color.png" alt="Task1"></p><ol start="2"><li>插入方向：我们使用的是LLRB，这意味着我们永远不可能拥有右侧的红色链接，如果需要在右侧插入，我们需要进行必要的旋转操作。</li></ol><p><img src="/Pictures/CS61b/02/insert_right.png" alt="Task2"></p><ol start="3"><li>引入暂时的 <em>4节点</em> 解决问题</li></ol><p><img src="/Pictures/CS61b/02/4node.png" alt="Task3"></p><p>之后我们利用 <em>flip</em> 操作来进行规范化操作。</p><p><img src="/Pictures/CS61b/02/flip.png" alt="Task4"></p><p>抽象代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">private</span> Node <span class="hljs-title function_">put</span><span class="hljs-params">(Node h, Key key, Value val)</span> &#123;<br>    <span class="hljs-keyword">if</span> (h == <span class="hljs-literal">null</span>) &#123; <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Node</span>(key, val, RED); &#125;<br><br>    <span class="hljs-type">int</span> <span class="hljs-variable">cmp</span> <span class="hljs-operator">=</span> key.compareTo(h.key);<br>    <span class="hljs-keyword">if</span> (cmp &lt; <span class="hljs-number">0</span>)      &#123; h.left  = put(h.left,  key, val); &#125;<br>    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (cmp &gt; <span class="hljs-number">0</span>) &#123; h.right = put(h.right, key, val); &#125;<br>    <span class="hljs-keyword">else</span>              &#123; h.val   = val;                    &#125;<br><br>    <span class="hljs-keyword">if</span> (isRed(h.right) &amp;&amp; !isRed(h.left))      &#123; h = rotateLeft(h);  &#125;<br>    <span class="hljs-keyword">if</span> (isRed(h.left)  &amp;&amp;  isRed(h.left.left)) &#123; h = rotateRight(h); &#125;<br>    <span class="hljs-keyword">if</span> (isRed(h.left)  &amp;&amp;  isRed(h.right))     &#123; flipColors(h);      &#125; <br><br>    <span class="hljs-keyword">return</span> h;<br>&#125;<br></code></pre></td></tr></table></figure><h1 id="Hashing"><a href="#Hashing" class="headerlink" title="Hashing"></a>Hashing</h1><h2 id="DataIndexedIntegerSet"><a href="#DataIndexedIntegerSet" class="headerlink" title="DataIndexedIntegerSet"></a>DataIndexedIntegerSet</h2><p>对于我们已经学习到的数据结构，我们需要寻找某一元素时，都需要遍历整个结构。这样通常会花费 $O(n)$ 运行时甚至更多。于是我们考虑设计这样一个数据结构，让寻找元素的时间变为 $O(1)$ 。</p><p>于是我们考虑这样一种数据结构：我们创建一个非常大的数组，存放boolean类型的数据，<strong>将数组的 index 作为数据的值</strong>。初始时我们将元素设置为<em>false</em>，代表没有存放对应序号的数据。在添加数据时，只需要将对应位置的元素更改为<em>true</em>即可。这样，我们的<em>search</em>和<em>contains</em>操作都将是 $O(1)$ 复杂度。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">DataIndexedIntegerSet</span> &#123;<br>    <span class="hljs-keyword">private</span> <span class="hljs-type">boolean</span>[] present;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">DataIndexedIntegerSet</span><span class="hljs-params">()</span> &#123;<br>        present = <span class="hljs-keyword">new</span> <span class="hljs-title class_">boolean</span>[<span class="hljs-number">200000000</span>];<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">add</span><span class="hljs-params">(<span class="hljs-type">int</span> i)</span> &#123;<br>        present[i] = <span class="hljs-literal">true</span>;<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">contains</span><span class="hljs-params">(<span class="hljs-type">int</span> i)</span> &#123;<br>        <span class="hljs-keyword">return</span> present[i];<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>显然，这个数据结构占用空间大、存储数据类型单一、浪费资源，但是却为我们提供了一个很好的思路。</p><h2 id="DataIndexedStringSet"><a href="#DataIndexedStringSet" class="headerlink" title="DataIndexedStringSet"></a>DataIndexedStringSet</h2><p>接下来我们尝试在数据结构中插入<em>String</em>类型的数据。</p><p>基于上面的思想，我们也考虑使用一个算法将每一个String转化成唯一的一个Integer。比如我们为每一个英文字母和符号分配一个数值，用数值加和得出的结果来代表这个单词。</p><p>这里很自然的我们想到利用<strong>ASCII码</strong>来处理。</p><p>在算法方面，我们考虑借鉴进制的定义，比如十进制利用0到9的十个数字表示出所有自然数。我们以 126 为基，这样 “cat” 便可以表示为：</p><p>$$cat &#x3D; char(c)\times 126^{2}+char(a)\times 126^{1}+char(t)\times 126^{0}$$</p><p>其中char代表对应的ASCII码值。</p><p>这样，我们便可以使用int代替String，接下来就可以用int进行存储。</p><p>但是，如果我们想要储存中文，最大的可能符号有 <strong>40959</strong> 种，意味着我们需要一个大于39万亿的数组存储，这显然是不现实的！</p><h2 id="Hash-Code"><a href="#Hash-Code" class="headerlink" title="Hash Code"></a>Hash Code</h2><p>对于小范围的哈希值，我们可以使用一个数组来区分每个哈希值。也就是说，数组中的每个索引都代表一个唯一的哈希值。如果我们的指数很小并且接近于零，那么这种方法很有效。</p><p>假设我们只想支持长度为 10 的数组，以避免分配过多的内存。此时，我们可以依靠取模运算实现这一点。</p><p>所以要创建有效的哈希码，我们需要考虑下述维度：</p><ol><li>Deterministic:确定性，两个相等的对象 A 和 B ( A.equals(B) &#x3D;&#x3D; true ) 的 hashCode() 函数具有相同的哈希码。</li><li>Consistent:每次在对象的同一实例上调用 hashCode() 函数时，它都会返回相同的整数。</li></ol><p>在此基础上，如果需要拥有高效的哈希码，我们需要进一步考虑以下问题：</p><ol><li>hashCode() 函数必须有效。</li><li>hashCode() 函数值应尽可能均匀地分布在所有整数的集合上。</li><li>hashCode() 函数的计算速度应该相对较快[理想情况下为 $O(1)$ 常数时间数学运算]</li></ol><p>由于数据溢出等特殊情况，出现冲突是不可避免的。对于这种情况，我们有以下方式进行处理：</p><ol><li><p>线性探测：将冲突键存储在数组中的其他位置，可能存储在下一个开放数组空间中。这种方法可以通过分布式哈希表看到。</p></li><li><p>外部链接：一个更简单的解决方案是将具有相同哈希值的所有键一起存储在它们自己的集合中，例如 <em>LinkedList</em> 。这种共享单个索引的条目集合称为<strong>存储桶</strong>。</p></li></ol><p>对于哈希表，一旦表中数据越来越倾向于饱和，发生冲突和错误的可能性就越大。因此，动态调整哈希表的大小是十分必要的。</p><p>为了跟踪哈希表的填充程度，我们定义了术语负载因子，它是插入的元素数量与数组总物理长度的比率。</p><p>$$load \ factor&#x3D;\frac{size()}{array.length}$$</p><p>对于我们的哈希表，我们将定义允许的最大负载因子。如果添加另一个键值对会导致负载因子超过指定的最大负载因子，则应调整哈希表的大小。这通常是通过将基础数组长度加倍来完成的。 Java 默认的最大负载因子是 0.75，它在合理大小的数组和减少冲突之间提供了良好的平衡。</p><h1 id="Heaps-and-Priority-Queues"><a href="#Heaps-and-Priority-Queues" class="headerlink" title="Heaps and Priority Queues"></a>Heaps and Priority Queues</h1><p>在二叉搜索树BST中，我们能够高效地搜索到需要的元素，只需要 $\log{}{N}$ 的时间复杂度。如果我们更加关心快速找到最小或最大元素而不是快速搜索怎么办？</p><h2 id="Priority-Queue"><a href="#Priority-Queue" class="headerlink" title="Priority Queue"></a>Priority Queue</h2><p>我们先来看优先队列的接口：在我们定义的最小优先队列中，我们只能与队列中的最小元素进行交互。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/** (Min) Priority Queue: Allowing tracking and removal of </span><br><span class="hljs-comment">  * the smallest item in a priority queue. */</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">interface</span> <span class="hljs-title class_">MinPQ</span>&lt;Item&gt; &#123;<br>    <span class="hljs-comment">/** Adds the item to the priority queue. */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">add</span><span class="hljs-params">(Item x)</span>;<br>    <span class="hljs-comment">/** Returns the smallest item in the priority queue. */</span><br>    <span class="hljs-keyword">public</span> Item <span class="hljs-title function_">getSmallest</span><span class="hljs-params">()</span>;<br>    <span class="hljs-comment">/** Removes the smallest item from the priority queue. */</span><br>    <span class="hljs-keyword">public</span> Item <span class="hljs-title function_">removeSmallest</span><span class="hljs-params">()</span>;<br>    <span class="hljs-comment">/** Returns the size of the priority queue. */</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">size</span><span class="hljs-params">()</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>我们考虑使用已经学习过的数据结构进行实现：</p><ol><li>Ordered Array 有序数组</li><li>BST 二叉搜索树</li><li>HashTable 哈希表</li></ol><h2 id="Heaps"><a href="#Heaps" class="headerlink" title="Heaps"></a>Heaps</h2><p>经过比较，我们发现BST具有已知的最佳运行效率。我们考虑在BST的基础上继续进行改进，可以进一步提高这些操作的运行时间效率。</p><p>我们定义 Heap 的数据结构，这是一种<strong>完全二叉树</strong>，即具有：</p><ol><li>堆序性质（Heap Property）：在堆中，对于每个节点 i，父节点的键值小于或等于（小顶堆）或大于或等于（大顶堆）其子节点的键值。</li><li>完全二叉树结构（Complete Binary Tree Structure）：堆是一种完全二叉树，即除了最底层节点，其他层的节点都是满的，最底层节点都尽可能地靠左排列。</li></ol><p>堆分为两种类型：最小堆和最大堆。在最小堆中，父节点的键值始终小于或等于其子节点的键值；而在最大堆中，父节点的键值始终大于或等于其子节点的键值。</p><p>Java实现最小优先队列的示例代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">import</span> java.util.PriorityQueue;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">MinPriorityQueue</span>&lt;T <span class="hljs-keyword">extends</span> <span class="hljs-title class_">Comparable</span>&lt;T&gt;&gt; &#123;<br>    <span class="hljs-keyword">private</span> PriorityQueue&lt;T&gt; heap;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">MinPriorityQueue</span><span class="hljs-params">()</span> &#123;<br>        heap = <span class="hljs-keyword">new</span> <span class="hljs-title class_">PriorityQueue</span>&lt;&gt;();<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">insert</span><span class="hljs-params">(T item)</span> &#123;<br>        heap.offer(item);<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> T <span class="hljs-title function_">extractMin</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">return</span> heap.poll();<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> T <span class="hljs-title function_">peekMin</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">return</span> heap.peek();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>如果不调用封装好的类，我们可以用计数器的思想实现优先级。即：计数器在每次插入项目时都会递增。最近插入的项目始终具有更高的优先级，因此它们将首先被删除。</p><p>一个可能的示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">import</span> java.util.LinkedList;<br><span class="hljs-keyword">import</span> java.util.Queue;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">CountingPriorityQueue</span>&lt;T&gt; &#123;<br>    <span class="hljs-keyword">private</span> Queue&lt;Element&lt;T&gt;&gt; queue;<br>    <span class="hljs-keyword">private</span> <span class="hljs-type">int</span> count;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">CountingPriorityQueue</span><span class="hljs-params">()</span> &#123;<br>        queue = <span class="hljs-keyword">new</span> <span class="hljs-title class_">LinkedList</span>&lt;&gt;();<br>        count = <span class="hljs-number">0</span>;<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">insert</span><span class="hljs-params">(T item, <span class="hljs-type">int</span> priority)</span> &#123;<br>        queue.offer(<span class="hljs-keyword">new</span> <span class="hljs-title class_">Element</span>&lt;&gt;(item, priority, count++));<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> T <span class="hljs-title function_">extractMin</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">if</span> (queue.isEmpty())<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">null</span>;<br>        Element&lt;T&gt; minElement = queue.poll();<br>        <span class="hljs-keyword">return</span> minElement.item;<br>    &#125;<br><br>    <span class="hljs-comment">// 定义一个内部类来表示带有优先级和插入顺序的元素</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Element</span>&lt;E&gt; <span class="hljs-keyword">implements</span> <span class="hljs-title class_">Comparable</span>&lt;Element&lt;E&gt;&gt; &#123;<br>        E item;<br>        <span class="hljs-type">int</span> priority;<br>        <span class="hljs-type">int</span> insertionOrder;<br><br>        Element(E item, <span class="hljs-type">int</span> priority, <span class="hljs-type">int</span> insertionOrder) &#123;<br>            <span class="hljs-built_in">this</span>.item = item;<br>            <span class="hljs-built_in">this</span>.priority = priority;<br>            <span class="hljs-built_in">this</span>.insertionOrder = insertionOrder;<br>        &#125;<br><br>        <span class="hljs-meta">@Override</span><br>        <span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">compareTo</span><span class="hljs-params">(Element&lt;E&gt; other)</span> &#123;<br>            <span class="hljs-keyword">if</span> (<span class="hljs-built_in">this</span>.priority != other.priority) &#123;<br>                <span class="hljs-keyword">return</span> Integer.compare(<span class="hljs-built_in">this</span>.priority, other.priority);<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                <span class="hljs-keyword">return</span> Integer.compare(<span class="hljs-built_in">this</span>.insertionOrder, other.insertionOrder);<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>一般而言，Heap有如下的性质使得它能很方便地实现优先队列的数据结构：</p><ol><li><p>高效的插入和删除操作：堆的插入和删除操作的时间复杂度为 $O(log n)$ ，其中n是堆中元素的数量。这使得堆非常适合用于实现优先队列，因为在优先队列中，我们经常需要插入和删除元素。</p></li><li><p>快速访问最小（或最大）元素：堆允许在常数时间内 $O(1)$ 访问堆顶元素，这是因为堆的根节点始终是最小（或最大）的元素。这对于优先队列来说非常重要，因为我们经常需要知道当前队列中优先级最高的元素。</p></li><li><p>自动维护顺序：堆具有自我调整的性质，即在插入或删除元素后，堆会自动调整其结构以保持堆的性质。这意味着我们不需要手动维护堆的顺序，从而简化了代码实现。</p></li><li><p>支持动态大小：堆可以动态地调整大小，因此可以容纳任意数量的元素。这使得堆非常适合用于实现优先队列，因为我们通常不知道在队列中需要存储多少元素。</p></li></ol><p>一些有意思的点：<br>按降序排序的数组是最大堆（根是最大值，值按级别顺序递减）。</p><h1 id="Graph"><a href="#Graph" class="headerlink" title="Graph"></a>Graph</h1><p>一般来说，图由两部分组成：</p><ol><li>一组节点</li><li>一组边，有向或无向</li></ol><p>所有树也是图，但并非所有图都是树。</p><p>对于图，我们一般考虑下列问题：</p><ol><li>路径：顶点 s 和 t 之间是否存在路径？</li><li>连通性：图是否连通，即所有顶点之间是否存在路径？</li><li>双连通性：是否存在删除某个顶点会断开图的连接？</li><li>最短 s-t 路径：顶点 s 和 t 之间的最短路径是多少？</li><li>环路检测：图表中是否存在环路？</li><li>同构：两个图是否同构（同构图）？</li></ol><p>总体来说，最根本的还是一个问题：我们如何遍历图？</p><h2 id="Graph-traversal"><a href="#Graph-traversal" class="headerlink" title="Graph traversal"></a>Graph traversal</h2><p>我们先关注第一个问题:如何确定两个节点 $s$ 和 $t$ 之间是否存在路径.</p><p>我们考虑一个函数：它接受两个顶点并返回两者之间是否存在路径。实现这个函数，我们可以以第一个节点为参考节点，然后访问他的一个邻居节点并将自己标记为已查找。之后对第二个节点递归的调用该函数知道找到目标节点或遍历完整个路径（所有节点均被标记）。</p><p>具体而言，可以拆解为以下步骤：</p><ol><li>从图中的某个顶点开始遍历，将该顶点标记为已访问。</li><li>递归地对该顶点的未访问邻居顶点进行深度优先遍历。</li><li>重复步骤2，直到该顶点的所有邻居顶点都被访问过。</li><li>回溯到上一个顶点，重复步骤2和步骤3，直到图中的所有顶点都被访问过。</li></ol><p>事实上，这正是图的<strong>深度优先遍历算法（Depth-First Search，DFS）</strong>。我们可以尝试用伪代码来实现一下：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs markdown">DFS(vertex):<br><span class="hljs-code">    将vertex标记为已访问</span><br><span class="hljs-code">    访问vertex</span><br><span class="hljs-code">    </span><br><span class="hljs-code">    对于vertex的每个未访问的邻居neighbor：</span><br><span class="hljs-code">        如果neighbor未被访问：</span><br><span class="hljs-code">            递归调用DFS(neighbor)</span><br></code></pre></td></tr></table></figure><p>我们也可以用栈来优化递归操作，在这里不做展示。</p><p>深度优先遍历算法的时间复杂度为 $O(V + E)$ ，其中 $V$ 是顶点的数量，$E$ 是边的数量。</p><p>事实上，我们也能用另一种思路解决这个问题：<br>我们先将第一个节点的所有邻居访问完成，然后逐层向下地访问其它节点。这一思想称为<strong>广度优先搜索（Breadth-First Search，BFS）</strong>。我们一般使用队列来进行实现：</p><ol><li>在遍历的过程中，先将起始顶点加入队列，然后重复以下步骤直到队列为空</li><li>弹出队列中的顶点，并访问该顶点。</li><li>遍历该顶点的所有邻居顶点，如果某个邻居顶点未被访问过，则将其加入队列，并标记为已访问。</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs java">BFS(Graph G, Vertex start):<br>    <span class="hljs-comment">// 初始化队列并将起始顶点入队</span><br>    Queue queue<br>    queue.enqueue(start)<br>    <span class="hljs-comment">// 标记起始顶点为已访问</span><br>    mark start as visited<br>    <br>    <span class="hljs-comment">// 循环直到队列为空</span><br>    <span class="hljs-keyword">while</span> queue is not empty:<br>        <span class="hljs-comment">// 弹出队列中的顶点，并访问该顶点</span><br>        current = queue.dequeue()<br>        visit current<br>        <br>        <span class="hljs-comment">// 遍历当前顶点的所有邻居顶点</span><br>        <span class="hljs-keyword">for</span> each neighbor of current:<br>            <span class="hljs-comment">// 如果邻居顶点未被访问过</span><br>            <span class="hljs-keyword">if</span> neighbor is not visited:<br>                <span class="hljs-comment">// 将邻居顶点标记为已访问，并入队</span><br>                mark neighbor as visited<br>                queue.enqueue(neighbor)<br></code></pre></td></tr></table></figure><h2 id="Graph-Representing"><a href="#Graph-Representing" class="headerlink" title="Graph Representing"></a>Graph Representing</h2><p>表示图的方式有很多，常见的是用邻接矩阵(Adjacency Matrix)和邻接表(Adjacency Lists)。</p><h3 id="Adjacency-Matrix"><a href="#Adjacency-Matrix" class="headerlink" title="Adjacency Matrix"></a>Adjacency Matrix</h3><p>使用二维数组。有一条边将顶点 s 连接到 t ，前提是相应的单元格是 1 （表示 true ）。请注意，如果图是无向的，则邻接矩阵将在其对角线上（从左上角到右下角）对称。  </p><h3 id="Adjacency-Lists"><a href="#Adjacency-Lists" class="headerlink" title="Adjacency Lists"></a>Adjacency Lists</h3><p>维护一个列表数组，按顶点号索引。如果存在从 s 到 t 的边，则数组索引 s 处的列表将包含 t 。</p><h2 id="Shortest-Paths–Dijkstra’s-Algorithm"><a href="#Shortest-Paths–Dijkstra’s-Algorithm" class="headerlink" title="Shortest Paths–Dijkstra’s Algorithm"></a>Shortest Paths–Dijkstra’s Algorithm</h2><p>Dijkstra算法是计算机科学中的一种流行算法，用于在图中找到节点之间的最短路径，特别是在具有非负边权重的图中。<br>该算法通过迭代地选择从源节点开始的已知距离最小的节点，并在发现更短路径时更新其相邻节点的距离来运作。它通过维护一个优先队列（通常用最小堆实现）来高效地选择下一个要探索的节点。</p><p>以下是Dijkstra算法的步骤概述：</p><ol><li><p>初始化： 将源节点的距离设置为0，将所有其他节点的距离设置为无穷大。初始化一个空的优先队列（或最小堆），用于按距离排序的节点。</p></li><li><p>选择下一个节点： 从优先队列中提取具有最小距离的节点。最初，这将是源节点。</p></li><li><p>更新相邻节点： 对于当前节点的每个相邻节点，计算通过当前节点到源节点的距离。如果此距离比先前已知的距离更短，则更新相邻节点的距离并更新其父节点（找到最短路径的节点）。将更新后的相邻节点插入优先队列。</p></li><li><p>重复： 重复步骤2和3，直到所有节点都被处理或达到目标节点。</p></li><li><p>最短路径重建： 一旦到达目标节点或所有节点都已处理，就可以通过在算法执行过程中存储的父指针回溯从目标节点到源节点，重建从源到目标的最短路径。</p></li></ol><p>下面是一个可能的伪代码实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">Dijkstra</span>(<span class="hljs-params">graph, source</span>):<br>    dist[source] = <span class="hljs-number">0</span> // 到源节点的距离为<span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> each vertex v <span class="hljs-keyword">in</span> graph:<br>        <span class="hljs-keyword">if</span> v ≠ source:<br>            dist[v] = ∞ // 到其他节点的距离初始化为无穷大<br>        add v to priority queue <span class="hljs-keyword">with</span> priority dist[v]<br>    <br>    <span class="hljs-keyword">while</span> priority queue <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> empty:<br>        u = remove vertex <span class="hljs-keyword">with</span> minimum dist[u] <span class="hljs-keyword">from</span> priority queue<br>        <span class="hljs-keyword">for</span> each neighbor v of u:<br>            alt = dist[u] + weight(u, v) // 计算通过u到达v的距离<br>            <span class="hljs-keyword">if</span> alt &lt; dist[v]: // 如果通过u到达v的距离更短<br>                dist[v] = alt // 更新到v的最短距离<br>                update priority queue <span class="hljs-keyword">with</span> new priority dist[v] // 更新优先队列中v的优先级<br></code></pre></td></tr></table></figure><h1 id="Minimum-Spanning-Trees"><a href="#Minimum-Spanning-Trees" class="headerlink" title="Minimum Spanning Trees"></a>Minimum Spanning Trees</h1><p>最小生成树（Minimum Spanning Tree，MST）是一种在连通加权图中找到的特殊树形结构，它包含了图中的所有顶点，并且是一个树，没有环路，同时权重之和最小。</p><p>割集（Cut Set）是指一个图中的边集合，当这些边被移除后，原本连通的图被分割成两个或多个不相连的子图。换句话说，割集是一组边，它们的移除会使得图中的顶点失去连接，导致图分裂成多个连通分量。</p><p>连支（Connected Components）是指图中的一组顶点，它们之间有路径相连，并且没有其他的顶点与这些顶点相连。连支是由顶点组成的集合，用于描述图的连通性。</p><p>寻找连通图的最小生成树，一般而言有两种算法，均基于贪心思想：</p><ol><li>Kruskal 算法</li><li>Prim 算法</li></ol><p>时间复杂度均为 $O(E\log{}{V})$ 。</p><h2 id="Prim’s-Algorithm"><a href="#Prim’s-Algorithm" class="headerlink" title="Prim’s Algorithm"></a>Prim’s Algorithm</h2><p>基本思想：<br>Prim 算法也是一种贪心策略，从一个初始顶点开始，逐步扩展最小生成树，每次选择与当前最小生成树相连的权重最小的边，并且不会形成环路。</p><p>Prim 算法在稠密图中效果更好，适用于边的数量与顶点数量相当的情况。</p><p>步骤：</p><ol><li>选择一个起始顶点作为初始树。</li><li>将与初始树相连的边加入候选边集合中。</li><li>从候选边集合中选择权重最小的边，将其加入最小生成树，并将其所连接的顶点加入最小生成树的顶点集合中。</li><li>重复步骤3，直到最小生成树包含了图中的所有顶点。</li></ol><h2 id="Kruskal’s-Algorithm"><a href="#Kruskal’s-Algorithm" class="headerlink" title="Kruskal’s Algorithm"></a>Kruskal’s Algorithm</h2><p>基本思想：<br>Kruskal 算法基于贪心策略，每次选择权重最小的边，如果这条边不形成环路，则将其加入最小生成树。</p><p>Kruskal 算法对于稀疏图效果较好，适用于边的数量远远大于顶点数量的情况。</p><p>步骤：</p><ol><li>将图中的所有边按照权重从小到大排序。</li><li>依次从排序后的边集合中选取边，如果选取的边不会形成环路（即加入这条边后不会出现环路），则将其加入最小生成树。</li><li>重复步骤2，直到最小生成树中包含了图中的所有顶点为止。</li></ol><h1 id="Mutidimensional-Data"><a href="#Mutidimensional-Data" class="headerlink" title="Mutidimensional Data"></a>Mutidimensional Data</h1><p>对于一维数据的存储，我们有十分简便的比较大小的方式。但是对于二维乃至于多维的数据，如果我们想要分类，一个依据是每个维度进行大小的比较，这时候就需要增加树的节点个数来表示不同的区间。</p><h2 id="Quadtree"><a href="#Quadtree" class="headerlink" title="Quadtree"></a>Quadtree</h2><p>四叉树（Quadtree）是一种用于表示二维空间的树形数据结构，它将二维空间递归地划分为四个象限，每个象限可以继续划分为四个子象限，以此类推。四叉树常用于表示和管理二维数据。</p><ol><li>空间划分：四叉树将二维空间划分为四个象限：左上、右上、左下、右下。每个象限可以继续划分为四个子象限，以此类推，直到达到某个终止条件。</li><li>节点结构：四叉树的节点包含四个指针，分别指向其四个子节点。如果一个节点没有子节点，则称为叶子节点。叶子节点通常包含相应区域内的数据。</li><li>查询操作：四叉树可以快速进行区域查询和范围查询。区域查询用于查找落在给定区域内的所有数据点，而范围查询用于查找与给定点距离不超过一定范围内的所有数据点。</li><li>空间分析：四叉树可以用于进行空间分析，如判断两个区域是否相交、计算区域的面积、查找最近邻点等。</li></ol><h2 id="K-D-Trees"><a href="#K-D-Trees" class="headerlink" title="K-D Trees"></a>K-D Trees</h2><p>KD 树（K-Dimensional Tree）是一种二叉树数据结构，用于对 k 维空间中的数据进行分割和组织。KD 树常被用于对多维数据进行搜索、范围查询和最近邻搜索等操作。</p><ol><li>空间划分：KD 树通过递归地将 k 维空间划分为轴对齐的超矩形区域。每个节点代表一个超矩形区域，其子节点对应于该区域被分割后的子区域。</li><li>轴选择：在构建 KD 树时，每次选择一个坐标轴作为切分的依据。通常，轴的选择是交替进行的，比如在二维空间中就是交替选择 x 轴和 y 轴。</li><li>节点结构：KD 树的节点包含一个数据点以及指向左右子节点的指针。根据选择的切分轴，左子节点的数据点在该轴上小于当前节点的值，右子节点的数据点在该轴上大于当前节点的值。</li><li>搜索操作：KD 树可以用于范围查询和最近邻搜索。范围查询用于查找落在给定超矩形区域内的所有数据点，最近邻搜索用于查找离给定点最近的数据点。</li></ol><p>构建 KD 树的步骤：</p><ol><li>选择初始轴（通常是坐标轴）。</li><li>根据选定的轴，找到中位数，将数据集分为两部分。</li><li>递归地构建左右子树，重复步骤 1 和步骤 2，直到每个区域只包含一个数据点为止。</li></ol><p>最近邻搜索算法（Nearest Neighbor Search）：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-keyword">def</span> <span class="hljs-title function_">NNS</span>(<span class="hljs-params">root, target</span>):<br>    best_node = <span class="hljs-literal">None</span><br>    best_distance = <span class="hljs-built_in">float</span>(<span class="hljs-string">&#x27;inf&#x27;</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">nearest</span>(<span class="hljs-params">node</span>):<br>        <span class="hljs-keyword">if</span> node = <span class="hljs-literal">None</span>:<br>            <span class="hljs-keyword">return</span><br>        axis = node.axis<br>        <span class="hljs-comment"># 这里的distance一般指欧氏距离</span><br>        current_distance = distance(node, target)<br>        <span class="hljs-keyword">if</span> current_distance &lt; best_distance:<br>            best_node = node<br>            best_distance = current_distance<br>        <span class="hljs-keyword">elif</span> target[axis] &lt; node[axis]:<br>            nearest(node.left)<br>            <span class="hljs-keyword">if</span> target[axis] + best_distance &gt;= node[axis]:<br>                nearest(node.right)<br>        <span class="hljs-keyword">else</span>:<br>            nearest(node.right)<br>            <span class="hljs-keyword">if</span> target[axis] - best_distance &lt;= node[axis]:<br>                nearest(node.left)<br></code></pre></td></tr></table></figure><h1 id="Prefix-Operations-and-Tire"><a href="#Prefix-Operations-and-Tire" class="headerlink" title="Prefix Operations and Tire"></a>Prefix Operations and Tire</h1><p>前缀操作（Prefix operation）是一种数学和计算机科学中的操作符表示法，其中运算符位于其操作数之前。这种表示法也称为波兰记法或前缀表示法。在前缀表示法中，运算符位于操作数之前，这与我们通常使用的中缀表示法（如2 + 3）或后缀表示法（逆波兰表示法，如2 3 +）不同。</p><p>例如，常见的算术表达式“2 + 3”在前缀表示法中将写为“+ 2 3”。在这个例子中，“+”是运算符，而“2”和“3”是操作数。</p><p>前缀表示法具有几个优点：</p><ol><li>无需括号：由于运算符位于操作数之前，不需要使用括号来表示优先级。</li><li>易于计算：计算机在处理前缀表示法时通常使用栈来进行计算，这使得计算过程更加简洁和高效。</li><li>易于转换：前缀表示法可以很容易地转换为后缀表示法或中缀表示法，从而便于人们阅读和理解。</li></ol><p>对于前缀操作，我们可以使用Tire树进行相关操作。</p><h2 id="Tire-Tree"><a href="#Tire-Tree" class="headerlink" title="Tire Tree"></a>Tire Tree</h2><p>Trie树（也称为前缀树或字典树）是一种树形数据结构，用于存储动态集合，其中键通常是字符串。Trie树的名称来源于”retrieval”，表明其主要用途是支持快速的检索操作。</p><p>在Trie树中，每个节点代表一个字符，通常从根节点开始，到达每个节点的路径表示从根到该节点的字符序列。叶节点通常表示一个完整的单词，但也可能只是一个前缀。</p><p>一个简单实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">TrieSet</span> &#123;<br>   <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">int</span> <span class="hljs-variable">R</span> <span class="hljs-operator">=</span> <span class="hljs-number">128</span>; <span class="hljs-comment">// ASCII</span><br>   <span class="hljs-keyword">private</span> Node root;    <span class="hljs-comment">// root of trie</span><br><br>   <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Node</span> &#123;<br>      <span class="hljs-keyword">private</span> <span class="hljs-type">boolean</span> isKey;   <br>      <span class="hljs-keyword">private</span> DataIndexedCharMap next;<br><br>      <span class="hljs-keyword">private</span> <span class="hljs-title function_">Node</span><span class="hljs-params">(<span class="hljs-type">boolean</span> blue, <span class="hljs-type">int</span> R)</span> &#123;<br>         isKey = blue;<br>         next = <span class="hljs-keyword">new</span> <span class="hljs-title class_">DataIndexedCharMap</span>&lt;Node&gt;(R);<br>      &#125;<br>   &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>为了让Tire能够高效地进行前缀匹配操作，我们可以定义一些方法：</p><p>首先我们考虑定义一个 <em>collect</em> 方法，该方法可以用于返回Tire中的所有键。<br>伪代码：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs py">collect():<br>    Create an empty <span class="hljs-built_in">list</span> of results x<br>    For character c <span class="hljs-keyword">in</span> root.<span class="hljs-built_in">next</span>.keys():<br>        Call colHelp(c, x, root.<span class="hljs-built_in">next</span>.get(c))<br>    Return x<br><br>colHelp(String s, <span class="hljs-type">List</span>&lt;String&gt; x, Node n):<br>    <span class="hljs-keyword">if</span> n.isKey:<br>        x.add(s)<br>    For character c <span class="hljs-keyword">in</span> n.<span class="hljs-built_in">next</span>.keys():<br>        Call colHelp(s + c, x, n.<span class="hljs-built_in">next</span>.get(c))<br></code></pre></td></tr></table></figure><p>基于 <em>collect</em> 方法，我们可以定义 <em>keyWithPrefix</em> 方法，返回具有特定前缀的所有键。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs py">keysWithPrefix(String s):<br>    Find the end of the prefix, alpha<br>    Create an empty <span class="hljs-built_in">list</span> x<br>    For character <span class="hljs-keyword">in</span> alpha.<span class="hljs-built_in">next</span>.keys():<br>        Call colHelp(<span class="hljs-string">&quot;sa&quot;</span> + c, x, alpha.<span class="hljs-built_in">next</span>.get(c))<br>    Return x<br></code></pre></td></tr></table></figure><h1 id="DAG-and-Topological-Sorting"><a href="#DAG-and-Topological-Sorting" class="headerlink" title="DAG and Topological Sorting"></a>DAG and Topological Sorting</h1><p>拓扑排序（Topological Sorting）是一种用于有向图的排序算法，它能够将图中的节点按照它们之间的依赖关系进行排序，使得所有的依赖关系都得到满足。</p><p>在拓扑排序中，如果存在一条从节点 A 到节点 B 的路径，那么在排序结果中节点 A 将位于节点 B 之前。换句话说，所有的依赖关系都是从左到右的。</p><p>拓扑排序通常应用于有向无环图（DAG），因为有向无环图是一种没有循环依赖的图，可以通过拓扑排序进行有效的排序。</p><p><img src="/Pictures/CS61b/02/DAG.png" alt="DAG"></p><p>对于上图中的DAG，我们有这样的一些有效的拓扑排序：</p><ol><li>$[D, B, A, E, C, F]$</li><li>$[E, D, C, B, A, F]$</li></ol><p>对于任何拓扑排序，我们都可以重绘图形使每个顶点都位于一条直线上，这称为图的线性化。</p><p><img src="/Pictures/CS61b/02/Linear.png" alt="DAG"></p><h2 id="Topological-Sort-Algorithm"><a href="#Topological-Sort-Algorithm" class="headerlink" title="Topological Sort Algorithm"></a>Topological Sort Algorithm</h2><p>我们一般利用DFS（深度优先搜索）来实现对DAG的拓扑排序。</p><ol><li>对于有向图中的每个节点，初始化一个标记数组，用于标记节点是否被访问过，以及一个栈或者列表用于存储排序结果。</li><li>从图中任意未被访问的节点开始，对每个未被访问的节点执行步骤 3。</li><li>对于当前节点，进行深度优先搜索：<ul><li>将当前节点标记为已访问。</li><li>对当前节点的所有邻居节点（即当前节点指向的节点）进行递归调用步骤 3。</li><li>将当前节点压入栈或者添加到列表中。</li></ul></li><li>当对当前节点的所有邻居节点都完成了深度优先搜索后，返回到步骤 2，选择另一个未被访问的节点进行深度优先搜索。</li><li>当所有节点都被访问并完成深度优先搜索后，栈或列表中的顺序就是拓扑排序的结果。</li></ol><p>利用python实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">topological_sort</span>(<span class="hljs-params">graph</span>):<br>    visited = <span class="hljs-built_in">set</span>()<br>    stack = []<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">dfs</span>(<span class="hljs-params">node</span>):<br>        visited.add(node)<br>        <span class="hljs-keyword">for</span> neighbor <span class="hljs-keyword">in</span> graph.get(node, []):<br>            <span class="hljs-keyword">if</span> neighbor <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> visited:<br>                dfs(neighbor)<br>        stack.append(node)<br><br>    <span class="hljs-keyword">for</span> node <span class="hljs-keyword">in</span> graph:<br>        <span class="hljs-keyword">if</span> node <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> visited:<br>            dfs(node)<br><br>    <span class="hljs-keyword">return</span> stack[::-<span class="hljs-number">1</span>]<br></code></pre></td></tr></table></figure><h2 id="Shortest-Paths-on-DAGs"><a href="#Shortest-Paths-on-DAGs" class="headerlink" title="Shortest Paths on DAGs"></a>Shortest Paths on DAGs</h2><p>Dijkstra算法可以计算最短路径，但是在边的权重为负值时，算法无法保证有效性。</p><p>我们考虑使用拓扑排序加动态规划的思想，对Dijkstra算法进行补全。</p><p>下面给出一个可能的步骤：</p><ol><li>对 DAG 进行拓扑排序，得到节点的拓扑排序顺序。</li><li>初始化一个距离数组，用于存储从起始节点到每个节点的最短距离。将起始节点的距离设为 0，其他节点的距离设为正无穷大。</li><li>按照拓扑排序的顺序依次处理每个节点：<ul><li>对于当前节点 u，遍历其所有的邻居节点 v。</li><li>对于每个邻居节点 v，更新其距离为 min(当前距离[v], 当前距离[u] + 边(u, v)的权重)。</li></ul></li><li>最终，距离数组中存储的就是从起始节点到每个节点的最短路径长度。</li></ol><h1 id="Sorts"><a href="#Sorts" class="headerlink" title="Sorts"></a>Sorts</h1><p>在最后，我们了解并实践一些常见的排序算法。</p><p><img src="/Pictures/CS61b/02/sort.png" alt="sort"></p><h2 id="Bubble-Sort"><a href="#Bubble-Sort" class="headerlink" title="Bubble Sort"></a>Bubble Sort</h2><p>冒泡排序（Bubble Sort）也是一种简单直观的排序算法。它重复地走访过要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。这个算法的名字由来是因为越小的元素会经由交换慢慢”浮”到数列的顶端。</p><p><img src="/Pictures/CS61b/02/bubbleSort.gif" alt="bubbleSort"></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Sort</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">bubbleSort</span><span class="hljs-params">(<span class="hljs-type">int</span>[] nums)</span> &#123;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; nums.length; i++) &#123;<br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> <span class="hljs-variable">j</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; j &lt; nums.length - i - <span class="hljs-number">1</span>; j++) &#123;<br>                <span class="hljs-type">int</span> temp;<br>                <span class="hljs-keyword">if</span>(nums[j] &gt; nums[j+<span class="hljs-number">1</span>]) &#123;<br>                    temp = nums[j];<br>                    nums[j] = nums[j+<span class="hljs-number">1</span>];<br>                    nums[j+<span class="hljs-number">1</span>] = temp;<br>                &#125;<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="Select-Sort"><a href="#Select-Sort" class="headerlink" title="Select Sort"></a>Select Sort</h2><p>选择排序的基本思想：首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置。</p><p>再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。</p><p>重复第二步，直到所有元素均排序完毕。</p><p><img src="/Pictures/CS61b/02/selectionSort.gif" alt="selectSort"></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Sort</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">selectSort</span><span class="hljs-params">(<span class="hljs-type">int</span>[] nums)</span> &#123;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">len</span> <span class="hljs-operator">=</span> nums.length;<br>        <span class="hljs-type">int</span> minIndex, temp;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; len; i++) &#123;<br>            minIndex = i;<br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> <span class="hljs-variable">j</span> <span class="hljs-operator">=</span> i + <span class="hljs-number">1</span>; j &lt; len; j++) &#123;<br>                <span class="hljs-keyword">if</span>(nums[j] &lt; nums[minIndex]) &#123;<br>                    minIndex = j;<br>                &#125;<br>            &#125;<br>            temp = arr[i];<br>            arr[i] = arr[minIndex];<br>            arr[minIndex] = temp;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="Insert-Sort"><a href="#Insert-Sort" class="headerlink" title="Insert Sort"></a>Insert Sort</h2><p>插入排序是一种最简单直观的排序算法，它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。</p><p><img src="/Pictures/CS61b/02/insertSort.gif" alt="insertSort"></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Sort</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">insertSort</span><span class="hljs-params">(<span class="hljs-type">int</span>[] nums)</span> &#123;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">len</span> <span class="hljs-operator">=</span> nums.length;<br>        <span class="hljs-type">int</span> preIndex, current;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; i &lt; len; i++) &#123;<br>            preIndex = i - <span class="hljs-number">1</span>;<br>            current = nums[i];<br>            <span class="hljs-keyword">while</span>(preIndex &gt;= <span class="hljs-number">0</span> &amp;&amp; nums[preIndex] &gt; current) &#123;<br>                nums[PreIndex + <span class="hljs-number">1</span>] = nums[preIndex];<br>                preIndex--;<br>            &#125;<br>            arr[preIndex + <span class="hljs-number">1</span>] = current;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="Shell-Sort"><a href="#Shell-Sort" class="headerlink" title="Shell Sort"></a>Shell Sort</h2><p>希尔排序的基本思想是：先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，待整个序列中的记录”基本有序”时，再对全体记录进行依次直接插入排序。</p><p><img src="/Pictures/CS61b/02/shellSort.gif" alt="shellSort"></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Sort</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">shellSort</span><span class="hljs-params">(<span class="hljs-type">int</span>[] nums)</span> &#123;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">len</span> <span class="hljs-operator">=</span> nums.length;<br>        <span class="hljs-type">int</span> temp, gap = <span class="hljs-number">1</span>;<br>        <span class="hljs-keyword">while</span>(gap &lt; len/<span class="hljs-number">3</span>) &#123;<br>            gap = gap*<span class="hljs-number">3</span>+<span class="hljs-number">1</span>;<br>        &#125;<br>        <span class="hljs-keyword">for</span>(gap; gap &gt;<span class="hljs-number">0</span>; gap = gap/<span class="hljs-number">3</span>) &#123;<br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> gap; i &lt; len; i++) &#123;<br>                temp = nums[i];<br>                <span class="hljs-type">int</span> <span class="hljs-variable">j</span> <span class="hljs-operator">=</span> i - gap;<br>                <span class="hljs-keyword">for</span>(j; j &gt;=<span class="hljs-number">0</span> &amp;&amp; nums[j] &gt; temp; j -= gap) &#123;<br>                    nums[j+gap] = nums[j];<br>                &#125;<br>                nums[j+gap] = temp;<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="Merge-Sort"><a href="#Merge-Sort" class="headerlink" title="Merge Sort"></a>Merge Sort</h2><p>归并排序（Merge sort）是建立在归并操作上的一种有效的排序算法。该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。</p><p><img src="/Pictures/CS61b/02/mergeSort.gif" alt="mergeSort"></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Sort</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-type">int</span>[] sort(<span class="hljs-type">int</span>[] nums) &#123;<br>        <span class="hljs-keyword">if</span>(nums.length &lt; <span class="hljs-number">2</span>) &#123;<br>            <span class="hljs-keyword">return</span> nums;<br>        &#125;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">mid</span> <span class="hljs-operator">=</span> nums.length / <span class="hljs-number">2</span>;<br>        <span class="hljs-type">int</span>[] left = Array.copyOfRange(nums, <span class="hljs-number">0</span>, mid);<br>        <span class="hljs-type">int</span>[] right = Array.copyOfRange(nums, mid, nums.length);<br>        <span class="hljs-keyword">return</span> merge(sort(left), sort(right));<br>    &#125;<br>    <br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-type">int</span>[] merge(<span class="hljs-type">int</span>[] left, <span class="hljs-type">int</span>[] right) &#123;<br>        <span class="hljs-type">int</span>[] result = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[left.length + right.length];<br>        <span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">while</span> (left.length &gt; <span class="hljs-number">0</span> &amp;&amp; right.length &gt; <span class="hljs-number">0</span>) &#123;<br>            <span class="hljs-keyword">if</span> (left[<span class="hljs-number">0</span>] &lt;= right[<span class="hljs-number">0</span>]) &#123;<br>                result[i++] = left[<span class="hljs-number">0</span>];<br>                left = Arrays.copyOfRange(left, <span class="hljs-number">1</span>, left.length);<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                result[i++] = right[<span class="hljs-number">0</span>];<br>                right = Arrays.copyOfRange(right, <span class="hljs-number">1</span>, right.length);<br>            &#125;<br>        &#125;<br><br>        <span class="hljs-keyword">while</span> (left.length &gt; <span class="hljs-number">0</span>) &#123;<br>            result[i++] = left[<span class="hljs-number">0</span>];<br>            left = Arrays.copyOfRange(left, <span class="hljs-number">1</span>, left.length);<br>        &#125;<br><br>        <span class="hljs-keyword">while</span> (right.length &gt; <span class="hljs-number">0</span>) &#123;<br>            result[i++] = right[<span class="hljs-number">0</span>];<br>            right = Arrays.copyOfRange(right, <span class="hljs-number">1</span>, right.length);<br>        &#125;<br><br>        <span class="hljs-keyword">return</span> result;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="Heap-Sort"><a href="#Heap-Sort" class="headerlink" title="Heap Sort"></a>Heap Sort</h2><p>堆排序（Heapsort）是指利用堆这种数据结构所设计的一种排序算法。堆积是一个近似完全二叉树的结构，并同时满足堆积的性质：即子结点的键值或索引总是小于（或者大于）它的父节点。堆排序可以说是一种利用堆的概念来排序的选择排序。分为两种方法：</p><ol><li>大顶堆：每个节点的值都大于或等于其子节点的值，在堆排序算法中用于升序排列；</li><li>小顶堆：每个节点的值都小于或等于其子节点的值，在堆排序算法中用于降序排列；<br>堆排序的平均时间复杂度为 Ο(nlogn)。</li></ol><p><img src="/Pictures/CS61b/02/heapSort.gif" alt="heapSort"></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Sort</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">heapSort</span><span class="hljs-params">(<span class="hljs-type">int</span>[] arr)</span> &#123;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">n</span> <span class="hljs-operator">=</span> arr.length;<br><br>        <span class="hljs-comment">// 构建最大堆（Heapify）</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> n / <span class="hljs-number">2</span> - <span class="hljs-number">1</span>; i &gt;= <span class="hljs-number">0</span>; i--) &#123;<br>            heapify(arr, n, i);<br>        &#125;<br><br>        <span class="hljs-comment">// 逐个从堆顶取出元素并进行堆调整</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> n - <span class="hljs-number">1</span>; i &gt; <span class="hljs-number">0</span>; i--) &#123;<br>            <span class="hljs-comment">// 将当前堆顶元素（最大元素）与未排序部分的最后一个元素交换</span><br>            <span class="hljs-type">int</span> <span class="hljs-variable">temp</span> <span class="hljs-operator">=</span> arr[<span class="hljs-number">0</span>];<br>            arr[<span class="hljs-number">0</span>] = arr[i];<br>            arr[i] = temp;<br><br>            <span class="hljs-comment">// 对交换后的堆顶元素进行堆调整</span><br>            heapify(arr, i, <span class="hljs-number">0</span>);<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-comment">// 堆调整</span><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">heapify</span><span class="hljs-params">(<span class="hljs-type">int</span>[] arr, <span class="hljs-type">int</span> n, <span class="hljs-type">int</span> i)</span> &#123;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">largest</span> <span class="hljs-operator">=</span> i; <span class="hljs-comment">// 初始化最大值索引为当前节点</span><br>        <span class="hljs-type">int</span> <span class="hljs-variable">left</span> <span class="hljs-operator">=</span> <span class="hljs-number">2</span> * i + <span class="hljs-number">1</span>; <span class="hljs-comment">// 左子节点索引</span><br>        <span class="hljs-type">int</span> <span class="hljs-variable">right</span> <span class="hljs-operator">=</span> <span class="hljs-number">2</span> * i + <span class="hljs-number">2</span>; <span class="hljs-comment">// 右子节点索引</span><br><br>        <span class="hljs-comment">// 找出当前节点、左子节点和右子节点中的最大值索引</span><br>        <span class="hljs-keyword">if</span> (left &lt; n &amp;&amp; arr[left] &gt; arr[largest]) &#123;<br>            largest = left;<br>        &#125;<br>        <span class="hljs-keyword">if</span> (right &lt; n &amp;&amp; arr[right] &gt; arr[largest]) &#123;<br>            largest = right;<br>        &#125;<br><br>        <span class="hljs-comment">// 如果最大值索引不是当前节点，则交换当前节点与最大值节点，并递归调整子堆</span><br>        <span class="hljs-keyword">if</span> (largest != i) &#123;<br>            <span class="hljs-type">int</span> <span class="hljs-variable">temp</span> <span class="hljs-operator">=</span> arr[i];<br>            arr[i] = arr[largest];<br>            arr[largest] = temp;<br>            <span class="hljs-comment">// 递归调整子堆</span><br>            heapify(arr, n, largest);<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="Quick-Sort"><a href="#Quick-Sort" class="headerlink" title="Quick Sort"></a>Quick Sort</h2><p>快速排序是由东尼·霍尔所发展的一种排序算法。在平均状况下，排序 n 个项目要 Ο(nlogn) 次比较。在最坏状况下则需要 Ο(n2) 次比较，但这种状况并不常见。事实上，快速排序通常明显比其他 Ο(nlogn) 算法更快，因为它的内部循环（inner loop）可以在大部分的架构上很有效率地被实现出来。</p><p>快速排序使用分治法（Divide and conquer）策略来把一个串行（list）分为两个子串行（sub-lists）。</p><p>快速排序又是一种分而治之思想在排序算法上的典型应用。本质上来看，快速排序应该算是在冒泡排序基础上的递归分治法。</p><p>算法步骤：</p><ol><li><p>从数列中挑出一个元素，称为 “基准”（pivot）;</p></li><li><p>重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区退出之后，该基准就处于数列的中间位置。这个称为分区（partition）操作；</p></li><li><p>递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序；</p></li></ol><p><img src="/Pictures/CS61b/02/quickSort.gif" alt="quickSort"></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Sort</span> &#123;<br>    <span class="hljs-keyword">private</span> <span class="hljs-type">int</span>[] quickSort(<span class="hljs-type">int</span>[] arr, <span class="hljs-type">int</span> left, <span class="hljs-type">int</span> right) &#123;<br>        <span class="hljs-keyword">if</span> (left &lt; right) &#123;<br>            <span class="hljs-type">int</span> <span class="hljs-variable">partitionIndex</span> <span class="hljs-operator">=</span> partition(arr, left, right);<br>            quickSort(arr, left, partitionIndex - <span class="hljs-number">1</span>);<br>            quickSort(arr, partitionIndex + <span class="hljs-number">1</span>, right);<br>        &#125;<br>        <span class="hljs-keyword">return</span> arr;<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-type">int</span> <span class="hljs-title function_">partition</span><span class="hljs-params">(<span class="hljs-type">int</span>[] arr, <span class="hljs-type">int</span> left, <span class="hljs-type">int</span> right)</span> &#123;<br>        <span class="hljs-comment">// 设定基准值（pivot）</span><br>        <span class="hljs-type">int</span> <span class="hljs-variable">pivot</span> <span class="hljs-operator">=</span> left;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">index</span> <span class="hljs-operator">=</span> pivot + <span class="hljs-number">1</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> index; i &lt;= right; i++) &#123;<br>            <span class="hljs-keyword">if</span> (arr[i] &lt; arr[pivot]) &#123;<br>                swap(arr, i, index);<br>                index++;<br>            &#125;<br>        &#125;<br>        swap(arr, pivot, index - <span class="hljs-number">1</span>);<br>        <span class="hljs-keyword">return</span> index - <span class="hljs-number">1</span>;<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">swap</span><span class="hljs-params">(<span class="hljs-type">int</span>[] arr, <span class="hljs-type">int</span> i, <span class="hljs-type">int</span> j)</span> &#123;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">temp</span> <span class="hljs-operator">=</span> arr[i];<br>        arr[i] = arr[j];<br>        arr[j] = temp;<br>    &#125;<br><br>&#125;<br></code></pre></td></tr></table></figure><h2 id="Counting-sort"><a href="#Counting-sort" class="headerlink" title="Counting sort"></a>Counting sort</h2><p>计数排序（Counting Sort）是一种非比较型的整数排序算法，它利用输入数据的特定范围进行排序。计数排序的基本思想是统计每个输入元素的出现次数，然后根据元素的值和出现次数，将元素放置到正确的位置上。</p><p>以一个例子说明：<br>假设我们有一个待排序的整数数组 <code>[4, 2, 2, 8, 3, 3, 1]</code>。</p><ol><li><p>确定输入数据的范围（最大值和最小值）。在这个例子中，最大值是 8，最小值是 1。</p></li><li><p>创建计数数组，并统计每个元素的出现次数。</p><table><thead><tr><th>元素</th><th>出现次数</th></tr></thead><tbody><tr><td>1</td><td>1</td></tr><tr><td>2</td><td>2</td></tr><tr><td>3</td><td>2</td></tr><tr><td>4</td><td>1</td></tr><tr><td>5</td><td>0</td></tr><tr><td>6</td><td>0</td></tr><tr><td>7</td><td>0</td></tr><tr><td>8</td><td>1</td></tr></tbody></table></li><li><p>将计数数组转换为每个元素在输出数组中的起始位置。</p><table><thead><tr><th>元素</th><th>出现次数</th><th>起始位置</th></tr></thead><tbody><tr><td>1</td><td>1</td><td>0</td></tr><tr><td>2</td><td>2</td><td>1</td></tr><tr><td>3</td><td>2</td><td>3</td></tr><tr><td>4</td><td>1</td><td>5</td></tr><tr><td>5</td><td>0</td><td>6</td></tr><tr><td>6</td><td>0</td><td>6</td></tr><tr><td>7</td><td>0</td><td>6</td></tr><tr><td>8</td><td>1</td><td>7</td></tr></tbody></table></li><li><p>创建输出数组，并将待排序数组中的元素放置到输出数组的正确位置上。</p><ul><li>从待排序数组的最后一个元素开始遍历，即 <code>arr = [4, 2, 2, 8, 3, 3, 1]</code>。</li><li>当前元素是 1，在计数数组中的起始位置是 0，因此放置到输出数组的索引位置为 0。</li><li>当前元素是 3，在计数数组中的起始位置是 3，因此放置到输出数组的索引位置为 3。</li><li>当前元素是 3，在计数数组中的起始位置是 3，因此放置到输出数组的索引位置为 4。</li><li>依此类推，将所有元素放置到输出数组的正确位置上。</li></ul></li><li><p>输出数组即为排序后的结果。在这个例子中，排序后的数组是 <code>[1, 2, 2, 3, 3, 4, 8]</code>。</p></li></ol><p><img src="/Pictures/CS61b/02/countingSort.gif" alt="countingSort"></p><p>算法实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Sort</span> &#123;<br>     <span class="hljs-keyword">private</span> <span class="hljs-type">int</span>[] countingSort(<span class="hljs-type">int</span>[] arr, <span class="hljs-type">int</span> maxValue) &#123;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">bucketLen</span> <span class="hljs-operator">=</span> maxValue + <span class="hljs-number">1</span>;<br>        <span class="hljs-type">int</span>[] bucket = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[bucketLen];<br><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> value : arr) &#123;<br>            bucket[value]++;<br>        &#125;<br><br>        <span class="hljs-type">int</span> <span class="hljs-variable">sortedIndex</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">j</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; j &lt; bucketLen; j++) &#123;<br>            <span class="hljs-keyword">while</span> (bucket[j] &gt; <span class="hljs-number">0</span>) &#123;<br>                arr[sortedIndex++] = j;<br>                bucket[j]--;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> arr;<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-type">int</span> <span class="hljs-title function_">getMaxValue</span><span class="hljs-params">(<span class="hljs-type">int</span>[] arr)</span> &#123;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">maxValue</span> <span class="hljs-operator">=</span> arr[<span class="hljs-number">0</span>];<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> value : arr) &#123;<br>            <span class="hljs-keyword">if</span> (maxValue &lt; value) &#123;<br>                maxValue = value;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> maxValue;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="Bucket-Sort"><a href="#Bucket-Sort" class="headerlink" title="Bucket Sort"></a>Bucket Sort</h2><p>桶排序是计数排序的升级版。它利用了函数的映射关系，高效与否的关键就在于这个映射函数的确定。为了使桶排序更加高效，我们需要做到这两点：</p><ol><li>在额外空间充足的情况下，尽量增大桶的数量</li><li>使用的映射函数能够将输入的 N 个数据均匀的分配到 K 个桶中<br>同时，对于桶中元素的排序，选择何种比较排序算法对于性能的影响至关重要。</li></ol><p><img src="/Pictures/CS61b/02/Bucket_sort_1.svg_.png" alt="bucketSort"><br><img src="/Pictures/CS61b/02/Bucket_sort_2.svg_.png" alt="bucketSort"></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Sort</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">bucketSort</span><span class="hljs-params">(<span class="hljs-type">double</span>[] arr)</span> &#123;<br>        <span class="hljs-keyword">if</span> (arr == <span class="hljs-literal">null</span> || arr.length &lt;= <span class="hljs-number">1</span>) &#123;<br>            <span class="hljs-keyword">return</span>;<br>        &#125;<br><br>        <span class="hljs-type">int</span> <span class="hljs-variable">n</span> <span class="hljs-operator">=</span> arr.length;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">numOfBuckets</span> <span class="hljs-operator">=</span> n; <span class="hljs-comment">// 设置桶的数量为待排序数组的长度</span><br>        ArrayList&lt;Double&gt;[] buckets = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ArrayList</span>[numOfBuckets];<br><br>        <span class="hljs-comment">// 初始化每个桶</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; numOfBuckets; i++) &#123;<br>            buckets[i] = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ArrayList</span>&lt;&gt;();<br>        &#125;<br><br>        <span class="hljs-comment">// 将元素放入对应的桶中</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">double</span> num : arr) &#123;<br>            <span class="hljs-type">int</span> <span class="hljs-variable">bucketIndex</span> <span class="hljs-operator">=</span> (<span class="hljs-type">int</span>) (num * numOfBuckets);<br>            buckets[bucketIndex].add(num);<br>        &#125;<br><br>        <span class="hljs-comment">// 对每个桶中的元素进行排序</span><br>        <span class="hljs-keyword">for</span> (ArrayList&lt;Double&gt; bucket : buckets) &#123;<br>            Collections.sort(bucket);<br>        &#125;<br><br>        <span class="hljs-comment">// 将排序后的元素依次放回原数组</span><br>        <span class="hljs-type">int</span> <span class="hljs-variable">index</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span> (ArrayList&lt;Double&gt; bucket : buckets) &#123;<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">double</span> num : bucket) &#123;<br>                arr[index++] = num;<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><h2 id="LSD-Radix-Sort"><a href="#LSD-Radix-Sort" class="headerlink" title="LSD Radix Sort"></a>LSD Radix Sort</h2><p>基数排序是一种非比较型整数排序算法，其原理是将整数按位数切割成不同的数字，然后按每个位数分别比较。由于整数也可以表达字符串（比如名字或日期）和特定格式的浮点数，所以基数排序也不是只能使用于整数。</p><p>LSD 基数排序的基本步骤如下：</p><ol><li>确定关键字的位数（即数字的最大位数）。</li><li>从最低有效位（最右边的位）开始，按照当前位的值进行稳定排序。</li><li>重复上述步骤，直到对所有位进行了排序。</li></ol><p>这三种排序算法都利用了桶的概念，但对桶的使用方法上有明显差异：</p><ul><li>基数排序：根据键值的每位数字来分配桶；</li><li>计数排序：每个桶只存储单一键值；</li><li>桶排序：每个桶存储一定范围的数值；</li></ul><p><img src="/Pictures/CS61b/02/radixSort.gif" alt="radixSort"></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">import</span> java.util.Arrays;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Sort</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">lsdRadixSort</span><span class="hljs-params">(<span class="hljs-type">int</span>[] arr)</span> &#123;<br>        <span class="hljs-comment">// 确定关键字的位数</span><br>        <span class="hljs-type">int</span> <span class="hljs-variable">maxDigits</span> <span class="hljs-operator">=</span> getMaxDigits(arr);<br><br>        <span class="hljs-comment">// 进行 LSD 基数排序</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">digit</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; digit &lt;= maxDigits; digit++) &#123;<br>            countingSort(arr, digit);<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">getMaxDigits</span><span class="hljs-params">(<span class="hljs-type">int</span>[] arr)</span> &#123;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">maxDigits</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> num : arr) &#123;<br>            maxDigits = Math.max(maxDigits, getDigitCount(num));<br>        &#125;<br>        <span class="hljs-keyword">return</span> maxDigits;<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">getDigitCount</span><span class="hljs-params">(<span class="hljs-type">int</span> num)</span> &#123;<br>        <span class="hljs-keyword">if</span> (num == <span class="hljs-number">0</span>) &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;<br>        &#125;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">count</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">while</span> (num != <span class="hljs-number">0</span>) &#123;<br>            count++;<br>            num /= <span class="hljs-number">10</span>;<br>        &#125;<br>        <span class="hljs-keyword">return</span> count;<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">countingSort</span><span class="hljs-params">(<span class="hljs-type">int</span>[] arr, <span class="hljs-type">int</span> digit)</span> &#123;<br>        <span class="hljs-keyword">final</span> <span class="hljs-type">int</span> <span class="hljs-variable">BASE</span> <span class="hljs-operator">=</span> <span class="hljs-number">10</span>; <span class="hljs-comment">// 基数为 10，表示十进制数</span><br><br>        <span class="hljs-type">int</span>[] output = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[arr.length];<br>        <span class="hljs-type">int</span>[] count = <span class="hljs-keyword">new</span> <span class="hljs-title class_">int</span>[BASE];<br><br>        <span class="hljs-comment">// 统计当前位上每个数字出现的次数</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> num : arr) &#123;<br>            <span class="hljs-type">int</span> <span class="hljs-variable">digitValue</span> <span class="hljs-operator">=</span> getDigitValue(num, digit);<br>            count[digitValue]++;<br>        &#125;<br><br>        <span class="hljs-comment">// 将 count 数组转换为每个数字在输出数组中的起始位置</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">1</span>; i &lt; BASE; i++) &#123;<br>            count[i] += count[i - <span class="hljs-number">1</span>];<br>        &#125;<br><br>        <span class="hljs-comment">// 从右向左遍历原数组，将数字放入正确的位置</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> arr.length - <span class="hljs-number">1</span>; i &gt;= <span class="hljs-number">0</span>; i--) &#123;<br>            <span class="hljs-type">int</span> <span class="hljs-variable">num</span> <span class="hljs-operator">=</span> arr[i];<br>            <span class="hljs-type">int</span> <span class="hljs-variable">digitValue</span> <span class="hljs-operator">=</span> getDigitValue(num, digit);<br>            output[count[digitValue] - <span class="hljs-number">1</span>] = num;<br>            count[digitValue]--;<br>        &#125;<br>        System.arraycopy(output, <span class="hljs-number">0</span>, arr, <span class="hljs-number">0</span>, arr.length);<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">getDigitValue</span><span class="hljs-params">(<span class="hljs-type">int</span> num, <span class="hljs-type">int</span> digit)</span> &#123;<br>        <span class="hljs-keyword">return</span> (num / (<span class="hljs-type">int</span>) Math.pow(<span class="hljs-number">10</span>, digit - <span class="hljs-number">1</span>)) % <span class="hljs-number">10</span>;<br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><h1 id="My-Thoughts"><a href="#My-Thoughts" class="headerlink" title="My Thoughts"></a>My Thoughts</h1><p><strong>Coming soon</strong></p><p><img src="/Pictures/CS61b/02/end.png" alt="end"></p>]]></content>
    
    
    <categories>
      
      <category>CS61b</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>新闻主题分类</title>
    <link href="/2024/02/25/06-%E6%96%B0%E9%97%BB%E4%B8%BB%E9%A2%98%E5%88%86%E7%B1%BB/"/>
    <url>/2024/02/25/06-%E6%96%B0%E9%97%BB%E4%B8%BB%E9%A2%98%E5%88%86%E7%B1%BB/</url>
    
    <content type="html"><![CDATA[<p>接下来我们利用浅层神经网络构建新闻主题分类器的实现过程。</p><p>数据集使用 <em>torchtext.datasets.AG_NEWS</em></p><p>数据集中包含了</p><ul><li>World</li><li>Sports</li><li>Business</li><li>Sci&#x2F;Tech</li></ul><p>这四种类别，我们需要做的就是训练模型对数据进行分类。</p><p>神经网络的训练和构建大致分为以下步骤：</p><ol><li>构建带有Embedding层的文本分类模型</li><li>对数据进行batch处理</li><li>构建训练与验证函数</li><li>进行模型训练和验证</li><li>查看Embedding层嵌入的词向量</li></ol><h2 id="1-构建带有Embedding层的文本分类模型"><a href="#1-构建带有Embedding层的文本分类模型" class="headerlink" title="1.构建带有Embedding层的文本分类模型"></a>1.构建带有Embedding层的文本分类模型</h2><p>下面是对基本网络的构建。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br>BATCH_SIZE = <span class="hljs-number">16</span><br>device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;CPU&quot;</span>)<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">TextSentiment</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, text</span>):<br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        :param vocab_size:整个语料包含的不同词汇总数</span><br><span class="hljs-string">        :param embed_dim:指定词嵌入的维度</span><br><span class="hljs-string">        :param num_class:文本分类的维度</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.embedding = nn.Embedding(vocab_size, embed_dim, sparse=<span class="hljs-literal">True</span>)<br>        self.fc = nn.Linear(embed_dim, num_class)<br>        self.init_weights()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">init_weights</span>(<span class="hljs-params">self</span>):<br>        initrange = <span class="hljs-number">0.5</span><br>        self.embedding.weight.data.uniform_(-initrange, initrange)<br>        self.fc.weight.data.uniform_(-initrange,initrange)<br>        self.fc.bias.data.zero_()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, text</span>):<br>        embedded = self.embedding(text)<br>        c = embedded.size(<span class="hljs-number">0</span>)<br>        embedded = embedded[:BATCH_SIZE*c]<br>        embedded = embedded.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">0</span>).unsqueeze(<span class="hljs-number">0</span>)<br>        embedded = F.avg_pool1d(embedded, kernel_size=c)<br>        <span class="hljs-keyword">return</span> self.fc<br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>文本预处理</title>
    <link href="/2024/02/24/NLP%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    <url>/2024/02/24/NLP%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</url>
    
    <content type="html"><![CDATA[<h1 id="文本预处理以及其作用"><a href="#文本预处理以及其作用" class="headerlink" title="文本预处理以及其作用"></a>文本预处理以及其作用</h1><p>文本语料在输送给模型前一般需要一系列的预处理工作，才能符合模型输入的要求，如：将文本转化成模型需要的张量，规范张量的尺寸等，而且科学的文本预处理环节还将有效指导模型超参数的选择，提升模型的评估指标。</p><h1 id="文本预处理中包含的主要环节"><a href="#文本预处理中包含的主要环节" class="headerlink" title="文本预处理中包含的主要环节"></a>文本预处理中包含的主要环节</h1><ul><li>文本预处理的基本方法</li><li>文本张量表示方法</li><li>文本语料的数据分析</li><li>文本特征处理</li><li>数据增强方法</li></ul><p>我们主要针对中文和英文进行处理</p><h1 id="1-文本预处理的基本方法"><a href="#1-文本预处理的基本方法" class="headerlink" title="1.文本预处理的基本方法"></a>1.文本预处理的基本方法</h1><h2 id="分词"><a href="#分词" class="headerlink" title="分词"></a>分词</h2><p><a href="https://github.com/fxsjy/jieba">https://github.com/fxsjy/jieba</a></p><p>jieba库可以帮助我们对句子进行切分，作为Tokenizer使用。</p><ol><li>精确模式：将句子最精确的切开（cut_all &#x3D; False）</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> jieba<br>content = <span class="hljs-string">&quot;坚决维护习近平总书记党中央的核心、全党的核心地位，坚决维护党中央权威和集中统一领导。&quot;</span><br>jieba.cut(content, cut_all=<span class="hljs-literal">False</span>)    <span class="hljs-comment">#cut_all默认为False</span><br><br><span class="hljs-comment"># 将返回一个生成器对象</span><br><span class="hljs-comment"># &lt;generator object Tokenizer.cut at ......&gt;</span><br><br><span class="hljs-comment"># 也可直接返回列表内容</span><br>out = jieba.lcut(content, cut_all=<span class="hljs-literal">False</span>)<br><span class="hljs-built_in">print</span>(out)<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs scheme">[<span class="hljs-symbol">&#x27;坚决</span>&#x27;, <span class="hljs-symbol">&#x27;维护</span>&#x27;, <span class="hljs-symbol">&#x27;习近平</span>&#x27;, <span class="hljs-symbol">&#x27;总书记</span>&#x27;, <span class="hljs-symbol">&#x27;党中央</span>&#x27;, <span class="hljs-symbol">&#x27;的</span>&#x27;, <span class="hljs-symbol">&#x27;核心</span>&#x27;, <span class="hljs-symbol">&#x27;、</span>&#x27;, <span class="hljs-symbol">&#x27;全党</span>&#x27;, <span class="hljs-symbol">&#x27;的</span>&#x27;, <span class="hljs-symbol">&#x27;核心</span>&#x27;, <span class="hljs-symbol">&#x27;地位</span>&#x27;, <span class="hljs-symbol">&#x27;，</span>&#x27;, <span class="hljs-symbol">&#x27;坚决</span>&#x27;, <span class="hljs-symbol">&#x27;维护</span>&#x27;, <span class="hljs-symbol">&#x27;党中央</span>&#x27;, <span class="hljs-symbol">&#x27;权威</span>&#x27;, <span class="hljs-symbol">&#x27;和</span>&#x27;, <span class="hljs-symbol">&#x27;集中统一</span>&#x27;, <span class="hljs-symbol">&#x27;领导</span>&#x27;, <span class="hljs-symbol">&#x27;。</span>&#x27;]<br></code></pre></td></tr></table></figure><ol start="2"><li>全模式分词：把句子中所有可以成词的词语都扫描出来，速度快但会产生歧义。</li></ol><p>将变量 <em>cut_all &#x3D; Ture</em> ,输出下面结果：</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs scheme">[<span class="hljs-symbol">&#x27;坚决</span>&#x27;, <span class="hljs-symbol">&#x27;维护</span>&#x27;, <span class="hljs-symbol">&#x27;习近平</span>&#x27;, <span class="hljs-symbol">&#x27;总书记</span>&#x27;, <span class="hljs-symbol">&#x27;书记</span>&#x27;, <span class="hljs-symbol">&#x27;党中央</span>&#x27;, <span class="hljs-symbol">&#x27;中央</span>&#x27;, <span class="hljs-symbol">&#x27;的</span>&#x27;, <span class="hljs-symbol">&#x27;核心</span>&#x27;, <span class="hljs-symbol">&#x27;、</span>&#x27;, <span class="hljs-symbol">&#x27;全党</span>&#x27;, <span class="hljs-symbol">&#x27;的</span>&#x27;, <span class="hljs-symbol">&#x27;核心</span>&#x27;, <span class="hljs-symbol">&#x27;心地</span>&#x27;, <span class="hljs-symbol">&#x27;地位</span>&#x27;, <span class="hljs-symbol">&#x27;，</span>&#x27;, <span class="hljs-symbol">&#x27;坚决</span>&#x27;, <span class="hljs-symbol">&#x27;维护</span>&#x27;, <span class="hljs-symbol">&#x27;党中央</span>&#x27;, <span class="hljs-symbol">&#x27;中央</span>&#x27;, <span class="hljs-symbol">&#x27;权威</span>&#x27;, <span class="hljs-symbol">&#x27;和</span>&#x27;, <span class="hljs-symbol">&#x27;集中</span>&#x27;, <span class="hljs-symbol">&#x27;集中统一</span>&#x27;, <span class="hljs-symbol">&#x27;中统</span>&#x27;, <span class="hljs-symbol">&#x27;统一</span>&#x27;, <span class="hljs-symbol">&#x27;领导</span>&#x27;, <span class="hljs-symbol">&#x27;。</span>&#x27;]<br></code></pre></td></tr></table></figure><ol start="3"><li>搜索引擎模式分词：对长词再次切分，提高召回率。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">out = jieba.lcut_for_search(content)<br><span class="hljs-built_in">print</span>(out)<br></code></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs scheme">[<span class="hljs-symbol">&#x27;坚决</span>&#x27;, <span class="hljs-symbol">&#x27;维护</span>&#x27;, <span class="hljs-symbol">&#x27;习近平</span>&#x27;, <span class="hljs-symbol">&#x27;书记</span>&#x27;, <span class="hljs-symbol">&#x27;总书记</span>&#x27;, <span class="hljs-symbol">&#x27;中央</span>&#x27;, <span class="hljs-symbol">&#x27;党中央</span>&#x27;, <span class="hljs-symbol">&#x27;的</span>&#x27;, <span class="hljs-symbol">&#x27;核心</span>&#x27;, <span class="hljs-symbol">&#x27;、</span>&#x27;, <span class="hljs-symbol">&#x27;全党</span>&#x27;, <span class="hljs-symbol">&#x27;的</span>&#x27;, <span class="hljs-symbol">&#x27;核心</span>&#x27;, <span class="hljs-symbol">&#x27;地位</span>&#x27;, <span class="hljs-symbol">&#x27;，</span>&#x27;, <span class="hljs-symbol">&#x27;坚决</span>&#x27;, <span class="hljs-symbol">&#x27;维护</span>&#x27;, <span class="hljs-symbol">&#x27;中央</span>&#x27;, <span class="hljs-symbol">&#x27;党中央</span>&#x27;, <span class="hljs-symbol">&#x27;权威</span>&#x27;, <span class="hljs-symbol">&#x27;和</span>&#x27;, <span class="hljs-symbol">&#x27;集中</span>&#x27;, <span class="hljs-symbol">&#x27;中统</span>&#x27;, <span class="hljs-symbol">&#x27;统一</span>&#x27;, <span class="hljs-symbol">&#x27;集中统一</span>&#x27;, <span class="hljs-symbol">&#x27;领导</span>&#x27;, <span class="hljs-symbol">&#x27;。</span>&#x27;]<br></code></pre></td></tr></table></figure><ol start="4"><li>使用用户自定义词典：</li></ol><ul><li>添加自定义词典后，jieba能够准确识别词典中出现的词汇，提升整体的识别准确率</li><li>词典格式：每一行分为三部分（词语，词频，词性，用空格隔开，顺序不可换）</li></ul><h2 id="流行中英文分词器hanlp"><a href="#流行中英文分词器hanlp" class="headerlink" title="流行中英文分词器hanlp"></a>流行中英文分词器hanlp</h2><ul><li>中英文NLP处理工具包，基于tensorflow2.0，使用在学术和行业中推广最先进的深度学习技术</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> hanlp<br>tokenizer = hanlp.load(<span class="hljs-string">&#x27;CTB6_CONVSEG&#x27;</span>)<br><span class="hljs-built_in">input</span> = <span class="hljs-string">&#x27;学历不但是敲门砖，也是我下不来的高台，更是孔乙己脱不下的长衫。&#x27;</span><br>tokenizer(<span class="hljs-built_in">input</span>)<br></code></pre></td></tr></table></figure><h2 id="命名实体的识别"><a href="#命名实体的识别" class="headerlink" title="命名实体的识别"></a>命名实体的识别</h2><p>对句子进行切分之后，我们可以进行命名实体的识别</p><ul><li><p>命名实体：通常我们将人名、地名、机构名等专有名词统称为命名实体。命名实体识别（Named Entity Recognition）就是识别出一段文本中可能的命名实体。</p></li><li><p>命名实体是人类理解文本的基础单元，也是AI解决NLP领域高阶任务的重要基础环节。</p></li></ul><p>我们可以使用hanlp进行中文命名实体的识别。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> hanlp<br>recognizer = hanlp.load(hanlp.pretrained.ner.MSRA_NER_BERT_BASE_ZH)<br></code></pre></td></tr></table></figure><h2 id="词性标注（Part-Of-Speech-tagging）"><a href="#词性标注（Part-Of-Speech-tagging）" class="headerlink" title="词性标注（Part-Of-Speech tagging）"></a>词性标注（Part-Of-Speech tagging）</h2><ul><li>词性标注以分词为基础，是对文本语言的另一个角度的理解，也常常称为AI解决NLP领域的高阶任务的重要基础环节。</li></ul><p>使用jieba进行中文词性标注：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> jieba.posseg <span class="hljs-keyword">as</span> posseg<br><span class="hljs-built_in">print</span>(posseg.lcut(<span class="hljs-string">&#x27;我是小明，我爱上海交通大学&#x27;</span>))<br></code></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs scheme">[<span class="hljs-name">pair</span>(<span class="hljs-symbol">&#x27;我</span>&#x27;, <span class="hljs-symbol">&#x27;r</span>&#x27;), pair(<span class="hljs-symbol">&#x27;是</span>&#x27;, <span class="hljs-symbol">&#x27;v</span>&#x27;), pair(<span class="hljs-symbol">&#x27;小明</span>&#x27;, <span class="hljs-symbol">&#x27;nr</span>&#x27;), pair(<span class="hljs-symbol">&#x27;，</span>&#x27;, <span class="hljs-symbol">&#x27;x</span>&#x27;), pair(<span class="hljs-symbol">&#x27;我</span>&#x27;, <span class="hljs-symbol">&#x27;r</span>&#x27;), pair(<span class="hljs-symbol">&#x27;爱</span>&#x27;, <span class="hljs-symbol">&#x27;v</span>&#x27;), pair(<span class="hljs-symbol">&#x27;上海交通大学</span>&#x27;, <span class="hljs-symbol">&#x27;nt</span>&#x27;)]<br></code></pre></td></tr></table></figure><table><thead><tr><th>标签</th><th>含义</th><th>标签</th><th>含义</th><th>标签</th><th>含义</th><th>标签</th><th>含义</th></tr></thead><tbody><tr><td>n</td><td>普通名词</td><td>f</td><td>方位名词</td><td>s</td><td>处所名词</td><td>t</td><td>时间</td></tr><tr><td>nr</td><td>人名</td><td>ns</td><td>地名</td><td>nt</td><td>机构名</td><td>nw</td><td>作品名</td></tr><tr><td>nz</td><td>其他专名</td><td>v</td><td>普通动词</td><td>vd</td><td>动副词</td><td>vn</td><td>名动词</td></tr><tr><td>a</td><td>形容词</td><td>ad</td><td>副形词</td><td>an</td><td>名形词</td><td>d</td><td>副词</td></tr><tr><td>m</td><td>数量词</td><td>q</td><td>量词</td><td>r</td><td>代词</td><td>p</td><td>介词</td></tr><tr><td>c</td><td>连词</td><td>u</td><td>助词</td><td>xc</td><td>其他虚词</td><td>w</td><td>标点符号</td></tr><tr><td>PER</td><td>人名</td><td>LOC</td><td>地名</td><td>ORG</td><td>机构名</td><td>TIME</td><td>时间</td></tr></tbody></table><h1 id="2-文本张量表示方法"><a href="#2-文本张量表示方法" class="headerlink" title="2.文本张量表示方法"></a>2.文本张量表示方法</h1><p>文本张量表示：讲一段文本使用张量进行表示，其中一般词汇表示成向量，称为词向量，再由各个词向量按顺序组成矩阵形成文本表示。</p><p>例子：[“学历”,”是”,”我”,”下不来的”,”高台”]<br>&#x3D;&#x3D;&gt;    [[1.32, 4.11, 2.33],<br>        [5.32, 6.11, 2.53],<br>        [1.22, 4.16, 2.83],<br>        [8.32, 6.61, 2.83],<br>        [8.62, 4.71, 2.73]]</p><h2 id="文本张量表示的方法"><a href="#文本张量表示的方法" class="headerlink" title="文本张量表示的方法"></a>文本张量表示的方法</h2><ul><li>one-hot编码</li></ul><p>One-hot编码是将每个词或字符映射到一个唯一的整数索引，然后创建一个向量，长度与词汇表大小相同，所有元素为0，除了对应索引处的元素为1。例如，假设我们有一个词汇表包含4个词：[“apple”, “banana”, “orange”, “grape”]，则每个词可以被编码为：</p><p>apple: [1, 0, 0, 0]<br>banana: [0, 1, 0, 0]<br>orange: [0, 0, 1, 0]<br>grape: [0, 0, 0, 1]<br>One-hot编码的优点是简单直观，并且不会引入任何语义相关性。然而，它也存在一些缺点，比如编码的向量维度很大，且无法捕捉词汇之间的语义相似性。</p><ul><li><p>one-hot编码实现</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">form sklearn.externals <span class="hljs-keyword">import</span> joblib<br>form keras.preprocessing.text <span class="hljs-keyword">import</span> Tokenizer<br>vocab = &#123;&#125;<br>t = Tokenizer(num_words = <span class="hljs-literal">None</span>, char_level=<span class="hljs-literal">False</span>)<br>t.fit_on_texts(vocab)<br><br><span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> vocab:<br>    zero_list = [<span class="hljs-number">0</span>]*<span class="hljs-built_in">len</span>(vocab)<br>    token_index = t.texts_to_sequences([token])[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>] - <span class="hljs-number">1</span><br>    zero_list[token_index] = <span class="hljs-number">1</span><br><span class="hljs-comment"># 保存</span><br>tokenizer_path = <span class="hljs-string">&quot;./Tokenizer&quot;</span><br>joblib.dump(t, tokenizer_path)<br></code></pre></td></tr></table></figure></li><li><p>one-hot编码使用</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 使用</span><br>t = joblib.load(tokenizer_path)<br>token = <span class="hljs-string">&quot;词&quot;</span><br>token_index = t.texts_to_sequences([token])[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>] - <span class="hljs-number">1</span><br>zero_list = [<span class="hljs-number">0</span>]*<span class="hljs-built_in">len</span>(vocab)<br>zero_list[token_index] = <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><ul><li>Word2vec</li></ul><p>Word2Vec是一种词嵌入技术，它能够将词汇映射到一个连续的低维向量空间。</p><p>Word2Vec模型通过学习大量文本语料库中的上下文信息来产生这些向量。其核心思想是：在一个窗口内，一个词的上下文可以帮助我们理解这个词的含义。</p><p>Word2Vec生成的词向量具有一定的语义关系，即在向量空间中相似的词在语义上也是相似的。例如，通过Word2Vec训练得到的词向量，可以通过计算向量之间的距离来找出语义上相似的词。</p><p>Word2Vec模型有两种主要的架构：连续词袋（CBOW）和Skip-gram。</p><ul><li>CBOW（Continuous Bag of Words）：通过上下文词预测目标词。</li></ul><p>CBOW在给定的一段文本语料中选调某段长度 <p style="color: #FF0000;">（窗口）</p> 作为研究对象，使用上下文词汇进行预测.</p><p><img src="/Pictures/DL/03/plot01.jpg" alt="img"></p><p>分析：图中窗口大小为9，使用前后4个词汇预测中心词。</p><p>CBOW模型的工作原理：</p><ol><li><p>输入层：CBOW模型的输入层接收由上下文词汇表示的One-hot编码。假设我们使用窗口大小为2的上下文，对于给定的目标词汇，上下文词汇包括其左右两个词汇。</p></li><li><p>投影层：输入的One-hot编码经过一个投影层，将每个One-hot编码映射到一个连续的低维向量空间，即词向量空间。</p></li><li><p>合并层：合并层将所有上下文词汇的词向量进行平均或求和，得到一个表示上下文信息的向量。</p></li><li><p>输出层：合并后的上下文向量通过输出层进行预测，输出层是一个softmax分类器，用于预测词汇表中每个词汇的概率分布。最终，模型选择概率最高的词汇作为预测的目标词汇</p></li></ol><p>假设我们有一个简单的语料库：”The cat sat on the mat.”</p><ol><li><p>输入：“The”、“sat”、“the”、“on” 的One-hot编码。</p></li><li><p>投影层：将上述词汇的One-hot编码映射到词向量空间。假设我们的词向量维度为3，每个词汇的向量表示如下：</p></li></ol><p>“The”：[0.2, 0.3, 0.1]<br>“sat”：[-0.1, 0.2, 0.4]<br>“the”：[0.3, -0.1, 0.2]<br>“on”：[0.4, 0.1, -0.3]</p><ol start="3"><li><p>合并层：将所有上下文词汇的词向量进行平均或求和。假设我们将它们求和，得到合并后的上下文向量为：[0.8, 0.5, 0.4]。</p></li><li><p>输出层：利用合并后的上下文向量，通过softmax分类器预测目标词汇的概率分布。例如，预测 “cat” 的概率为0.6，”dog” 的概率为0.3，”apple” 的概率为0.1。则模型将选择概率最高的词汇 “cat” 作为预测的目标词汇。</p></li></ol><ul><li>Skip-gram：通过目标词预测上下文词。<br>Skip-gram模型是Word2Vec中的一种模型，与CBOW模型相反，它的核心思想是根据目标词来预测上下文词，通过学习到的词向量来捕捉词汇之间的语义关系。</li></ul><p>结构模型：</p><ol><li><p>输入层：Skip-gram模型的输入是目标词的One-hot编码。</p></li><li><p>投影层：输入的One-hot编码经过一个投影层，将每个One-hot编码映射到一个连续的低维向量空间，即词向量空间。</p></li><li><p>输出层：投影后的目标词汇向量通过输出层，输出的是上下文词汇的概率分布。对于给定的目标词汇，Skip-gram模型试图学习到一个概率分布，使得给定目标词汇的情况下，其周围上下文词汇出现的概率最大化。输出层是一个softmax分类器，用于预测词汇表中每个词汇的概率分布。</p></li></ol><p>假设我们有一个简单的语料库：”The cat sat on the mat.”</p><ol><li><p>输入：“cat” 的One-hot编码。</p></li><li><p>投影层：将目标词汇的One-hot编码映射到词向量空间。假设我们的词向量维度为3，每个词汇的向量表示如下：</p></li></ol><p>“cat”：[0.2, 0.5, -0.1]</p><ol start="3"><li>输出层：利用投影后的目标词汇向量，通过softmax分类器预测周围上下文词汇的概率分布。例如，预测 “The” 的概率为0.6，”sat” 的概率为0.3，”mat” 的概率为0.1。则模型将选择概率最高的词汇作为上下文词汇的预测结果。</li></ol><ul><li>Word Embedding<br>Word Embedding是一种将词汇映射到实数向量的技术.</li></ul><p>广义的word embedding包括所有密集词汇向量的表示方法，狭义的word embedding指在神经网络中加入embedding层，对整个网络进行训练的同时产生的embedding矩阵。</p><h2 id="使用fasttext工具实现word2vec的训练和使用"><a href="#使用fasttext工具实现word2vec的训练和使用" class="headerlink" title="使用fasttext工具实现word2vec的训练和使用"></a>使用fasttext工具实现word2vec的训练和使用</h2><ol><li>获取训练数据</li><li>训练词向量</li><li>模型超参数设定</li><li>模型效果检验</li><li>模型的保存与重加载</li></ol><h3 id="获取训练数据"><a href="#获取训练数据" class="headerlink" title="获取训练数据"></a>获取训练数据</h3><p>在这里，我们研究 <em>Wikipedia</em> 的部分网页信息。<br>下载数据：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-variable">$</span> mkdir <span class="hljs-keyword">data</span><br><span class="hljs-variable">$</span> <span class="hljs-built_in">wget</span> <span class="hljs-literal">-c</span> http://mattmahoney.net/dc/enwik9.zip <span class="hljs-literal">-P</span> <span class="hljs-keyword">data</span><br><span class="hljs-variable">$</span> unzip <span class="hljs-keyword">data</span>/enwik9.zip <span class="hljs-literal">-d</span> <span class="hljs-keyword">data</span><br></code></pre></td></tr></table></figure><p>原始数据处理：我们需要将html语言中无用的符号去除。</p><p>这里我们使用fasttext中的Perl脚本Wikifil.pl</p><figure class="highlight perl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><code class="hljs perl"><span class="hljs-comment">#!/usr/bin/perl</span><br><br><span class="hljs-comment"># Program to filter Wikipedia XML dumps to &quot;clean&quot; text consisting only of lowercase</span><br><span class="hljs-comment"># letters (a-z, converted from A-Z), and spaces (never consecutive).  </span><br><span class="hljs-comment"># All other characters are converted to spaces.  Only text which normally appears </span><br><span class="hljs-comment"># in the web browser is displayed.  Tables are removed.  Image captions are </span><br><span class="hljs-comment"># preserved.  Links are converted to normal text.  Digits are spelled out.</span><br><br><span class="hljs-comment"># Written by Matt Mahoney, June 10, 2006.  This program is released to the public domain.</span><br><br>$/=<span class="hljs-string">&quot;&gt;&quot;</span>;                     <span class="hljs-comment"># input record separator</span><br><span class="hljs-keyword">while</span> (&lt;&gt;) &#123;<br>  <span class="hljs-keyword">if</span> (<span class="hljs-regexp">/&lt;text /</span>) &#123;$text=<span class="hljs-number">1</span>;&#125;  <span class="hljs-comment"># remove all but between &lt;text&gt; ... &lt;/text&gt;</span><br>  <span class="hljs-keyword">if</span> (<span class="hljs-regexp">/#redirect/i</span>) &#123;$text=<span class="hljs-number">0</span>;&#125;  <span class="hljs-comment"># remove #REDIRECT</span><br>  <span class="hljs-keyword">if</span> ($text) &#123;<br><br>    <span class="hljs-comment"># Remove any text not normally visible</span><br>    <span class="hljs-keyword">if</span> (<span class="hljs-regexp">/&lt;\/text&gt;/</span>) &#123;$text=<span class="hljs-number">0</span>;&#125;<br>    s/&lt;.*&gt;<span class="hljs-regexp">//</span>;               <span class="hljs-comment"># remove xml tags</span><br>    s/&amp;amp;<span class="hljs-regexp">/&amp;/g</span>;            <span class="hljs-comment"># decode URL encoded chars</span><br>    s/&amp;<span class="hljs-keyword">lt</span>;<span class="hljs-regexp">/&lt;/g</span>;<br>    <span class="hljs-regexp">s/&amp;gt;/&gt;/g</span>;<br>    <span class="hljs-regexp">s/&lt;ref[^&lt;]*&lt;\/ref&gt;//g</span>;  <span class="hljs-comment"># remove references &lt;ref...&gt; ... &lt;/ref&gt;</span><br>    s/&lt;[^&gt;]*&gt;<span class="hljs-regexp">//g</span>;           <span class="hljs-comment"># remove xhtml tags</span><br>    s/\[http:[^] ]*<span class="hljs-regexp">/[/g</span>;    <span class="hljs-comment"># remove normal url, preserve visible text</span><br>    s/\|thumb//ig;          <span class="hljs-comment"># remove images links, preserve caption</span><br>    s/\|left//ig;<br>    <span class="hljs-regexp">s/\|right//ig</span>;<br>    <span class="hljs-regexp">s/\|\d+px//ig</span>;<br>    <span class="hljs-regexp">s/\[\[image:[^\[\]]*\|//ig</span>;<br>    <span class="hljs-regexp">s/\[\[category:([^|\]]*)[^]]*\]\]/[[$1]]/ig</span>;  <span class="hljs-comment"># show categories without markup</span><br>    s/\[\[[a-z\-]*:[^\]]*\]\]//g;  <span class="hljs-comment"># remove links to other languages</span><br>    s/\[\[[^\|\]]*\|<span class="hljs-regexp">/[[/g</span>;  <span class="hljs-comment"># remove wiki url, preserve visible text</span><br>    s/\&#123;\&#123;[^\&#125;]*\&#125;\&#125;//g;         <span class="hljs-comment"># remove &#123;&#123;icons&#125;&#125; and &#123;tables&#125;</span><br>    s/\&#123;[^\&#125;]*\&#125;//g;<br>    <span class="hljs-regexp">s/\[//g</span>;                <span class="hljs-comment"># remove [ and ]</span><br>    s/\]//g;<br>    <span class="hljs-regexp">s/&amp;[^;]*;/ /g</span>;          <span class="hljs-comment"># remove URL encoded chars</span><br><br>    <span class="hljs-comment"># convert to lowercase letters and spaces, spell digits</span><br>    $_=<span class="hljs-string">&quot; $_ &quot;</span>;<br>    <span class="hljs-regexp">tr/A-Z/a-z/</span>;<br>    <span class="hljs-regexp">s/0/ zero /g</span>;<br>    <span class="hljs-regexp">s/1/ one /g</span>;<br>    <span class="hljs-regexp">s/2/ two /g</span>;<br>    <span class="hljs-regexp">s/3/ three /g</span>;<br>    <span class="hljs-regexp">s/4/ four /g</span>;<br>    <span class="hljs-regexp">s/5/ five /g</span>;<br>    <span class="hljs-regexp">s/6/ six /g</span>;<br>    <span class="hljs-regexp">s/7/ seven /g</span>;<br>    <span class="hljs-regexp">s/8/ eight /g</span>;<br>    <span class="hljs-regexp">s/9/ nine /g</span>;<br>    <span class="hljs-regexp">tr/a-z/ /</span>cs;<br>    <span class="hljs-keyword">chop</span>;<br>    <span class="hljs-keyword">print</span> $_;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="训练词向量"><a href="#训练词向量" class="headerlink" title="训练词向量"></a>训练词向量</h3><p>代码直接在解释器中运行。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> fasttext<br><span class="hljs-meta">&gt;&gt;&gt; </span>model = fasttext.train_unsupervised(<span class="hljs-string">&#x27;data/fil9&#x27;</span>)<br>Read 124M words<br>Number of words:  <span class="hljs-number">218316</span><br>Number of labels: <span class="hljs-number">0</span><br>Progress: <span class="hljs-number">100.0</span>% words/sec/thread:   <span class="hljs-number">48200</span> lr:  <span class="hljs-number">0.000000</span> avg.loss:  <span class="hljs-number">0.746600</span> ETA:   0h 0m 0s<br><br><span class="hljs-meta">&gt;&gt;&gt; </span>model.get_word_vector(<span class="hljs-string">&quot;the&quot;</span>)<br>array([ <span class="hljs-number">0.21138486</span>, -<span class="hljs-number">0.12589064</span>, -<span class="hljs-number">0.19342858</span>, -<span class="hljs-number">0.19221118</span>, -<span class="hljs-number">0.01785146</span>,<br>        <span class="hljs-number">0.01988586</span>, -<span class="hljs-number">0.31821433</span>, -<span class="hljs-number">0.02154824</span>, -<span class="hljs-number">0.03422537</span>, -<span class="hljs-number">0.13752697</span>,<br>        <span class="hljs-number">0.28236884</span>,  <span class="hljs-number">0.47459602</span>, -<span class="hljs-number">0.1452173</span> ,  <span class="hljs-number">0.08719557</span>,  <span class="hljs-number">0.11245055</span>,<br>       -<span class="hljs-number">0.01942564</span>, -<span class="hljs-number">0.38417512</span>, -<span class="hljs-number">0.10941568</span>,  <span class="hljs-number">0.04246465</span>, -<span class="hljs-number">0.11036458</span>,<br>        <span class="hljs-number">0.2774673</span> ,  <span class="hljs-number">0.20110597</span>,  <span class="hljs-number">0.3259078</span> , -<span class="hljs-number">0.12203481</span>,  <span class="hljs-number">0.12826309</span>,<br>       -<span class="hljs-number">0.11036057</span>,  <span class="hljs-number">0.39044794</span>, -<span class="hljs-number">0.04462426</span>, -<span class="hljs-number">0.02714067</span>,  <span class="hljs-number">0.11053375</span>,<br>       -<span class="hljs-number">0.15136002</span>,  <span class="hljs-number">0.22139746</span>,  <span class="hljs-number">0.24734512</span>,  <span class="hljs-number">0.06377611</span>,  <span class="hljs-number">0.02416253</span>,<br>        <span class="hljs-number">0.17551999</span>, -<span class="hljs-number">0.23311079</span>,  <span class="hljs-number">0.06661322</span>,  <span class="hljs-number">0.32424128</span>,  <span class="hljs-number">0.2101823</span> ,<br>        <span class="hljs-number">0.25691697</span>,  <span class="hljs-number">0.25832957</span>,  <span class="hljs-number">0.1729201</span> ,  <span class="hljs-number">0.13627136</span>,  <span class="hljs-number">0.02371691</span>,<br>       -<span class="hljs-number">0.43661168</span>, -<span class="hljs-number">0.04388802</span>, -<span class="hljs-number">0.045301</span>  , -<span class="hljs-number">0.00119099</span>, -<span class="hljs-number">0.10205071</span>,<br>        <span class="hljs-number">0.18704088</span>, -<span class="hljs-number">0.2600936</span> ,  <span class="hljs-number">0.2387853</span> , -<span class="hljs-number">0.29954398</span>,  <span class="hljs-number">0.08725815</span>,<br>       -<span class="hljs-number">0.23276895</span>,  <span class="hljs-number">0.00449505</span>, -<span class="hljs-number">0.19258054</span>,  <span class="hljs-number">0.05162204</span>, -<span class="hljs-number">0.06285881</span>,<br>       -<span class="hljs-number">0.08242426</span>,  <span class="hljs-number">0.25470343</span>,  <span class="hljs-number">0.03506103</span>, -<span class="hljs-number">0.18733846</span>, -<span class="hljs-number">0.11046141</span>,<br>        <span class="hljs-number">0.05378657</span>,  <span class="hljs-number">0.21005692</span>,  <span class="hljs-number">0.14785953</span>,  <span class="hljs-number">0.24190894</span>,  <span class="hljs-number">0.01004618</span>,<br>       -<span class="hljs-number">0.1438988</span> ,  <span class="hljs-number">0.04277115</span>,  <span class="hljs-number">0.27179587</span>, -<span class="hljs-number">0.04454158</span>,  <span class="hljs-number">0.11442478</span>,<br>        <span class="hljs-number">0.09336581</span>, -<span class="hljs-number">0.02072855</span>,  <span class="hljs-number">0.1449741</span> , -<span class="hljs-number">0.05423071</span>, -<span class="hljs-number">0.02627472</span>,<br>        <span class="hljs-number">0.0190267</span> , -<span class="hljs-number">0.03677283</span>, -<span class="hljs-number">0.3188731</span> ,  <span class="hljs-number">0.29706222</span>,  <span class="hljs-number">0.3178355</span> ,<br>       -<span class="hljs-number">0.18600275</span>,  <span class="hljs-number">0.17816757</span>, -<span class="hljs-number">0.12264849</span>, -<span class="hljs-number">0.08815578</span>,  <span class="hljs-number">0.04992864</span>,<br>       -<span class="hljs-number">0.07476765</span>,  <span class="hljs-number">0.2927304</span> ,  <span class="hljs-number">0.29114792</span>,  <span class="hljs-number">0.2975045</span> ,  <span class="hljs-number">0.02667597</span>,<br>       -<span class="hljs-number">0.41576225</span>,  <span class="hljs-number">0.05530886</span>, -<span class="hljs-number">0.01657987</span>,  <span class="hljs-number">0.17934221</span>,  <span class="hljs-number">0.09024961</span>],<br>      dtype=float32)<br></code></pre></td></tr></table></figure><h3 id="模型超参数设定"><a href="#模型超参数设定" class="headerlink" title="模型超参数设定"></a>模型超参数设定</h3><ol><li>训练模式：无监督训练分为’skipgram’和’chow’，默认为前者</li><li>词嵌入维度dim：默认为100</li><li>数据循环次数epoch：默认为5</li><li>学习率lr：默认为0.05</li><li>线程数thread：默认为12个线程，建议与CPU核数相同</li></ol><h3 id="模型效果检验"><a href="#模型效果检验" class="headerlink" title="模型效果检验"></a>模型效果检验</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>model.get_nearest_neighbors(<span class="hljs-string">&#x27;sports&#x27;</span>)<br><br>[(<span class="hljs-number">0.8495004773139954</span>, <span class="hljs-string">&#x27;sport&#x27;</span>), (<span class="hljs-number">0.8420268893241882</span>, <span class="hljs-string">&#x27;sporting&#x27;</span>), (<span class="hljs-number">0.80378657579422</span>, <span class="hljs-string">&#x27;sportsnet&#x27;</span>), (<span class="hljs-number">0.8021653294563293</span>, <span class="hljs-string">&#x27;sportsplex&#x27;</span>), (<span class="hljs-number">0.7963152527809143</span>, <span class="hljs-string">&#x27;sportsground&#x27;</span>), (<span class="hljs-number">0.7816479802131653</span>, <span class="hljs-string">&#x27;sportswomen&#x27;</span>), (<span class="hljs-number">0.7815326452255249</span>, <span class="hljs-string">&#x27;sportsman&#x27;</span>), (<span class="hljs-number">0.7743322253227234</span>, <span class="hljs-string">&#x27;sportscars&#x27;</span>), (<span class="hljs-number">0.7705729007720947</span>, <span class="hljs-string">&#x27;sportscar&#x27;</span>), (<span class="hljs-number">0.7693472504615784</span>, <span class="hljs-string">&#x27;athletics&#x27;</span>)]<br></code></pre></td></tr></table></figure><h3 id="模型的保存与重加载"><a href="#模型的保存与重加载" class="headerlink" title="模型的保存与重加载"></a>模型的保存与重加载</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>model.save_model(<span class="hljs-string">&quot;fil9.bin&quot;</span>)<br><br><span class="hljs-comment"># load</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>model = fasttext.load_model(<span class="hljs-string">&quot;fil9.bin&quot;</span>)<br></code></pre></td></tr></table></figure><h1 id="3-文本数据分析"><a href="#3-文本数据分析" class="headerlink" title="3.文本数据分析"></a>3.文本数据分析</h1><p>文本数据分析的作用：文本数据分析能够有效帮助我们理解数据语料，快速检查出语料可能存在的问题，并指导之后模型训练过程中一些超参数的选择。</p><p>常用的几种文本数据分析方法：</p><ul><li>标签数量分布</li><li>句子长度分布</li><li>词频统计与关键词词云</li></ul><h1 id="4-文本特征处理"><a href="#4-文本特征处理" class="headerlink" title="4.文本特征处理"></a>4.文本特征处理</h1><p>文本特征处理的作用：为语料添加具有普适性的文本特征，如n-gram特征，以及对加入特征之后的文本语料进行必要的处理，如长度规范。这些特征处理工作能够有效的将重要的文本特征加入模型训练当中，增强模型评估指标。</p><ul><li>n-gram特征：给定一段文本序列，其中n个词或字的相邻共现特征即n-gram特征。</li></ul><p>常用的n-gram特征是bi-gram和tri-gram，对应n为2和3</p><ul><li>文本长度规范：一般模型的输入需要等尺寸大小的矩阵，因此在进入模型前需要对每条文本数值映射后的长度进行规范，此时将根据句子长度分布分析出覆盖绝大多数文本的合理长度，对超长文本进行截断，对不足文本进行补齐。</li></ul><h1 id="5-文本数据增强"><a href="#5-文本数据增强" class="headerlink" title="5.文本数据增强"></a>5.文本数据增强</h1><p>关于回译数据增强法：回译数据增强指将文本数据翻译成另外一种语言，之后再翻译回原语言，就得到了同标签的新语料，将这个新语料加入原数据集中即可认为是数据增强。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> googletrans <span class="hljs-keyword">import</span> Translator<br>translator = Translator()<br>translations_ko = translator.translate([sample1, sample2, sample3], dest = <span class="hljs-string">&#x27;ko&#x27;</span>)<br>ko_res = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> x : x.text, translations_ko))<br>translations_cn = translator.translate(ko_res, dest = <span class="hljs-string">&#x27;zh-cn&#x27;</span>)<br>cn_res = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> x : x.text, translations_cn))<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Autograd</title>
    <link href="/2024/02/11/Autograd/"/>
    <url>/2024/02/11/Autograd/</url>
    
    <content type="html"><![CDATA[<h1 id="PyTorch中的autograd"><a href="#PyTorch中的autograd" class="headerlink" title="PyTorch中的autograd"></a>PyTorch中的autograd</h1><p>在整个PyTorch框架中，所有的神经网络都是一个autograd package（自动求导工具包）</p><p>autograd package提供了一个对Tensor上的所有操作进行自动微分的功能</p><h2 id="关于torch-Tensor"><a href="#关于torch-Tensor" class="headerlink" title="关于torch.Tensor"></a>关于torch.Tensor</h2><ul><li><p>torch.Tensor是整个package中的核心类，如果将属性 <em>.requires_grad</em> 设置为 true，他将追踪这个类上的所有操作，当代码要进行反向传播时，直接调用 <em>.backward()</em> 就可以自动计算所有的梯度，在这个Tensor上的所有梯度将被累加进属性 <em>.grad</em> 中。</p></li><li><p>如果想终止一个Tensor在计算图中的追踪回溯，只需要执行 <em>.detach()</em> 就可以将该Tensor从计算图中撤下，在未来的回溯计算中也不会在计算该Tensor。</p></li><li><p>除了 <em>.detach()</em> 如果想终止对计算图的回溯，也就是不再进行方向传播求导的过程，也可以采用代码块的形式 <em>with torch.no_grad():</em> ，这种操作非常适用于对模型进行预测的时候，因为预测阶段不需要对梯度进行计算。</p></li></ul><h2 id="关于torch-Function"><a href="#关于torch-Function" class="headerlink" title="关于torch.Function"></a>关于torch.Function</h2><ul><li><p>Function类是和Tensor类同等重要的一个核心类,它和Tensor共同构成一个完整的类</p></li><li><p>每一个Tensor拥有一个 <em>grad.fn</em> 属性,代表引用了哪个具体的Function创建了该Tensor</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> __future__ <span class="hljs-keyword">import</span> print_function<br><span class="hljs-keyword">import</span> torch<br><br>x1 = torch.ones(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>)<br>x2 = torch.ones(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, requires_grad=<span class="hljs-literal">True</span>)<br><span class="hljs-built_in">print</span>(x1, <span class="hljs-string">&#x27;\n&#x27;</span>, x2)<br><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">tensor([[1., 1., 1.],</span><br><span class="hljs-string">        [1., 1., 1.],</span><br><span class="hljs-string">        [1., 1., 1.]]) </span><br><span class="hljs-string"> tensor([[1., 1.],</span><br><span class="hljs-string">        [1., 1.]], requires_grad=True)</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><br>y = x2 + <span class="hljs-number">2</span><br><span class="hljs-built_in">print</span>(y)<br><span class="hljs-built_in">print</span>(x1.grad_fn, <span class="hljs-string">&#x27;\n&#x27;</span>, y.grad_fn)<br><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">tensor([[3., 3.],</span><br><span class="hljs-string">        [3., 3.]], grad_fn=&lt;AddBackward0&gt;)</span><br><span class="hljs-string">None </span><br><span class="hljs-string"> &lt;AddBackward0 object at 0x0000020CC93A7F70&gt;</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure><blockquote><p>用户自定义的Tensor,其grad_fn&#x3D;None.</p></blockquote><p>一些更复杂的操作:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">z = y * y * <span class="hljs-number">3</span><br>out = z.mean()<br><span class="hljs-built_in">print</span>(z, out)<br><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">tensor([[27., 27.],</span><br><span class="hljs-string">        [27., 27.]], grad_fn=&lt;MulBackward0&gt;) tensor(27., grad_fn=&lt;MeanBackward0&gt;)</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure><blockquote><p><em>.mean()</em> 方法表示求均值</p></blockquote><p>使用inplace操作符可以改变Tensor的 <em>requires_grad</em> 属性:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">a = torch.ones(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)<br><span class="hljs-built_in">print</span>(a.requires_grad)<br>a.requires_grad_(<span class="hljs-literal">True</span>)<br><span class="hljs-built_in">print</span>(a.requires_grad)<br><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">False</span><br><span class="hljs-string">True</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure><h2 id="关于梯度Gradients"><a href="#关于梯度Gradients" class="headerlink" title="关于梯度Gradients"></a>关于梯度Gradients</h2><p>在PyTorch中,反向传播是依靠 <em>.backward()</em> 实现的,下面是一个使用例子:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">out.backward()<br><span class="hljs-built_in">print</span>(x2.grad)<br><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">tensor([[4.5000, 4.5000],</span><br><span class="hljs-string">        [4.5000, 4.5000]])</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure><p>这里我们首先要弄清 $out$ 是如何得到的.</p><p>我们把 $out$ 视为一个多元函数,将 $x$ 视为一个多元变量,那么:<br>$$out &#x3D; \frac{3(x+2)^{2}}{4}$$</p><p>对 $out$ 求 $x$ 的导数:<br>$$out’ &#x3D; \frac{3(x+2)}{2}$$</p><p>将x代入,便得到结果.</p><ul><li>关于自动求导的属性设置:可以通过设置 <em>.requires_grad&#x3D;True</em> 来执行自动求导,也可以通过代码块的限制来停止自动求导.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(x.requires_grad)<br><span class="hljs-built_in">print</span>((x ** <span class="hljs-number">2</span>).equires_grad)<br><br><span class="hljs-keyword">with</span> torch.no_grad():<br>    <span class="hljs-built_in">print</span>((x ** <span class="hljs-number">2</span>).requires_grad)<br><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">True</span><br><span class="hljs-string">True</span><br><span class="hljs-string">False</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure><ul><li>可以通过 <em>.detach()</em> 获得一个新的Tensor,拥有相同内容但不需要自动求导.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(x.requires_grad)<br>y = x.detach()<br><span class="hljs-built_in">print</span>(y,requires_grad)<br><span class="hljs-built_in">print</span>(x.eq(y).<span class="hljs-built_in">all</span>)<br><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">True</span><br><span class="hljs-string">False</span><br><span class="hljs-string">tensor(True)</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Pytorch基本语法</title>
    <link href="/2024/02/09/PyTorch%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/"/>
    <url>/2024/02/09/PyTorch%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/</url>
    
    <content type="html"><![CDATA[<h1 id="Pytorch的基本操作"><a href="#Pytorch的基本操作" class="headerlink" title="Pytorch的基本操作"></a>Pytorch的基本操作</h1><h2 id="张量的创建"><a href="#张量的创建" class="headerlink" title="张量的创建"></a>张量的创建</h2><p>Tensor张量：张量的概念类似于Numpy中的ndarray数据结构，最大的区别在于Tensor可以利用GPU的加速功能。</p><p>在使用Pytorch时，需要先引入模块：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> __future__ <span class="hljs-keyword">import</span> print_function<br><span class="hljs-keyword">import</span> torch<br></code></pre></td></tr></table></figure><p>下面是Pytorch中创建张量的基本语法：</p><ol><li>torch.tensor 根据指定数据创建张量</li><li>torch.Tensor 根据形状创建张量, 其也可用来创建指定数据的张量</li><li>torch.IntTensor、torch.FloatTensor、torch.DoubleTensor 创建指定类型的张量</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> __future__ <span class="hljs-keyword">import</span> print_function<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> random<br><br><span class="hljs-comment"># 1. 根据已有数据创建张量</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test01</span>():<br>    <span class="hljs-comment"># 1. 创建张量标量</span><br>    data = torch.tensor(<span class="hljs-number">10</span>)<br>    <span class="hljs-built_in">print</span>(data)<br>    <span class="hljs-comment"># 2. numpy 数组, 由于 data 为 float64, 下面代码也使用该类型</span><br>    data = np.random.randn(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>)<br>    data = torch.tensor(data)<br>    <span class="hljs-built_in">print</span>(data)<br>    <span class="hljs-comment"># 3. 列表, 下面代码使用默认元素类型 float32</span><br>    data = [[<span class="hljs-number">10.</span>, <span class="hljs-number">20.</span>, <span class="hljs-number">30.</span>], [<span class="hljs-number">40.</span>, <span class="hljs-number">50.</span>, <span class="hljs-number">60.</span>]]<br>    data = torch.tensor(data)<br>    <span class="hljs-built_in">print</span>(data)<br><br><span class="hljs-comment"># 2. 创建指定形状的张量</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test02</span>():<br>    <span class="hljs-comment"># 1. 创建2行3列的张量, 默认 dtype 为 float32</span><br>    data = torch.Tensor(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>)<br>    <span class="hljs-built_in">print</span>(data)<br>    <span class="hljs-comment"># 2. 注意: 如果传递列表, 则创建包含指定元素的张量</span><br>    data = torch.Tensor([<span class="hljs-number">10</span>])<br>    <span class="hljs-built_in">print</span>(data)<br>    data = torch.Tensor([<span class="hljs-number">10</span>, <span class="hljs-number">20</span>])<br>    <span class="hljs-built_in">print</span>(data)<br><br><span class="hljs-comment"># 3. 使用具体类型的张量</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test03</span>():<br>    <span class="hljs-comment"># 1. 创建2行3列, dtype 为 int32 的张量</span><br>    data = torch.IntTensor(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>)<br>    <span class="hljs-built_in">print</span>(data)<br>    <span class="hljs-comment"># 2. 注意: 如果传递的元素类型不正确, 则会进行类型转换</span><br>    data = torch.IntTensor([<span class="hljs-number">2.5</span>, <span class="hljs-number">3.3</span>])<br>    <span class="hljs-built_in">print</span>(data)<br>    <span class="hljs-comment"># 3. 其他的类型</span><br>    data = torch.ShortTensor()  <span class="hljs-comment"># int16</span><br>    data = torch.LongTensor()   <span class="hljs-comment"># int64</span><br>    data = torch.FloatTensor()  <span class="hljs-comment"># float32</span><br>    data = torch.DoubleTensor() <span class="hljs-comment"># float64</span><br></code></pre></td></tr></table></figure><p>创建线性和随机张量：</p><ol><li>torch.arange 和 torch.linspace 创建线性张量</li><li>torch.random.init_seed 和 torch.random.manual_seed 随机种子设置</li><li>torch.randn 创建随机张量</li></ol><ul><li>rand和randn：</li></ul><ol><li>torch.rand(): 这个函数生成一个张量，其中的值是在 $[0, 1)$ 区间内均匀分布的随机数。你可以通过指定张量的形状来生成不同形状的张量。</li><li>torch.randn(): 这个函数生成一个张量，其中的值是从标准正态分布（均值为0，标准差为1）中随机采样得到的。你同样可以通过指定张量的形状来生成不同形状的张量。<br>Pytorch的基本运算操作</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-comment"># 1. 创建线性空间的张量</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test01</span>():<br>    <span class="hljs-comment"># 1. 在指定区间按照步长生成元素 [start, end, step)</span><br>    data = torch.arange(<span class="hljs-number">0</span>, <span class="hljs-number">10</span>, <span class="hljs-number">2</span>)<br>    <span class="hljs-built_in">print</span>(data)<br>    <span class="hljs-comment"># 2. 在指定区间按照元素个数生成</span><br>    data = torch.linspace(<span class="hljs-number">0</span>, <span class="hljs-number">11</span>, <span class="hljs-number">10</span>)<br>    <span class="hljs-built_in">print</span>(data)<br><br><span class="hljs-comment"># 2. 创建随机张量</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test02</span>():<br>    <span class="hljs-comment"># 1. 创建随机张量</span><br>    data = torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>)  <span class="hljs-comment"># 创建2行3列张量</span><br>    <span class="hljs-built_in">print</span>(data)<br>    <span class="hljs-comment"># 2. 随机数种子设置</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;随机数种子:&#x27;</span>, torch.random.initial_seed())<br>    torch.random.manual_seed(<span class="hljs-number">100</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;随机数种子:&#x27;</span>, torch.random.initial_seed())<br></code></pre></td></tr></table></figure><p>创建01张量</p><ol><li>torch.ones 和 torch.ones_like 创建全1张量</li><li>torch.zeros 和 torch.zeros_like 创建全0张量</li><li>torch.full 和 torch.full_like 创建全为指定值张量</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test01</span>():<br>    <span class="hljs-comment"># 1. 创建指定形状全0张量</span><br>    data = torch.zeros(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>)<br>    <span class="hljs-built_in">print</span>(data)<br>    <span class="hljs-comment"># 2. 根据张量形状创建全0张量</span><br>    data = torch.zeros_like(data)<br>    <span class="hljs-built_in">print</span>(data)<br><br><span class="hljs-comment"># 2. 创建全1张量</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test02</span>():<br>    <span class="hljs-comment"># 1. 创建指定形状全0张量</span><br>    data = torch.ones(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>)<br>    <span class="hljs-built_in">print</span>(data)<br>    <span class="hljs-comment"># 2. 根据张量形状创建全0张量</span><br>    data = torch.ones_like(data)<br>    <span class="hljs-built_in">print</span>(data)<br><br><span class="hljs-comment"># 3. 创建全为指定值的张量</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test03</span>():<br>    <span class="hljs-comment"># 1. 创建指定形状指定值的张量</span><br>    data = torch.full([<span class="hljs-number">2</span>, <span class="hljs-number">3</span>], <span class="hljs-number">10</span>)<br>    <span class="hljs-built_in">print</span>(data)<br>    <span class="hljs-comment"># 2. 根据张量形状创建指定值的张量</span><br>    data = torch.full_like(data, <span class="hljs-number">20</span>)<br>    <span class="hljs-built_in">print</span>(data)<br></code></pre></td></tr></table></figure><p>张量元素类型转换</p><ol><li>tensor.type(torch.DoubleTensor)</li><li>torch.double()<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>():<br>    data = torch.full([<span class="hljs-number">2</span>, <span class="hljs-number">3</span>], <span class="hljs-number">10</span>)<br>    <span class="hljs-comment"># 将 data 元素类型转换为 float64 类型</span><br>    <span class="hljs-comment"># 1. 第一种方法</span><br>    data = data.<span class="hljs-built_in">type</span>(torch.DoubleTensor)<br>    <span class="hljs-comment"># 转换为其他类型</span><br>    <span class="hljs-comment"># data = data.type(torch.ShortTensor)</span><br>    <span class="hljs-comment"># data = data.type(torch.IntTensor)</span><br>    <span class="hljs-comment"># data = data.type(torch.LongTensor)</span><br>    <span class="hljs-comment"># data = data.type(torch.FloatTensor)</span><br><br>    <span class="hljs-comment"># 2. 第二种方法</span><br>    data = data.double()<br>    <span class="hljs-comment"># 转换为其他类型</span><br>    <span class="hljs-comment"># data = data.short()</span><br>    <span class="hljs-comment"># data = data.int()</span><br>    <span class="hljs-comment"># data = data.long()</span><br>    <span class="hljs-comment"># data = data.float()</span><br></code></pre></td></tr></table></figure></li></ol><h2 id="张量的基本运算"><a href="#张量的基本运算" class="headerlink" title="张量的基本运算"></a>张量的基本运算</h2><p>基本运算中，包括 add、sub、mul、div、neg 等函数，以及这些函数的 in-place 版本。</p><blockquote><p>注意：所有的in-place的操作函数都有一个下划线的后缀，如x.copy_(y)，都会直接改变x的值</p></blockquote><p>阿达玛积指的是矩阵对应位置的元素相乘，用 * 表示。<br>点积运算指一般意义上的矩阵乘法，要求矩阵可乘，用运算符 @ 表示。<br>torch.matmul 对进行点乘运算的两矩阵形状没有限定，利用广播机制进行。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test01</span>():<br>    data1 = torch.tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]])<br>    data2 = torch.tensor([[<span class="hljs-number">5</span>, <span class="hljs-number">6</span>], [<span class="hljs-number">7</span>, <span class="hljs-number">8</span>]])<br>    <span class="hljs-comment"># 第一种方式</span><br>    data = torch.mul(data1, data2)<br><br>    <span class="hljs-comment"># 第二种方式</span><br>    data = data1 * data2<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test02</span>():<br>    data1 = torch.tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">5</span>, <span class="hljs-number">6</span>]])<br>    data2 = torch.tensor([[<span class="hljs-number">5</span>, <span class="hljs-number">6</span>], [<span class="hljs-number">7</span>, <span class="hljs-number">8</span>]])<br><br>    <span class="hljs-comment"># 第一种方式</span><br>    data = data1 @ data2<br><br>    <span class="hljs-comment"># 第二种方式</span><br>    data = torch.mm(data1, data2)<br><br>    <span class="hljs-comment"># 第三种方式</span><br>    data = torch.matmul(data1, data2)<br></code></pre></td></tr></table></figure><p>对于PyTorch的四则运算会优先进行元素级别的操作，即两个张量之间对应位置元素进行运算。这就要求张量满足同型或满足广播规则。</p><p>和一个常数进行运算时，会将张量中的每一个元素都进行运算，可以看作将常数广播为同型张量。</p><ul><li><strong>广播规则：</strong></li></ul><p>广播规则是指在进行张量运算时，PyTorch会自动调整张量的形状，使得它们能够进行元素级别的操作。</p><p>具体来说，当两个张量的形状不完全匹配时，PyTorch会根据一组规则对它们进行扩展，使它们的形状能够对齐，从而进行运算。</p><p>广播规则的基本思想是，如果两个张量的形状在某个维度上相同，或者其中一个张量在某个维度上的长度为1，那么可以在该维度上进行广播。广播操作会在这些维度上复制张量，使其形状与另一个张量相匹配，从而进行运算。</p><p>具体来说，广播规则包括以下几点：</p><ol><li><p>维度数增加：如果两个张量的维度数不同，会在较小的张量的前面添加一个或多个维度，直到两个张量的维度数相同。</p></li><li><p>维度长度为1的扩展：对于每个维度，如果两个张量在该维度上的长度不同，且其中一个张量在该维度上的长度为1，可以在该维度上对该张量进行扩展，使其长度与另一个张量相同。</p></li><li><p>扩展之后形状相同：经过广播之后，两个张量的形状必须是相同的才能进行元素级别的操作。</p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br>x = torch.tensor([<span class="hljs-number">1</span>],[<span class="hljs-number">2</span>],[<span class="hljs-number">3</span>])<br>y = torch.tensor([[<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>]])<br><span class="hljs-comment"># 执行广播操作</span><br>broadcasted_x, broadcasted_y = torch.broadcast_tensors(x, y)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Broadcasted x:&quot;</span>, broadcasted_x)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Broadcasted y:&quot;</span>, broadcasted_y)<br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">Broadcasted x: </span><br><span class="hljs-string">tensor([[1, 1, 1],</span><br><span class="hljs-string">        [2, 2, 2],</span><br><span class="hljs-string">        [3, 3, 3]])</span><br><span class="hljs-string"></span><br><span class="hljs-string">Broadcasted y: </span><br><span class="hljs-string">tensor([[4, 5, 6],</span><br><span class="hljs-string">        [4, 5, 6],</span><br><span class="hljs-string">        [4, 5, 6]])</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure><h2 id="指定运算设备"><a href="#指定运算设备" class="headerlink" title="指定运算设备"></a>指定运算设备</h2><p>将张量移动到 GPU 上有两种方法: </p><ol><li>使用 cuda 方法 </li><li>直接在 GPU 上创建张量 </li><li>使用 to 方法指定设备<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment"># 1. 使用 cuda 方法</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test01</span>():<br>    data = torch.tensor([<span class="hljs-number">10</span>, <span class="hljs-number">20</span> ,<span class="hljs-number">30</span>])<br>    data = data.cuda()<br><br><span class="hljs-comment"># 2. 直接将张量创建在 GPU 上</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test02</span>():<br>    data = torch.tensor([<span class="hljs-number">10</span>, <span class="hljs-number">20</span>, <span class="hljs-number">30</span>], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>)<br>    <span class="hljs-comment"># 使用 cpu 函数将张量移动到 cpu 上</span><br>    data = data.cpu()<br><br><span class="hljs-comment"># 3. 使用 to 方法</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test03</span>():<br>    data = torch.tensor([<span class="hljs-number">10</span>, <span class="hljs-number">20</span>, <span class="hljs-number">30</span>])<br>    data = data.to(<span class="hljs-string">&#x27;cuda:0&#x27;</span>)<br></code></pre></td></tr></table></figure></li></ol><h2 id="张量类型转换"><a href="#张量类型转换" class="headerlink" title="张量类型转换"></a>张量类型转换</h2><ol><li>使用 Tensor.numpy 函数可以将张量转换为 ndarray 数组，但是共享内存，可以使用 copy 函数避免共享。</li><li>使用 from_numpy 可以将 ndarray 数组转换为 Tensor，默认共享内存，使用 copy 函数避免共享。</li><li>使用 torch.tensor 可以将 ndarray 数组转换为 Tensor，默认不共享内存。</li><li>对于只有一个元素的张量，使用 item 方法将该值从张量中提取出来。</li></ol><h2 id="张量拼接操作"><a href="#张量拼接操作" class="headerlink" title="张量拼接操作"></a>张量拼接操作</h2><ol><li><p>torch.cat 函数可以将两个张量根据指定的维度拼接起来。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment"># 生成形状为3，5，4的三维张量</span><br><span class="hljs-comment"># 第0维（也就是维度索引为0的维度）是大小为3，通常表示这个张量中包含3个样本或者批次。</span><br><span class="hljs-comment"># 第1维（维度索引为1的维度）是大小为5，代表每个样本中的特征数量。</span><br><span class="hljs-comment"># 第2维（维度索引为2的维度）是大小为4，代表每个特征的维度或者特征向量的长度。</span><br>data1 = torch.randint(<span class="hljs-number">0</span>, <span class="hljs-number">10</span>, [<span class="hljs-number">3</span>, <span class="hljs-number">5</span>, <span class="hljs-number">4</span>])<br>data2 = torch.randint(<span class="hljs-number">0</span>, <span class="hljs-number">10</span>, [<span class="hljs-number">3</span>, <span class="hljs-number">5</span>, <span class="hljs-number">4</span>])<br><span class="hljs-comment"># 按第0维拼接</span><br>new_data = torch.cat([data1, data2], dim=<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure></li><li><p>torch.stack 函数可以将两个张量根据指定的维度叠加起来，会增加新的维度。</p></li></ol><p>两个[2, 2] 的张量堆叠，产生大小为 [2, 2, 2] 的张量。</p><h2 id="张量索引操作"><a href="#张量索引操作" class="headerlink" title="张量索引操作"></a>张量索引操作</h2><ol><li><p>简单行、列索引</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><br>data = torch.randint(<span class="hljs-number">0</span>, <span class="hljs-number">10</span>, [<span class="hljs-number">4</span>, <span class="hljs-number">5</span>])<br>data[<span class="hljs-number">0</span>]    <span class="hljs-comment"># 第一行</span><br>data[:, <span class="hljs-number">0</span>]    <span class="hljs-comment"># 第一列</span><br>data[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>]    <span class="hljs-comment"># 返回(0, 1) 位置即第一行第二列的元素，返回一个张量</span><br>data[[[<span class="hljs-number">0</span>], [<span class="hljs-number">1</span>]], [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>]]    <span class="hljs-comment"># 返回 0、1 行的 1、2 列共4个元素</span><br></code></pre></td></tr></table></figure></li><li><p>范围索引</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 前3行的前2列数据</span><br>data[:<span class="hljs-number">3</span>, :<span class="hljs-number">2</span>]<br><span class="hljs-comment"># 第2行到最后的前2列数据</span><br>data[<span class="hljs-number">2</span>:, :<span class="hljs-number">2</span>]<br></code></pre></td></tr></table></figure></li><li><p>布尔索引</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 第三列大于5的行数据，输出整行</span><br>data[data[:, <span class="hljs-number">2</span>] &gt; <span class="hljs-number">5</span>]<br><span class="hljs-comment"># 第二行大于5的列数据</span><br>data[:, data[<span class="hljs-number">1</span>] &gt; <span class="hljs-number">5</span>]<br></code></pre></td></tr></table></figure></li></ol><h2 id="张量形状操作"><a href="#张量形状操作" class="headerlink" title="张量形状操作"></a>张量形状操作</h2><p>reshape 函数可以在保证张量数据不变的前提下改变数据的维度，将其转换成指定的形状，前提是数据个数不变。</p><p>ranspose 函数可以实现交换张量形状的指定维度, 例如: 一个张量的形状为 (2, 3, 4) 可以通过 transpose 函数把 3 和 4 进行交换, 将张量的形状变为 (2, 4, 3)</p><p>squeeze 函数用删除 shape 为 1 的维度，unsqueeze 在每个维度添加 1, 以增加数据的形状。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">data = torch.tensor(np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">10</span>, [<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">5</span>]))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;data shape:&#x27;</span>, data.size())<br><br><span class="hljs-comment"># 1. 去掉值为1的维度</span><br>new_data = data.squeeze()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;new_data shape:&#x27;</span>, new_data.size())  <span class="hljs-comment"># torch.Size([3, 5])</span><br><br><span class="hljs-comment"># 2. 去掉指定位置为1的维度，注意: 如果指定位置不是1则不删除</span><br>new_data = data.squeeze(<span class="hljs-number">2</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;new_data shape:&#x27;</span>, new_data.size())  <span class="hljs-comment"># torch.Size([3, 5])</span><br><br><span class="hljs-comment"># 3. 在2维度增加一个维度</span><br>new_data = data.unsqueeze(-<span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;new_data shape:&#x27;</span>, new_data.size())  <span class="hljs-comment"># torch.Size([3, 1, 5, 1])</span><br></code></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">data shape: torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">5</span>])<br>new_data shape: torch.Size([<span class="hljs-number">3</span>, <span class="hljs-number">5</span>])<br>new_data shape: torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">5</span>])<br>new_data shape: torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">5</span>, <span class="hljs-number">1</span>])<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>BP神经网络</title>
    <link href="/2024/01/31/BP/"/>
    <url>/2024/01/31/BP/</url>
    
    <content type="html"><![CDATA[<h1 id="神经网络的构成"><a href="#神经网络的构成" class="headerlink" title="神经网络的构成"></a>神经网络的构成</h1><p><img src="/Pictures/MCM/BP/plot01.png" alt="img"></p><p>人工神经网络（ANN）具有自学习、自组织、较好的容错性和优良的非线性逼近能力。</p><p>在实际应用中，80%~90%的人工神经网络模型是采用误差反传算法或其变化形式的网络模型。</p><p>ANN通过数学近似映射（函数逼近）完成拟合——&gt;预测，分类——&gt;聚类分析的工作</p><p>从模型上进行拆分，神经网络包括：</p><ol><li>神经元模型</li><li>激活函数</li><li>网络结构</li><li>工作状态</li><li>学习方式</li></ol><h2 id="建立和应用神经网络的步骤"><a href="#建立和应用神经网络的步骤" class="headerlink" title="建立和应用神经网络的步骤"></a>建立和应用神经网络的步骤</h2><ol><li><p>网络结构的确定</p><blockquote><p>包含网络的拓扑结构和每个神经元相应函数的选取。</p></blockquote></li><li><p>权值和阈值的确定</p><blockquote><p>通过学习得到，利用已知的一组正确的输入输出，调整权值和阈值使得网络输出与理想输出偏差尽量小。</p></blockquote></li><li><p>工作阶段</p><blockquote><p>用带有确定权重值和阈值的神经网络解决问题的过程，也叫模拟。</p></blockquote></li></ol><h2 id="人工神经元的模型"><a href="#人工神经元的模型" class="headerlink" title="人工神经元的模型"></a>人工神经元的模型</h2><p><img src="/Pictures/MCM/BP/plot02.png" alt="img"></p><ul><li>神经元输入与输出的关系为：</li></ul><p>$$<br>net_{i}&#x3D;\sum_{j&#x3D;1}^{n}w_{ij}x_{j}-\theta &#x3D;\sum_{j&#x3D;0}^{n}w_{ij}x_{j} \\<br>y_{i}&#x3D;f(net_{i})<br>$$</p><ul><li>若用X表示输入向量，W表示权重向量</li></ul><p>$$net_{i}&#x3D;XW,y_{i}&#x3D;f(XW)$$</p><ul><li>常用激活函数</li></ul><ol><li><p>线性函数<br>$$f(x)&#x3D;kx+c$$</p></li><li><p>S函数<br>$$f(x)&#x3D;\frac{1}{1+e^{-ax}}$$</p></li><li><p>阈值函数<br>$$f(x)&#x3D;\begin{cases} T,x&gt;c\\ kx,-c\le x\le c \\ -T,x&lt;-c \end{cases}$$</p></li><li><p>双极S函数<br>$$f(x)&#x3D;\frac{2}{1+e^{-ax}}-1$$</p></li></ol><h2 id="网络模型"><a href="#网络模型" class="headerlink" title="网络模型"></a>网络模型</h2><ol><li><p>前馈神经网络</p><blockquote><p>只在训练过程会有反馈信号，而在分类过程中数据只能向前传送，直到到达输出层</p></blockquote></li><li><p>反馈神经网络</p><blockquote><p>从输出到输入过程具有反馈链接的神经网络</p></blockquote></li><li><p>自组织神经网络</p><blockquote><p>通过自动寻找样本中的内在规律和本质属性，自组织、自适应地改变网络参数与结构。</p></blockquote></li></ol><p><img src="/Pictures/MCM/BP/plot03.png" alt="img"></p><h2 id="学习方式"><a href="#学习方式" class="headerlink" title="学习方式"></a>学习方式</h2><ol><li>有监督学习</li></ol><p>将一组训练集送入网络，根据网络的实际输出与期望输出之间的差别来调整连接权</p><ol start="2"><li>无监督学习</li></ol><p>抽取样本中蕴含的统计特征，并以神经元之间的连接权的方式存于网络中。</p><p><strong>采用BP学习算法的前馈神经网络称为BP神经网络</strong></p><h1 id="BP算法"><a href="#BP算法" class="headerlink" title="BP算法"></a>BP算法</h1><h2 id="BP-Back-Propagation-算法的基本原理"><a href="#BP-Back-Propagation-算法的基本原理" class="headerlink" title="BP(Back Propagation)算法的基本原理"></a>BP(Back Propagation)算法的基本原理</h2><p>利用输出后的误差来估计输出层的直接前导层的误差，再用这个误差估计更前一层的误差，获得各层的误差估计。</p><p>总结来说，就是<strong>信号的正向传播&amp;误差的反向传播</strong></p><h1 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h1><p>1981年生物学家发现了两类蚊子，他们测量的数据如下</p><table><thead><tr><th>翼长</th><th>触角长</th><th>类别</th></tr></thead><tbody><tr><td>1.78</td><td>1.14</td><td>Apf</td></tr><tr><td>1.96</td><td>1.18</td><td>Apf</td></tr><tr><td>1.86</td><td>1.20</td><td>Apf</td></tr><tr><td>1.72</td><td>1.24</td><td>Af</td></tr><tr><td>2.00</td><td>1.26</td><td>Apf</td></tr><tr><td>2.00</td><td>1.28</td><td>Apf</td></tr><tr><td>1.96</td><td>1.30</td><td>Apf</td></tr><tr><td>1.74</td><td>1.36</td><td>Af</td></tr><tr><td>1.64</td><td>1.38</td><td>Af</td></tr><tr><td>1.82</td><td>1.38</td><td>Af</td></tr><tr><td>1.90</td><td>1.38</td><td>Af</td></tr><tr><td>1.70</td><td>1.40</td><td>Af</td></tr><tr><td>1.82</td><td>1.48</td><td>Af</td></tr><tr><td>1.82</td><td>1.54</td><td>Af</td></tr><tr><td>2.08</td><td>1.56</td><td>Af</td></tr></tbody></table><p>构建模型区分两种蚊子。</p><h2 id="以触角和翼长为坐标轴作图"><a href="#以触角和翼长为坐标轴作图" class="headerlink" title="以触角和翼长为坐标轴作图"></a>以触角和翼长为坐标轴作图</h2><p>x为触角长，y为翼长</p><p><img src="/Pictures/MCM/BP/plot04.png" alt="img"></p><p><strong>思路一：做一条直线将两类蚊子区分开</strong></p><p>$$y&#x3D;1.47x-0.017$$</p><p>分类规则：在直线一侧的便归为那一类。</p><p><strong>思路二：将问题看为一个系统，构建一个神经网络训练模型</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn.tree <span class="hljs-keyword">import</span> DecisionTreeClassifier<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> accuracy_score<br><br><span class="hljs-comment"># 创建数据框</span><br>data = &#123;<br>    <span class="hljs-string">&#x27;翼长&#x27;</span>: [<span class="hljs-number">1.78</span>, <span class="hljs-number">1.96</span>, <span class="hljs-number">1.86</span>, <span class="hljs-number">1.72</span>, <span class="hljs-number">2.00</span>, <span class="hljs-number">2.00</span>, <span class="hljs-number">1.96</span>, <span class="hljs-number">1.74</span>, <span class="hljs-number">1.64</span>, <span class="hljs-number">1.82</span>, <span class="hljs-number">1.90</span>, <span class="hljs-number">1.70</span>, <span class="hljs-number">1.82</span>, <span class="hljs-number">1.82</span>, <span class="hljs-number">2.08</span>],<br>    <span class="hljs-string">&#x27;触角长&#x27;</span>: [<span class="hljs-number">1.14</span>, <span class="hljs-number">1.18</span>, <span class="hljs-number">1.20</span>, <span class="hljs-number">1.24</span>, <span class="hljs-number">1.26</span>, <span class="hljs-number">1.28</span>, <span class="hljs-number">1.30</span>, <span class="hljs-number">1.36</span>, <span class="hljs-number">1.38</span>, <span class="hljs-number">1.38</span>, <span class="hljs-number">1.38</span>, <span class="hljs-number">1.40</span>, <span class="hljs-number">1.48</span>, <span class="hljs-number">1.54</span>, <span class="hljs-number">1.56</span>],<br>    <span class="hljs-string">&#x27;类别&#x27;</span>: [<span class="hljs-string">&#x27;Apf&#x27;</span>, <span class="hljs-string">&#x27;Apf&#x27;</span>, <span class="hljs-string">&#x27;Apf&#x27;</span>, <span class="hljs-string">&#x27;Af&#x27;</span>, <span class="hljs-string">&#x27;Apf&#x27;</span>, <span class="hljs-string">&#x27;Apf&#x27;</span>, <span class="hljs-string">&#x27;Apf&#x27;</span>, <span class="hljs-string">&#x27;Af&#x27;</span>, <span class="hljs-string">&#x27;Af&#x27;</span>, <span class="hljs-string">&#x27;Af&#x27;</span>, <span class="hljs-string">&#x27;Af&#x27;</span>, <span class="hljs-string">&#x27;Af&#x27;</span>, <span class="hljs-string">&#x27;Af&#x27;</span>, <span class="hljs-string">&#x27;Af&#x27;</span>, <span class="hljs-string">&#x27;Af&#x27;</span>]<br>&#125;<br>df = pd.DataFrame(data)<br><br><span class="hljs-comment"># 将类别转换为数值编码</span><br>df[<span class="hljs-string">&#x27;类别&#x27;</span>] = df[<span class="hljs-string">&#x27;类别&#x27;</span>].<span class="hljs-built_in">map</span>(&#123;<span class="hljs-string">&#x27;Apf&#x27;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;Af&#x27;</span>: <span class="hljs-number">1</span>&#125;)<br><br><span class="hljs-comment"># 准备训练集和测试集</span><br>X = df[[<span class="hljs-string">&#x27;翼长&#x27;</span>, <span class="hljs-string">&#x27;触角长&#x27;</span>]]<br>y = df[<span class="hljs-string">&#x27;类别&#x27;</span>]<br>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="hljs-number">0.2</span>, random_state=<span class="hljs-number">42</span>)<br><br><span class="hljs-comment"># 创建并训练决策树模型</span><br>clf = DecisionTreeClassifier(random_state=<span class="hljs-number">42</span>)<br>clf.fit(X_train, y_train)<br><br><span class="hljs-comment"># 在测试集上进行预测</span><br>y_pred = clf.predict(X_test)<br><br><span class="hljs-comment"># 计算准确率</span><br>accuracy = accuracy_score(y_test, y_pred)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;准确率：&quot;</span>, accuracy)<br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>MCM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MCM</tag>
      
      <tag>BP神经网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>元胞自动机</title>
    <link href="/2024/01/31/%E5%85%83%E8%83%9E%E8%87%AA%E5%8A%A8%E6%9C%BA/"/>
    <url>/2024/01/31/%E5%85%83%E8%83%9E%E8%87%AA%E5%8A%A8%E6%9C%BA/</url>
    
    <content type="html"><![CDATA[<h1 id="元胞自动机的构成"><a href="#元胞自动机的构成" class="headerlink" title="元胞自动机的构成"></a>元胞自动机的构成</h1><p>元胞自动机最基本的组成：</p><ol><li>元胞</li><li>元胞空间</li><li>邻近元胞</li><li>规则</li></ol><p>简单来说，元胞自动机可以视为由一个元胞空间和定义于该空间的变换函数组成，每一个元胞依照规则发生状态的变化，并对邻近元胞产生影响。</p><p>在计算机环境下，我们一般用四边形网格进行表达显示。</p><h1 id="例题：元胞自动机模拟森林火灾"><a href="#例题：元胞自动机模拟森林火灾" class="headerlink" title="例题：元胞自动机模拟森林火灾"></a>例题：元胞自动机模拟森林火灾</h1><p>众所周知，森林火灾一直是很多森林覆盖率比较高的国家的心头大患。</p><p>因为人类活动的不断增加，森林火灾的几率也逐渐增加，从之前的自然火（闪电、高温）到现在的人为火，都是森林火灾的罪魁祸首。</p><p>所以森林大火的防治一直是萦绕在各个国家元首头顶的问题。</p><p>而下面这个例题就是来简单描述森林火灾的形成和发展。</p><h2 id="基本假设和假设解析"><a href="#基本假设和假设解析" class="headerlink" title="基本假设和假设解析"></a>基本假设和假设解析</h2><ul><li>正在燃烧的树变成空格位</li><li>如果绿树格位的最近邻居中有一个树在燃烧，则它变成正在燃烧的树</li><li>在空格位，树以概率p生长</li><li>在最近的邻居中没有正在燃烧的树的情况下树在每一时步以概率f(闪电)变为正在燃烧的树</li></ul><p><img src="/Pictures/MCM/Cell/plot01.png" alt="img"></p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><code class="hljs MATLAB">close all;<br>clc;<br>clear;<span class="hljs-comment">%清屏命令</span><br><span class="hljs-built_in">figure</span>;<span class="hljs-comment">%利用当前属性创建窗格</span><br>p=<span class="hljs-number">0.3</span>;<span class="hljs-comment">% 概率p，用来表示树生长的速度</span><br>f=<span class="hljs-number">6e-5</span>;<span class="hljs-comment">% 概率f,用来表示闪电击中的概率</span><br>axes;<span class="hljs-comment">%建立坐标轴</span><br><span class="hljs-built_in">rand</span>(<span class="hljs-string">&#x27;state&#x27;</span>,<span class="hljs-number">0</span>);<br><span class="hljs-comment">%这个命令应该是回到最开始的种子，</span><br><span class="hljs-comment">%否则森林的状态在你第二次运行的时候是接着上一次运行的结果</span><br><span class="hljs-comment">%不是一个新的状态</span><br>set(gcf,<span class="hljs-string">&#x27;DoubleBuffer&#x27;</span>,<span class="hljs-string">&#x27;on&#x27;</span>);<br><span class="hljs-comment">%设置的目的是为了防止在不断循环画动画的时候会产生闪烁的现象</span><br>S=<span class="hljs-built_in">round</span>(<span class="hljs-built_in">rand</span>(<span class="hljs-number">300</span>)*<span class="hljs-number">2</span>);<br><span class="hljs-comment">%将 X 的每个元素四舍五入为最近的整数,本质上就是一个四舍五入的函数</span><br><span class="hljs-comment">%初始化森林</span><br>Sk=<span class="hljs-built_in">zeros</span>(<span class="hljs-number">302</span>);<span class="hljs-comment">%初始化Sk矩阵</span><br>Sk(<span class="hljs-number">2</span>:<span class="hljs-number">301</span>,<span class="hljs-number">2</span>:<span class="hljs-number">301</span>)=S;<span class="hljs-comment">%%加边开始的森林初值，森林的边界为一列或者一行</span><br><span class="hljs-comment">%将其森林的部分插入这个矩阵中</span><br><span class="hljs-comment">% 红色表示正在燃烧(S中等于2的位置)% 绿色表示绿树(S中等于1的位置)% 黑色表示空格位(S中等于0的位置)</span><br>C=<span class="hljs-built_in">zeros</span>(<span class="hljs-number">302</span>,<span class="hljs-number">302</span>,<span class="hljs-number">3</span>);<span class="hljs-comment">%构造一个302*302*3的张量（数组）</span><br>R=<span class="hljs-built_in">zeros</span>(<span class="hljs-number">300</span>);<span class="hljs-comment">%初始化R矩阵</span><br>G=<span class="hljs-built_in">zeros</span>(<span class="hljs-number">300</span>);<span class="hljs-comment">%初始化G矩阵</span><br>R(S==<span class="hljs-number">2</span>)=<span class="hljs-number">1</span>;<span class="hljs-comment">%构成的向量的一个位置上对应的数为2，则给R赋值1</span><br>G(S==<span class="hljs-number">1</span>)=<span class="hljs-number">1</span>;<span class="hljs-comment">%构成的向量的一个位置上对应的数为1，则给R赋值1</span><br><br>C(<span class="hljs-number">2</span>:<span class="hljs-number">301</span>,<span class="hljs-number">2</span>:<span class="hljs-number">301</span>,<span class="hljs-number">1</span>)=R;<span class="hljs-comment">%将C的第一层赋值为R矩阵</span><br>C(<span class="hljs-number">2</span>:<span class="hljs-number">301</span>,<span class="hljs-number">2</span>:<span class="hljs-number">301</span>,<span class="hljs-number">2</span>)=G;<span class="hljs-comment">%将C的第二层赋值为G矩阵</span><br><br>Ci=imshow(C);<span class="hljs-comment">%在图窗中显示灰度图像 I</span><br>ti=<span class="hljs-number">0</span>;<span class="hljs-comment">%初始化时间</span><br>tp=title([<span class="hljs-string">&#x27;T = &#x27;</span>,num2str(ti)]);<span class="hljs-comment">%在标题处显示时间</span><br><span class="hljs-keyword">while</span> <span class="hljs-number">1</span><br>    ti=ti+<span class="hljs-number">1</span>;<span class="hljs-comment">%时间的递增</span><br>    St=Sk;<span class="hljs-comment">%St表示t时刻的森林情况，Sk矩阵代表着随机出来的森林情况</span><br>    St(Sk==<span class="hljs-number">2</span>)=<span class="hljs-number">0</span>;<span class="hljs-comment">%正在燃烧的树变成空格位，经过一个时间间隔后</span><br>    Su=<span class="hljs-built_in">zeros</span>(<span class="hljs-number">302</span>);<span class="hljs-comment">%初始化Su矩阵</span><br>    Sf=Sk;<span class="hljs-comment">%Sf初始化为Sk</span><br>    Sf(Sf&lt;<span class="hljs-number">1.5</span>)=<span class="hljs-number">0</span>;<span class="hljs-comment">%将森林中的空白点和有树的点去掉，只留下着火点</span><br>    Sf=Sf/<span class="hljs-number">2</span>;<span class="hljs-comment">%着火点变为1，此处Sf只有着火和空格两种</span><br>    Su(<span class="hljs-number">2</span>:<span class="hljs-number">301</span>,<span class="hljs-number">2</span>:<span class="hljs-number">301</span>)=Sf(<span class="hljs-number">1</span>:<span class="hljs-number">300</span>,<span class="hljs-number">1</span>:<span class="hljs-number">300</span>)+Sf(<span class="hljs-number">1</span>:<span class="hljs-number">300</span>,<span class="hljs-number">2</span>:<span class="hljs-number">301</span>)+Sf(<span class="hljs-number">1</span>:<span class="hljs-number">300</span>,<span class="hljs-number">3</span>:<span class="hljs-number">302</span>) +...<br>        Sf(<span class="hljs-number">2</span>:<span class="hljs-number">301</span>,<span class="hljs-number">1</span>:<span class="hljs-number">300</span>)+Sf(<span class="hljs-number">2</span>:<span class="hljs-number">301</span>,<span class="hljs-number">3</span>:<span class="hljs-number">302</span>)+Sf(<span class="hljs-number">3</span>:<span class="hljs-number">302</span>,<span class="hljs-number">1</span>:<span class="hljs-number">300</span>) + ...<br>        Sf(<span class="hljs-number">3</span>:<span class="hljs-number">302</span>,<span class="hljs-number">2</span>:<span class="hljs-number">301</span>)+Sf(<span class="hljs-number">3</span>:<span class="hljs-number">302</span>,<span class="hljs-number">3</span>:<span class="hljs-number">302</span>);<br>    <span class="hljs-comment">%对于矩阵中的一个点来说，周围八个点只要有一个点大于0，那么这个点就要变成着火状态（Sf=2）</span><br>    <span class="hljs-comment">%所以这个命令是将矩阵中的一个点的周围八个点的数相加，这个数值就是周围八个点着火点的个数</span><br>    St((Su&gt;<span class="hljs-number">0.5</span>)&amp;(Sk==<span class="hljs-number">1</span>))=<span class="hljs-number">2</span>;<span class="hljs-comment">%如果绿树格位的最近邻居中有一个树在燃烧，则它变成正在燃烧的树；</span><br>    <br>    Se=Sk(<span class="hljs-number">2</span>:<span class="hljs-number">301</span>,<span class="hljs-number">2</span>:<span class="hljs-number">301</span>);<span class="hljs-comment">%将Se初始化为最初森林</span><br>    Se(Se&lt;<span class="hljs-number">0.5</span>)=<span class="hljs-number">4</span>;<span class="hljs-comment">%% 空白地方赋值为4</span><br>    Se(Se&lt;<span class="hljs-number">3</span>)=<span class="hljs-number">0</span>;<span class="hljs-comment">%%有树和着火赋值为0</span><br>    Se(Se&gt;<span class="hljs-number">3</span>)=<span class="hljs-number">1</span>;<span class="hljs-comment">%%空白地方赋值为1</span><br>    <span class="hljs-comment">%三步操作一起将空白处变为1，不是空白处变为0</span><br>    St(<span class="hljs-number">2</span>:<span class="hljs-number">301</span>,<span class="hljs-number">2</span>:<span class="hljs-number">301</span>)=St(<span class="hljs-number">2</span>:<span class="hljs-number">301</span>,<span class="hljs-number">2</span>:<span class="hljs-number">301</span>)+Se.*(<span class="hljs-built_in">rand</span>(<span class="hljs-number">300</span>)&lt;p);<br>    <span class="hljs-comment">%rand(300)&lt;p是一个判断矩阵，对于rand(300)这个矩阵的每一项，如果小于p那么输出1，反之输出0</span><br>    <span class="hljs-comment">%也就是在小于p时长树，大于p时不长树</span><br>    <span class="hljs-comment">%更新t时刻的森林St     </span><br>    Ss=<span class="hljs-built_in">zeros</span>(<span class="hljs-number">302</span>);<span class="hljs-comment">%初始化Ss矩阵</span><br>    Ss(Sk==<span class="hljs-number">1</span>)=<span class="hljs-number">1</span>;<span class="hljs-comment">%%讨论绿树情况</span><br>    Ss(<span class="hljs-number">2</span>:<span class="hljs-number">301</span>,<span class="hljs-number">2</span>:<span class="hljs-number">301</span>)=Ss(<span class="hljs-number">1</span>:<span class="hljs-number">300</span>,<span class="hljs-number">1</span>:<span class="hljs-number">300</span>)+Ss(<span class="hljs-number">1</span>:<span class="hljs-number">300</span>,<span class="hljs-number">2</span>:<span class="hljs-number">301</span>)+Ss(<span class="hljs-number">1</span>:<span class="hljs-number">300</span>,<span class="hljs-number">3</span>:<span class="hljs-number">302</span>) +...<br>        Ss(<span class="hljs-number">2</span>:<span class="hljs-number">301</span>,<span class="hljs-number">1</span>:<span class="hljs-number">300</span>)+Ss(<span class="hljs-number">2</span>:<span class="hljs-number">301</span>,<span class="hljs-number">3</span>:<span class="hljs-number">302</span>)+Ss(<span class="hljs-number">3</span>:<span class="hljs-number">302</span>,<span class="hljs-number">1</span>:<span class="hljs-number">300</span>) + ...<br>        Ss(<span class="hljs-number">3</span>:<span class="hljs-number">302</span>,<span class="hljs-number">2</span>:<span class="hljs-number">301</span>)+Ss(<span class="hljs-number">3</span>:<span class="hljs-number">302</span>,<span class="hljs-number">3</span>:<span class="hljs-number">302</span>);<br>    <span class="hljs-comment">%记录矩阵中的一个点的周围八个点一共有多少棵树</span><br>    <span class="hljs-comment">%这个式子求出的值就是一个点周围树的个数</span><br>    Ss(Ss&lt;<span class="hljs-number">7.5</span>)=<span class="hljs-number">0</span>;<br>    Ss(Ss&gt;<span class="hljs-number">7.5</span>)=<span class="hljs-number">1</span>;<br>    <span class="hljs-comment">%周围的树等于8棵时，Ss赋值为1</span><br>    <span class="hljs-comment">%周围的树小于8棵时，Ss赋值为0</span><br>    d=<span class="hljs-built_in">find</span>(Ss==<span class="hljs-number">1</span> &amp; Sk==<span class="hljs-number">1</span>);<span class="hljs-comment">%查找非零元素的索引和值</span><br>    <span class="hljs-comment">%返回一个包含数组 X 中每个非零元素的线性索引的向量。</span><br>    <span class="hljs-keyword">for</span> k=<span class="hljs-number">1</span>:<span class="hljs-built_in">length</span>(d)<br>        r=<span class="hljs-built_in">rand</span>(<span class="hljs-number">1</span>);<br>        St(d(k))=<span class="hljs-built_in">round</span>(<span class="hljs-number">2</span>*(r&lt;=f)+(r&gt;f));<br>    <span class="hljs-keyword">end</span><br>    <span class="hljs-comment">%在最近的邻居中没有正在燃烧的树的情况下树在每一时步以概率f(闪电)变为正在燃烧的树</span><br>    Sk=St;<span class="hljs-comment">%更新t时刻的森林St</span><br>    R=<span class="hljs-built_in">zeros</span>(<span class="hljs-number">302</span>);<span class="hljs-comment">%初始化R矩阵</span><br>    G=<span class="hljs-built_in">zeros</span>(<span class="hljs-number">302</span>);<span class="hljs-comment">%初始化G矩阵</span><br>    R(Sk==<span class="hljs-number">2</span>)=<span class="hljs-number">1</span>;<span class="hljs-comment">%当Sk中标记为2的点，也是表示着火点则在R中标记出来</span><br>    G(Sk==<span class="hljs-number">1</span>)=<span class="hljs-number">1</span>;<span class="hljs-comment">%当Sk中标记为1的点，也是表示树的点在G中标记出来</span><br>  <br>    C(:,:,<span class="hljs-number">1</span>)=R;<span class="hljs-comment">%把C的第一层赋值为R</span><br>    C(:,:,<span class="hljs-number">2</span>)=G;<span class="hljs-comment">%把C的第二层赋值为G</span><br>  <br>    set(Ci,<span class="hljs-string">&#x27;CData&#x27;</span>,C);<span class="hljs-comment">%第一行是显示图像，C是图像的矩阵，Ci上面有定义，是显示图像。</span><br>    set(tp,<span class="hljs-string">&#x27;string&#x27;</span>,[<span class="hljs-string">&#x27;T = &#x27;</span>,num2str(ti)]);<span class="hljs-comment">%第二行是设置图像的标题，显示T=当前时刻</span><br>    pause(<span class="hljs-number">1</span>);<br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure><hr><p>摘自：<a href="https://zhuanlan.zhihu.com/p/113204715">https://zhuanlan.zhihu.com/p/113204715</a></p>]]></content>
    
    
    <categories>
      
      <category>MCM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MCM</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PCA</title>
    <link href="/2024/01/30/PCA/"/>
    <url>/2024/01/30/PCA/</url>
    
    <content type="html"><![CDATA[<h1 id="主成分分析简述"><a href="#主成分分析简述" class="headerlink" title="主成分分析简述"></a>主成分分析简述</h1><p>主成分分析法通过研究少数几个主成分来解释多个变量之间的内部结构，即从原始变量中导出少数几个主分量，使它们尽可能的保留原始变量的信息，且彼此之间互不相关。</p><p>主成分分析的目的：数据的压缩和数据的解释。</p><h2 id="基本思想"><a href="#基本思想" class="headerlink" title="基本思想"></a>基本思想</h2><p>主成分分析法就是设法将原来众多的具有一定相关性的变量（如P变量），重新组合成一组新的相互无关的变量。</p><p>在数学上，就是将原来p个变量作线性组合作为新的综合变量。</p><p>最经典的方法就是用方差来衡量。设我们选取的数据集为 $F_{1}$, $var(F_{1})$ 越大，说明 $F_{1}$ 所包含的信息越多。因此在所有的线性组合中选取的 $F_{1}$ 应该是方差最大的，称为<strong>第一主成分</strong>。</p><p>如果第一主成分不足以代表原来p个变量的信息，再考虑选取 $F_{2}$ 为第二主成分。</p><p>为了有效反应原来的关系，我们一般要求 $F_{1},F_{2}$ 不含重复信息。</p><p>在实际中，如果各主成分的累计方差贡献率&gt;80%或特征根&gt;1，则满足建模要求。</p><h2 id="数学模型"><a href="#数学模型" class="headerlink" title="数学模型"></a>数学模型</h2><p>我们假定有n个地理样本，每个样本有p个变量，构成一个n*p的矩阵</p><p>$$<br>X_{i}&#x3D;\begin{bmatrix}<br>  x_{11}&amp;x_{12}  &amp;\ldots&amp;x_{1p} \\<br>  x_{21}&amp;x_{22}  &amp;\ldots&amp;x_{2p} \\<br>  \ldots&amp; &amp; &amp;\ldots \\<br>  x_{n1}&amp;x_{n2}  &amp;\ldots&amp;x_{np}<br>\end{bmatrix}<br>$$</p><p>当p比较大时，我们需要进行降维处理，用较少的综合变量代替原来较多的变量。并尽可能反映原始变量的特征。</p><p>一种比较简单的方法是作线性变换，使新的综合变量变为原变量的线性组合</p><p>$$\begin{cases}<br>F_{1}&#x3D;a_{11}x_{1}+\ldots+a_{p1}x_{p}\\<br>F_{2}&#x3D;a_{12}x_{1}+\ldots+a_{p2}x_{p}\\<br>\ldots \\<br>F_{p}&#x3D;a_{1p}x_{1}+\ldots+a_{pp}x_{p}<br>\end{cases}$$</p><p>对于任意常数，我们要求 $var(cF_{i})&#x3D;c^{2}var(F_{i})$</p><p>为了使方差可以比较，我们要求线性组合的系数满足 $\sum_{i&#x3D;1}^{p}a_{ki}^{2}&#x3D;1$</p><p>各变量之间互不相关，协方差为0.</p><p>在建模前，需要进行数据处理，即标准化处理。变量之间的协方差即为相关系数。</p><p>这里直接给出结论：</p><p>通过推导可知， $X_{i}$ 的主成分就是以协方差阵 $\sum$ 的特征向量为系数的线性组合，其方差为协方差阵的特征根。</p><p>主成分的名次使按特征值取值的大小的顺序排列的。</p><p><strong>下面定义贡献率和累计贡献率：</strong></p><p>贡献率</p><p>$$\frac{\lambda_{1}}{\sum_{i&#x3D;1}^{p}\lambda_{i}} 称为第一主成分的贡献率。</p><p>$$var(F_{1})&#x3D;\lambda_{1}$$</p><p>因此第一主成分的贡献率越大，表明其综合各成分的能力越强。</p><p>各成分的贡献率的加和就为累计贡献率。</p><h2 id="检验方法"><a href="#检验方法" class="headerlink" title="检验方法"></a>检验方法</h2><ol><li>KMO检验</li><li>Bartlett’s检验</li></ol>]]></content>
    
    
    <categories>
      
      <category>MCM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MCM</tag>
      
      <tag>PCA</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>线性回归</title>
    <link href="/2024/01/30/RA/"/>
    <url>/2024/01/30/RA/</url>
    
    <content type="html"><![CDATA[<h1 id="一元线性回归"><a href="#一元线性回归" class="headerlink" title="一元线性回归"></a>一元线性回归</h1><p>一般的，我们称由 $y&#x3D;\beta_{0}+\beta_{1}x+\varepsilon $ 确定的模型为一元线性回归模型，记为</p><p>$$\begin{cases}<br>y&#x3D;\beta_{0}+\beta_{1}x+\varepsilon \\<br>E(\varepsilon)&#x3D;0,D(\varepsilon)&#x3D;\sigma^{2}<br>\end{cases}$$</p><p>固定的未知参数 $\beta_{0},\beta_{1}$ 称为回归系数，自变量x称为回归变量。</p><p>$Y&#x3D;\beta_{0}+\beta_{1}x$ 称为<strong>y对x的回归直线方程。</strong></p><p>一元线性回归的主要任务：</p><ol><li>用试验值（样本值）对 $\beta_{0},\beta_{1},\varepsilon$ 作估计</li><li>用回归系数作假设检验</li><li>在 $x&#x3D;x_{0}$ 处作预测得出 $\hat y$ ，对y作区间估计</li></ol><h2 id="普通最小二乘法（OLS）"><a href="#普通最小二乘法（OLS）" class="headerlink" title="普通最小二乘法（OLS）"></a>普通最小二乘法（OLS）</h2><p>在已知数据的基础上，拟合出函数曲线进行预测。</p><p>评判回归精度的标准是：样本回归线上的点与真实观测点的误差应该尽可能小。</p><p>OLS给出的判断标准是：二者之差的平方和最小，即</p><p>$$Q&#x3D;\sum_{i&#x3D;1}^{n}(Y_{i}-\hat Y_{i})^(2)&#x3D;\sum_{i&#x3D;1}^{n}(Y_{i}-(\hat \beta_{0}+\beta_{1}X_{i}))^{2}$$</p><p>由于Q是关于 $\hat \beta_{0},\hat \beta_{1}$ 的二次函数且非负，故极小值存在。</p><p>$$\begin{cases}<br>\frac{\partial Q}{\partial \hat \beta_{0}}&#x3D;0 \\<br> \\<br>\frac{\partial Q}{\partial \hat \beta_{1}}&#x3D;0<br>\end{cases}$$</p><p>结果为：</p><p>$$\begin{cases}<br>\hat \beta_{1}&#x3D;\frac{n\sum Y_{i}X_{i}-\sum Y_{i}\sum X_{i}}{n\sum X_{i}^{2}-(\sum X_{i})^{2}} \\<br> \\<br>\hat \beta_{0}&#x3D;\bar Y-\hat \beta_{1} \bar X<br>\end{cases}$$</p><blockquote><p>其实就是高中的最小二乘法，别被吓到了。</p></blockquote><p>离散形式的版本：</p><p>$$\begin{cases}<br>\bar X&#x3D;\frac{1}{n} \sum X_{i} \\<br>\bar Y&#x3D;\frac{1}{n} \sum Y_{i} \\<br>x_{i}&#x3D;X_{i}-\bar X \\<br>y_{i}&#x3D;Y_{i}-\bar Y<br>\end{cases}$$</p><p>$$\begin{cases}<br>\hat \beta_{1}&#x3D;\frac{\sum x_{i}y_{i}}{\sum x_{i}^{2}} \\<br> \\<br>\hat \beta_{0}&#x3D;\bar Y-\hat \beta_{1} \bar X<br>\end{cases}$$</p><h2 id="随机误差项方差的估计量"><a href="#随机误差项方差的估计量" class="headerlink" title="随机误差项方差的估计量"></a>随机误差项方差的估计量</h2><p>记 $e_{i}&#x3D;Y_{i}-\hat Y_{i}$ 为残差，则随机误差项方差的估计量为：</p><p>$$\hat \delta_{e}^{2}&#x3D;\frac{\sum e_{i}^{2}}{n-2}$$</p><h2 id="回归方程的显著性检验"><a href="#回归方程的显著性检验" class="headerlink" title="回归方程的显著性检验"></a>回归方程的显著性检验</h2><p>对回归方程的显著性检验，归结为对假设</p><p>$$H_{0}:\beta_{1}&#x3D;0,H_{1}:\beta_{1}\ne 0$$</p><p>若 $H_{0}$ 不成立，说明回归方程通过检测。</p><ol><li><em>F</em>检验法</li></ol><p>$$F&#x3D;\frac{U}{Q_{e}&#x2F;(n-2)} ~ F(1,n-2)$$</p><p>其中 $U&#x3D;\sum_{i&#x3D;1}^{n}(\hat y_{i}-\bar y)^{2}$ （回归平方和）</p><p>$Q_{e}&#x3D;\sum_{i&#x3D;0}^{n}(y_{i}-\hat y_{i})^{2}$ （残差平方和）</p><p>$1-\alpha$ 为置信度（即多大把握假设成立）</p><p>若 $F&gt;F_{1-\alpha}(1,n-2)$ ，零假设不成立。</p><ol start="2"><li>r检验法</li></ol><p>$$r&#x3D;\frac{\sum_{i&#x3D;1}^{n}(x_{i}-\bar x)(y_{i}-\bar y)}{\sqrt{\sum_{i&#x3D;1}^{n}(x_{i}-\bar x)^{2}\sum_{i&#x3D;1}^{n}(y_{i}-\bar y)^{2}}}$$</p><p>查表，大于时，零假设不成立。</p><h1 id="多元线性回归"><a href="#多元线性回归" class="headerlink" title="多元线性回归"></a>多元线性回归</h1><p>我们一般称模型<br>$$\begin{cases} Y&#x3D;X\beta+\varepsilon \\ E(\varepsilon)&#x3D;0,COV(\varepsilon,\varepsilon)&#x3D;\sigma^{2}I_{n} \end{cases}$$</p><p>为高斯-马尔可夫线性模型（k元线性回归模型），简记为 $(Y,X\beta,\sigma^{2}I_{n})$</p><p><img src="/Pictures/MCM/RA/plot01.png" alt="img"></p><p>$y&#x3D;\beta_{0}+\sum_{i&#x3D;1}^{n}\beta_{i}x_{i}$ 称为回归平面方程</p><hr><p>多项式回归</p><p>设变量X、Y的回归模型为：</p><p>$$Y&#x3D;\beta_{0}+\beta_{1}x+\beta_{2}x^{2}+\ldots+\beta_{p}x^{p}+\varepsilon$$</p><p>其中p已知， $\varepsilon$ 服从正态分布。</p><p>令 $x_{i}&#x3D;x^{i}$ ，可以转化为多元线性回归模型。</p><h2 id="模型参数估计"><a href="#模型参数估计" class="headerlink" title="模型参数估计"></a>模型参数估计</h2><p>用最小二乘法求 $\beta_{0},\ldots,\beta_{k}$ 的估计量，作离差平方和：</p><p>$$Q&#x3D;\sum_{i&#x3D;1}^{n}(y_{i}-\beta_{0}-\beta_{1}x_{i1}-\ldots-\beta_{k}x_{ik})$$</p><p>选择合适的 $\beta_{0},\ldots,\beta_{k}$ 使Q取最小值</p><p>解得估计值为 $\hat \beta&#x3D;(X^{T}X)^{-1}(X^{T}Y)$ （向量式）</p><p>将求出的 $\hat \beta_{i}$ 代入平面方程得到回归方程。</p><h2 id="线性模型和回归系数的检验"><a href="#线性模型和回归系数的检验" class="headerlink" title="线性模型和回归系数的检验"></a>线性模型和回归系数的检验</h2><p>我们依然可使用<em>F</em>检验法。</p><p>$$F&#x3D;\frac{U&#x2F;k}{Q_{e}&#x2F;(n-k-1)} ~ F(k,n-k-1)$$</p><p>其中 $U&#x3D;\sum_{i&#x3D;1}^{n}(\hat y_{i}-\bar y)^{2}$ （回归平方和）</p><p>$Q_{e}&#x3D;\sum_{i&#x3D;0}^{n}(y_{i}-\hat y_{i})^{2}$ （残差平方和）</p><p>$1-\alpha$ 为置信度（即多大把握假设成立）</p><p>若 $F&gt;F_{1-\alpha}(1,n-2)$ ，零假设不成立。</p><h1 id="逐步回归分析"><a href="#逐步回归分析" class="headerlink" title="逐步回归分析"></a>逐步回归分析</h1><p>在建立回归方程是，我们可以经过筛选，剔除那些对Y影响不显著的变量，而保留影响显著的变量来建立回归方程。</p><p>选择的过程有以下几种：</p><ol><li><p>从所有的变量组合的回归方程中选择最优者</p></li><li><p>从包含全部变量的回归方程中逐次剔除不显著因子</p></li><li><p>从一个变量开始，把变量逐个引入方程</p></li><li><p>有进有出逐步回归分析</p></li></ol><p>一般我们选用第四种方法。</p>]]></content>
    
    
    <categories>
      
      <category>MCM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MCM</tag>
      
      <tag>RA</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>插值与拟合</title>
    <link href="/2024/01/30/%E6%8F%92%E5%80%BC%E4%B8%8E%E6%8B%9F%E5%90%88/"/>
    <url>/2024/01/30/%E6%8F%92%E5%80%BC%E4%B8%8E%E6%8B%9F%E5%90%88/</url>
    
    <content type="html"><![CDATA[<h1 id="插值问题"><a href="#插值问题" class="headerlink" title="插值问题"></a>插值问题</h1><p>当我们遇到“已知函数在某区间内若干点处的值，求函数在该区间（域）内其他点处的值”这种问题使，我们可以考虑使用插值法解决。</p><p>常用的插值法有<em>Lagrange插值法</em>和<em>Newton插值法</em>。</p><h2 id="Lagrange插值法"><a href="#Lagrange插值法" class="headerlink" title="Lagrange插值法"></a>Lagrange插值法</h2><p>拉格朗日插值公式指的是在节点上给出节点基函数，然后做基函数的线性组合，组合系数为节点函数值的一种插值多项式。</p><p>$$f(x)&#x3D;\sum_{i&#x3D;0}^{k}y_{i}\prod_{j\ne i}\frac{x-x_{j}}{x_{i}-x_{j}}$$</p><p>在高次插值时，我们需要考虑高次插值的<strong>Runge现象</strong></p><p>当插值次数超过七次时，插值多项式会出现严重的振荡现象，称为Runge现象。</p><p><img src="/Pictures/MCM/%E6%8F%92%E5%80%BC/plot01.png" alt="img"></p><p>避免方法为：将插值区间分为若干小区间，在小区间内用低次插值</p><h2 id="MATLAB的使用"><a href="#MATLAB的使用" class="headerlink" title="MATLAB的使用"></a>MATLAB的使用</h2><p>基本命令：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs MATLAB">yi=interp1(x,y,xi,<span class="hljs-string">&#x27;method&#x27;</span>) <span class="hljs-comment">%一维插值</span><br><br>zi=interp2(x,y,z,xi,yi,<span class="hljs-string">&#x27;method&#x27;</span>) <span class="hljs-comment">%二维插值</span><br></code></pre></td></tr></table></figure><p>x,y为插值点，xi,yi为被插值点和插值结果,通常为向量；’method’表示插值方法：’nearest’——最邻近插值，’linear’——线性插值 ，’spline’——三次样条插值， ‘cubic’——立方插值。</p><h1 id="拟合问题"><a href="#拟合问题" class="headerlink" title="拟合问题"></a>拟合问题</h1><p>插值和拟合的区别：</p><ol><li><p>插值函数一定过已知点，拟合函数不一定过已知点</p></li><li><p>插值主要求函数值，拟合主要求函数关系</p></li></ol><h2 id="拟合的计算"><a href="#拟合的计算" class="headerlink" title="拟合的计算"></a>拟合的计算</h2><p>曲线拟合需要解决如下两个问题：</p><ol><li><p>线型的选择（根据散点图选择合适的函数模型）</p></li><li><p>线型中参数的计算</p></li></ol><h2 id="MATLAB的使用-1"><a href="#MATLAB的使用-1" class="headerlink" title="MATLAB的使用"></a>MATLAB的使用</h2><ol><li>多项式拟合</li></ol><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs MATLAB">[a,S]=polyfit(x,y,n)<br></code></pre></td></tr></table></figure><p>其中x和y是被拟合数据的自变量和因变量，n为拟合多项式的次数，a为拟合多项式系数构成的向量，S为分析拟合效果所需的指标。</p>]]></content>
    
    
    <categories>
      
      <category>MCM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MCM</tag>
      
      <tag>Interpolation</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>数据预处理</title>
    <link href="/2024/01/29/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/"/>
    <url>/2024/01/29/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h1 id="数据存在的问题"><a href="#数据存在的问题" class="headerlink" title="数据存在的问题"></a>数据存在的问题</h1><ol><li><p>数据不一致</p><blockquote><p>各系统之间数据的量纲不一致</p></blockquote></li><li><p>噪声数据</p><blockquote><p>数据中存在明显错误或异常的数据（偏离期望值）</p></blockquote></li><li><p>缺失值</p><blockquote><p>数据记录出现的局部的缺失</p></blockquote></li></ol><h1 id="数据预处理的任务"><a href="#数据预处理的任务" class="headerlink" title="数据预处理的任务"></a>数据预处理的任务</h1><ol><li><p>数据清洗</p><blockquote><p>去掉数据中的噪声，纠正不一致</p></blockquote></li><li><p>数据集成</p><blockquote><p>将多个数据源合并成一致的数据存储，构成一个完美的数据集，如数据仓库</p></blockquote></li><li><p>数据归约</p><blockquote><p>通过聚集、删除冗余属性或聚类等方法来压缩数据</p></blockquote></li><li><p>数据变换</p><blockquote><p>将一种格式的数据转换为另一种形式的数据</p></blockquote></li></ol><h1 id="基本方法"><a href="#基本方法" class="headerlink" title="基本方法"></a>基本方法</h1><ol><li>简单函数变换</li></ol><p>如果要保持数据保持正态分布，如果提供的数据是偏态的，我们需要将数据从偏态分布变为正态分布。</p><p>此时我们可以对一侧取指数、对数函数</p><ol start="2"><li>归一化</li></ol><p>将数据映射到区间 [-1,1] 或 [0,1] 之间。</p><ul><li>最小-最大规范化</li></ul><p>$$x^{\ast} &#x3D; \frac{x-min}{max-min}$$</p><ul><li>零-均值规范化：处理后平均数为0，标准差为1</li></ul><p>$$x^{\ast} &#x3D; \frac{x-\bar x}{\sigma}$$</p><ul><li>小数定标规范化：移动小数点的数位，k取决于最大值</li></ul><p>$$x^{\ast}&#x3D; \frac{x}{10^{k}}$$</p><ol start="3"><li>缺失值处理</li></ol><p>缺失值的处理可分为三类：删除记录、数据补差和不处理。</p><ul><li>数据补差：<ol><li>我们可以采用平均数、中位数、众数进行补差</li><li>使用固定值</li><li>最近邻补差（使用最相似的数据）</li><li>回归方法（预测）</li><li>插值法（利用已知点建立插值函数）</li></ol></li></ul><p>$$f(x)&#x3D;\sum_{i&#x3D;0}^{n}y_{i} \frac{(x-x_{0})\ldots(x-x_{n})}{(x_{i}-x_{0})\ldots(x_{i}-x_{n})}$$</p><ol start="4"><li>异常值处理<ul><li>删除含有异常值的记录<blockquote><p>设置阈值，处理数据。</p></blockquote></li><li>视为缺失值</li><li>平均值修正</li><li>不处理</li></ul></li></ol><h1 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h1><p>去掉无用特征，去除冗余特征，利用存在的特征、转换特征、内容中的特征以及其他数据源生成的新特征，然后对特征进行转换，最后对特征进行处理，已符合模型的使用。</p><p>简单来说，特征工程的处理有以下的步骤：</p><ul><li>数据预处理</li><li>特征处理</li><li>特征选择</li></ul><h2 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h2><ul><li><p>过滤法：按照发散性或者相关性对各个特征进行评分，通过阈值或者待选择阈的个数来选择特征</p></li><li><p>包装法：根据目标函数（通常是预测效果评分）每次选择若干选项或者排除若干选项</p></li><li><p>嵌入法：使用机器学习的某些算法和模型进行训练，得到各个特征的权值系数，并根据系数从大到小选择特征。</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>MCM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MCM</tag>
      
      <tag>datas</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>GRA</title>
    <link href="/2024/01/29/GRA/"/>
    <url>/2024/01/29/GRA/</url>
    
    <content type="html"><![CDATA[<h2 id="灰色系统的概念"><a href="#灰色系统的概念" class="headerlink" title="灰色系统的概念"></a>灰色系统的概念</h2><p><strong>灰色系统</strong>这个概念的是相对于<strong>白色系统</strong>和<strong>黑色系统</strong>而言的。</p><ul><li><p>白色系统是指一个系统的内部特征是完全已知的，即系统的信息是完全充分的。</p></li><li><p>黑色系统是指一个系统的内部信息对外界来说是一无所知的，只能通过它与外界的联系来加以研究。</p></li><li><p>灰色系统介于两者之间，表示我们只对该系统有部分了解，系统内各因素间有不确定的关系。</p></li></ul><p>灰色系统的应用范畴大致分为以下几方面：</p><ol><li>灰色关联分析</li><li>灰色预测：人口、灾变等</li><li>灰色决策</li><li>灰色预测控制</li></ol><h2 id="灰色预测法"><a href="#灰色预测法" class="headerlink" title="灰色预测法"></a>灰色预测法</h2><p>灰色预测法是一种对含有不确定因素的系统进行预测的方法。</p><p>其核心是在一定范围内变化的、与时间有关的灰色过程进行预测。</p><p>灰色预测通过鉴别系统因素之间发展趋势的相异程度，即进行关联分析，并对原始数据进行生成处理来寻找系统变动的规律，生成有较强规律性的数据序列，建立相应的微分方程模型。</p><h3 id="灰色预测的四种常见类型"><a href="#灰色预测的四种常见类型" class="headerlink" title="灰色预测的四种常见类型"></a>灰色预测的四种常见类型</h3><ol><li><p>灰色时间序列预测</p><blockquote><p>用观察到的反应预测对象特征的时间序列来构造灰色预测模型，预测未来某一时刻的特征量，或达到某一特征量的时间</p></blockquote></li><li><p>畸变预测</p><blockquote><p>即通过灰色模型预测异常值出现的时刻，预测异常值什么时候出现在特定时区内</p></blockquote></li><li><p>系统预测</p><blockquote><p>通过对系统行为特征指标建立一组相互关联的灰色预测模型，预测系统中众多变量之间的相互协调关系的变化。</p></blockquote></li><li><p>拓扑预测</p><blockquote><p>将原始数据做曲线，在曲线上按定值寻找该定值发生的所有时点，并以该定值为框架生成时点数列，建立模型预测该定值所发生的时间点</p></blockquote></li></ol><h2 id="灰色关联度与优势分析"><a href="#灰色关联度与优势分析" class="headerlink" title="灰色关联度与优势分析"></a>灰色关联度与优势分析</h2><p>我们分析一个系统时，需要对系统进行因素分析，找出主要和次要、促进和抑制、潜在和明显的因素。</p><p>事实上，<em>因素之间关联性如何、关联程度如何量化等问题</em>是系统分析的关键。</p><p>对于回归分析法来说，灰色关联度不需要大量的数据、计算量较小、反常情况影响小。</p><p>灰色关联度是分析向量与向量、矩阵与矩阵之间的关联度，需要<strong>选取参考数据。</strong></p><h3 id="灰色关联度的数学模型"><a href="#灰色关联度的数学模型" class="headerlink" title="灰色关联度的数学模型"></a>灰色关联度的数学模型</h3><p>首先也是最重要的，我们需要确定<strong>参考数列</strong>。我们假设参考数列为 $X_{0}$ ，有：</p><p>$$<br>X_{0}&#x3D;（X_{0}(k) | k&#x3D;1,2,\ldots,n）&#x3D;(X_{0}(1),X_{0}(2),\ldots,X_{0}(n))<br>$$</p><p>其中 $k$ 表示时刻</p><p>假设有m个<strong>比较数列</strong></p><p>$$<br>X_{i}&#x3D;（X_{i}(k)|k&#x3D;1,2,\ldots,n ）&#x3D;(X_{i}(1),X_{i}(2),\ldots,X_{i}(n))\\<br>(i&#x3D;1,2,\ldots,n)<br>$$</p><p>则称</p><p><img src="/Pictures/MCM/GRA/plot01.png" alt="img"></p><p>为灰色关联系数，其中 $\rho$ 称为分辨系数，一般取 $\rho &#x3D; 0.5$ 。</p><p>由上式给出的定义在各个时刻都有一个关联系数，信息过于分散不易比较，因此我们给出</p><p>$$ r_{i}&#x3D;\frac{1}{n} \sum_{k&#x3D;1}^{n} \zeta_{i}(k) $$</p><p>为比较数列对参考数列的<strong>关联度</strong>。</p><p>由于公式研究的是关联系数的相对大小，无法判断是正相关还是负相关，我们记</p><p>$$<br>\sigma_{i}&#x3D;\sum_{k&#x3D;1}^{n}kX_{i}(k)-\sum_{k&#x3D;1}^{n}X_{i}(k)\sum_{k&#x3D;1}^{n}\frac{k}{n}<br>$$</p><p>$$<br>\sigma_{n}&#x3D;\sum_{k&#x3D;1}^{n}k^{2}-\frac{2(\sum_{k&#x3D;1}^{n}k)}{n}<br>$$</p><p>$$sign(\frac{\sigma_{i}}{\sigma_{n}})&#x3D;sign(\frac{\sigma_{j}}{\sigma_{n}})$$ </p><p>称数列i与j为正相关，反之若不同号则为负相关。</p><h2 id="灰色生成数列"><a href="#灰色生成数列" class="headerlink" title="灰色生成数列"></a>灰色生成数列</h2><p>灰色序列常见的数据生成方法有：累加生成、累减生成和加权累加。</p><h3 id="累加生成"><a href="#累加生成" class="headerlink" title="累加生成"></a>累加生成</h3><p>把数列各项（时刻）数据依次累加的过程称为累加生成过程，由累加生成过程所得的数列称为累加生成数列。</p><p>若原始数列为 $x^{0}&#x3D;(x^{0}(1),x^{0}(2),\ldots,x^{0}(n))$</p><p>令 $x^{1}(k)&#x3D;\sum_{i&#x3D;1}^{k}x^{0}(i)$ ,得到新数列,称为1次累加生成数列。</p><p>例如，数列 $(1,2,3,4)$ 经过累加处理得到 $(1,3,6,10)$</p><p>多次累加处理即可得到i次累加生成数列</p><h3 id="累减生成"><a href="#累减生成" class="headerlink" title="累减生成"></a>累减生成</h3><p>为累加过程的逆过程</p><p>由上述的数列 $x^{1}$ 累减得到的数列就是 $x^{0}$</p><p>在实际运用中，我们可以i在数列 $x^{1}$ 的基础上得到预测数列 $\hat x^{1}$ ，累减得到预测数列 $\hat x^{0}$ 。</p><p>不难看出，累减生成具有求导性质。</p><h3 id="加权邻值生成"><a href="#加权邻值生成" class="headerlink" title="加权邻值生成"></a>加权邻值生成</h3><p>在原始数列中，相邻的两个数据称为前邻值和后邻值。对于常数 $\alpha$ ，令：</p><p>$$z^{0}(k)&#x3D;\alpha x^{0}(k)+(1-\alpha)x^{0}(k-1)$$</p><p>得到的数列 $z^{0}$ 称为数列 $x^{0}$ 在权 $\alpha$ 下的邻值生成数， $\alpha$ 为生成系数。</p><p>当 $\alpha&#x3D;0.5$ 时，也称均值生成数。</p><p>应用：便于将无规律的数据处理为有一定规律的数据。</p><p><img src="/Pictures/MCM/GRA/plot02.png" alt="img"></p><p><img src="/Pictures/MCM/GRA/plot03.png" alt="img"></p><h2 id="灰色模型GM"><a href="#灰色模型GM" class="headerlink" title="灰色模型GM"></a>灰色模型GM</h2><p>灰色模型是利用离散随机数经过生成变为随机性被显著削弱而且有规律的生成数建立起的微分方程形式的模型，这样便于对其变化过程进行研究和描述。</p><p>设原始数列为 $x^{0}&#x3D;(x^{0}(1),x^{0}(2),\ldots,x^{0}(n))$</p><p>一次累加数列为 $x^{1}&#x3D;(x^{1}(1),x^{1}(2),\ldots,x^{1}(n))$</p><p>定义 $x^{1}$ 的<strong>灰导数</strong>为：</p><p>$$d(k)&#x3D;x^{0}(k)&#x3D;x^{1}(k)-x^{1}(k-1)$$</p><p>令 $z^{1}$ 为数列 $x^{1}$ 的邻值生成数列，即</p><p>$$z^{0}(k)&#x3D;\alpha x^{0}(k)+(1-\alpha)x^{0}(k-1)$$</p><p>于是定义GM的灰微分方程模型为</p><p>$$d(k)+az^{1}(k)&#x3D;x^{0}(k)&#x3D;az^{1}(k)&#x3D;b$$</p><p>我们称a为发展系数，b为灰作用量。</p><p>将k代入可得：</p><p>$$\begin{cases}<br>x^{0}(2)&#x3D;az^{1}(2)&#x3D;b \\<br>x^{0}(3)&#x3D;az^{1}(3)&#x3D;b \\<br>\ldots \\<br>x^{0}(n)&#x3D;az^{1}(n)&#x3D;b<br>\end{cases}$$</p><p><img src="/Pictures/MCM/GRA/plot04.png" alt="img"></p><p>则该模型表示为 $Y&#x3D;Bu$</p><p>用最小二乘法估计：</p><p><img src="/Pictures/MCM/GRA/plot05.png" alt="img"></p><p><strong>这样我们可以得到a、b的值。</strong></p><p>之后，我们建立GM模型，得出对应的白化模型并求解。</p><p>白化模型为：</p><p>$$<br>\frac{dx^{1}(t)}{dt}+ax^{1}(t)&#x3D;b<br>$$</p><p>通解为：</p><p>$$<br>x^{1}(t)&#x3D;(x^{0}(1)-\frac{b}{a})e^{-a(t-1)}+\frac{b}{a}<br>$$</p><p>将t替换为k，即得到预测值。</p><h2 id="数据的处理"><a href="#数据的处理" class="headerlink" title="数据的处理"></a>数据的处理</h2><p>在大部分情况下，我们需要对原始数据进行处理。</p><p>设原始数列为 $x^{0}&#x3D;(x^{0}(1),x^{0}(2),\ldots,x^{0}(n))$</p><p>定义<strong>数列的级比</strong>：</p><p>$$<br>\lambda(k)&#x3D;\frac{x^{0}(k-1)}{x^{0}(k)},k&#x3D;2,3,\ldots,n<br>$$</p><p>如果所有的级比均落在可容覆盖区间 $X&#x3D;(e^{\frac{-2}{n+1}},e^{\frac{2}{n+1}})$ 内，则数据可以建立GM模型。</p><p>否则需要对数据进行变换处理。</p><p>平移变换：取常数c，使数据列</p><p>$$y^{0}(k)&#x3D;x^{0}(k)+C$$</p><p>让数据均落在区间内。</p><h2 id="结果的检验"><a href="#结果的检验" class="headerlink" title="结果的检验"></a>结果的检验</h2><ol><li>残差检验<br>定义相对残差：<br>$$<br>\varepsilon (k)&#x3D;\frac{x^{0}(k)-\hat x^{0}(k)}{x^{0}(k)}<br>$$</li></ol><p>根据实际情况界定残差的范围，一般要求 $\varepsilon(k) &lt;0.2$</p><ol start="2"><li>级比偏差值检验：<br>$$<br>\rho(k)&#x3D;1-\frac{1-0.5a}{1+0.5a} \lambda (k)<br>$$</li></ol><p>根据实际情况界定残差的范围，一般要求 $\rho(k) &lt;0.2$</p>]]></content>
    
    
    <categories>
      
      <category>MCM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MCM</tag>
      
      <tag>GRA</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CA</title>
    <link href="/2024/01/28/CA/"/>
    <url>/2024/01/28/CA/</url>
    
    <content type="html"><![CDATA[<h1 id="聚类分析（CA）"><a href="#聚类分析（CA）" class="headerlink" title="聚类分析（CA）"></a>聚类分析（CA）</h1><h2 id="聚类（Clustering）"><a href="#聚类（Clustering）" class="headerlink" title="聚类（Clustering）"></a>聚类（Clustering）</h2><p>聚类是将一个数据集划分为若干组（class）或类（cluster）的过程，使得同一组内的数据对象具有较高的相似度，而不同组的数据对象是不相似的。</p><p>相似和不相似是基于数据描述属性的取值来决定的，通常利用各数据对象之间的距离来表示。</p><p>聚类分析适用于探讨样本之间的相互关联关系从而对一个样本结构做一个初步的评价。</p><blockquote><p>聚类和分类的区别：聚类是一种无监督的学习方法，不依赖于事先确定的数据类别以及标有数据类别的学习训练样本集合。</p></blockquote><h2 id="聚类分析的分类"><a href="#聚类分析的分类" class="headerlink" title="聚类分析的分类"></a>聚类分析的分类</h2><p>聚类分析由两种组成：</p><ul><li>对样品的分类，称为Q型</li><li>对变量（指标）的分类，称为R型</li></ul><p>R型聚类分析的主要作用：</p><ol><li>了解各个变量之间的亲疏程度，进行综合降维处理</li><li>根据变量的分类结果以及它们之间的关系，可以选择主要变量进行Q型聚类分析或回归分析</li></ol><p>Q型聚类分析的主要作用：</p><ol><li>可以综合利用多个变量的信息对样本进行分析。</li><li>分类结果直观，聚类谱系图清楚地表现数值分类结果。</li><li>聚类分析所得到的结果更为细致全面。</li></ol><p>Q型聚类分析一般是我们研究的重点，Q型聚类的统计量一般是距离。</p><h2 id="样品间的相似度量——距离"><a href="#样品间的相似度量——距离" class="headerlink" title="样品间的相似度量——距离"></a>样品间的相似度量——距离</h2><p>设有n个样本的p元观测数据：</p><p>$$x_{i}&#x3D;(x_{i1},x_{i2},\ldots,x_{ip})^{T} , i&#x3D;1,2,\ldots,n$$</p><p>这时，每一个样本可以看作p元空间的一个点，每两个点之间的距离记为 $d(x_{i},x_{j})$ 。</p><p>$$\begin{cases}<br>d(x_{i},x_{j})\ge 0,且 d(x_{i},x_{j})&#x3D;0 当且仅当x_{i}&#x3D;x_{j}\\<br>d(x_{i},x_{j})&#x3D;d(x_{j},x_{i})<br>d(x_{i},x{j})\le d(x_{i},x_{k})+d(x_{k},x_{j})<br>\end{cases}$$</p><ol><li>欧式距离</li></ol><p>$$d(x_{i},x_{j})&#x3D;\sqrt{\sum_{k&#x3D;1}^{p}(x_{ik}-x_{jk})^{2}}$$</p><p>记为 $pdist(x)$</p><ol start="2"><li>明式距离</li></ol><p>$$d(x_{i},x_{j})&#x3D;[{\sum_{k&#x3D;1}^{p}(x_{ik}-x_{jk})^{m}}]^{\frac{1}{m}}$$</p><ol start="3"><li>切式距离</li></ol><p>$$d(x_{i},x_{j})&#x3D;max\ \left| x_{ik}-x_{jk} \right | $$</p><h2 id="变量之间的相似度量——相似系数"><a href="#变量之间的相似度量——相似系数" class="headerlink" title="变量之间的相似度量——相似系数"></a>变量之间的相似度量——相似系数</h2><p>当对p个指标变量进行聚类时，用相似系数来衡量变量之间的相似程度（关联度）。</p><p>$$定义相似系数为 C_{\alpha \beta }$$</p><p>满足：</p><p>$$\begin{cases}<br>\left |C_{\alpha \beta } \right | \le 1 \\<br>C_{\alpha \alpha }&#x3D;1 \\<br>C_{\alpha \beta }&#x3D;\pm 1 当且仅当 \alpha&#x3D;k \beta,k\ne 0 \\<br>C_{\alpha \beta }&#x3D;C_{\beta \alpha}<br>\end{cases}$$</p><p>相似系数中最常用的是相关系数与夹角余弦。</p><ol><li>夹角余弦<br>两变量的夹角余弦的定义为：</li></ol><p>$$C_{ij}&#x3D;cos\ \alpha_{ij}&#x3D; \frac{\sum_{t&#x3D;1}^{n}x_{ti}x_{tj}}{\sqrt{\sum_{t&#x3D;1}^{n}x_{ti}^{2}} \sqrt{\sum_{t&#x3D;1}^{n}x_{tj}^{2}}}$$</p><ol start="2"><li>相关系数<br>两变量的相关系数为：</li></ol><p>$$C_{ij}&#x3D; \frac{\sum_{t&#x3D;1}^{n}(x_{ti}-\bar x_{i})(x_{tj}-\bar x_{j})}{\sqrt{\sum_{t&#x3D;1}^{n}(x_{ti}-\bar x_{i})^{2}} \sqrt{\sum_{t&#x3D;1}^{n}(x_{tj}-\bar x_{j})^{2}}}$$</p><h2 id="类间距离"><a href="#类间距离" class="headerlink" title="类间距离"></a>类间距离</h2><p>现在我们可以来计算两个类别之间的距离。</p><p>设 $d_{ij}$ 表示两个样品 $x_{i},x_{j}$ 之间的距离， $G_{p},G_{q}$ 表示两个类别，各自含有 $n_{p},n_{q}$ 个样品。</p><p>我们可以用两类中的样本之间的最短（最长）距离作为两类之间的距离。</p><ul><li><p>重心距离：平均点之间的距离:<br>$$D_{pq}&#x3D;\sqrt{(\bar x_{p}-\bar x_{q})^{T}(\bar x_{p}-\bar x_{q})}$$</p></li><li><p>重心：每个维度的坐标均为所有坐标的算术平均数</p></li><li><p>类平均距离：<br>$$D_{pq}&#x3D;\frac{1}{n_{p}n_{q}} \sum_{i\in G_{p}} \sum_{j\in G_{q}} d_{ij} $$</p></li></ul><h2 id="谱系聚类法的步骤"><a href="#谱系聚类法的步骤" class="headerlink" title="谱系聚类法的步骤"></a>谱系聚类法的步骤</h2><ol><li>选择样本点之间距离的定义以及类间距离的定义</li><li>计算n个样本两两之间的距离，得到距离矩阵 $D&#x3D;(d_{ij})_{n*n}$ ，D为实对称矩阵</li><li>构造个类，每个类只含有一个样本</li><li>合并符合类间距离定义要求的两个类为一个新类</li><li>重新计算类间距离，并重复上述步骤直到类数为1</li><li>画出聚类图</li><li>决定类的个数和类</li></ol><p>下图为聚类谱系图的实例：</p><p><img src="/Pictures/MCM/CA/plot01.png" alt="img"></p><p>上图中，3，4在2.20处分为了一类G1，G1和5在2.21处分为了一类G2，1，2在11左右分为了一类G3，到最大值时G2和G3归为一类G0.</p><h2 id="k——平均聚类算法"><a href="#k——平均聚类算法" class="headerlink" title="k——平均聚类算法"></a>k——平均聚类算法</h2><h3 id="k-means算法"><a href="#k-means算法" class="headerlink" title="k-means算法"></a><em>k-means</em>算法</h3><ol><li>从n个数据对象中选择k个对象作为初始聚类中心</li><li>根据每个聚类对象的均值（中心对象），计算距离并根据最小距离重新对相应对象进行划分</li><li>更新中心对象</li><li>循环上述步骤一直到每个聚类不再变化</li></ol><p>算法特点：</p><ul><li>只适用于均值有意义的场所</li><li>对离群点和噪声数据敏感，极端效应严重</li></ul><p><img src="/Pictures/MCM/CA/plot02.png" alt="img"></p>]]></content>
    
    
    <categories>
      
      <category>MCM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MCM</tag>
      
      <tag>CA</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>TOPSIS</title>
    <link href="/2024/01/28/TOPSIS/"/>
    <url>/2024/01/28/TOPSIS/</url>
    
    <content type="html"><![CDATA[<h1 id="TOPSIS法简述"><a href="#TOPSIS法简述" class="headerlink" title="TOPSIS法简述"></a>TOPSIS法简述</h1><p>TOPSIS法，又称理想解法。这种方法通过构造评价问题的正理想解和负理想解，即各指标的最优解和最劣解，通过计算每个方案到理想方案的相对贴进度，远离最劣解的程度来进行排序。</p><h2 id="方法和原理"><a href="#方法和原理" class="headerlink" title="方法和原理"></a>方法和原理</h2><p>设多属性决策方案集为 $D&#x3D;$ { $d_{i}|i&#x3D;1,2,\ldots,n$ } ，衡量方案优劣的属性变量为 $x_{i}$ ，这时方案集D中每个方案的n个属性值构成的向量是 $\left[ a_{i1},\ldots,a_{in} \right]$ ，它作为空间中的一个点，能唯一地表征方案 $d_{i}$ 。</p><p>正理想解 $C^{*}$ 是一个方案集中并不存在的虚拟的最佳方案，它的每个属性值都是决策矩阵中该属性的最好值。</p><p>而负理想解 $C^{0}$ 是虚拟的最差方案，它的每个属性值都是决策矩阵中该属性的最差值。</p><p>在方案集中，尽可能靠近正理想解而原理负理想解的方案就是最佳方案。</p><p>在实际操作中我们需要解决如下几个问题：</p><ol><li>数据的规律</li><li>距离的计算方法和衡量方法</li><li>消除量纲的影响</li></ol><h2 id="算法的步骤"><a href="#算法的步骤" class="headerlink" title="算法的步骤"></a>算法的步骤</h2><h3 id="用向量规划化的方法求得规范决策矩阵"><a href="#用向量规划化的方法求得规范决策矩阵" class="headerlink" title="用向量规划化的方法求得规范决策矩阵"></a>用向量规划化的方法求得规范决策矩阵</h3><p>设多属性决策问题的决策矩阵 $A&#x3D;(a_{ij})_{m*n}$</p><p>规范化决策矩阵 $B&#x3D;(b_{ij})_{m*n}$ </p><p>其中 $b_{ij}&#x3D; \frac{a_{ij}}{\sqrt {\sum_{i&#x3D;1}^{m} a_{ij}^{2}}}$  </p><blockquote><p>这一步用来消除量纲的影响</p></blockquote><p>对于每一项属性，其所占的评价权重也不尽相同，因此我们需要构造加权规范矩阵 $C&#x3D;(c_{ij})_{m*n}$</p><p>设由决策人给定各属性的权重向量为 $w&#x3D;[w_{1},w_{2},\ldots,w_{n}]^{T}$ ，则</p><p>$$<br>c_{ij}&#x3D;w_{j}*b_{ij}<br>$$</p><h3 id="确定正理想解和负理想解"><a href="#确定正理想解和负理想解" class="headerlink" title="确定正理想解和负理想解"></a>确定正理想解和负理想解</h3><p>设正（负）理想解的第j个属性值为 $c_{j}^{*}$ ( $c_{j}^{0}$ ) ，则：</p><p>$$<br>c_{j}^{\ast}&#x3D;<br>\begin{cases}<br>max\ c_{ij} , j 为效益性属性 \\<br> \\<br>min\ c_{ij} , j 为成本性属性 \\<br>\end{cases}<br>$$</p><p>$$<br>c_{j}^{0}&#x3D;<br>\begin{cases}<br>max\ c_{ij} , j 为成本性属性 \\<br> \\<br>min\ c_{ij} , j 为效益性属性 \\<br>\end{cases}<br>$$</p><h3 id="确定距离公式"><a href="#确定距离公式" class="headerlink" title="确定距离公式"></a>确定距离公式</h3><p>各方案到正（负）理想解的距离为：</p><p>$$<br>s_{i}^{\ast}\ &#x3D; \ \sqrt{ \sum_{j&#x3D;1}^{n} (c_{ij}-c_{j}^{\ast})^{2}}<br>$$</p><p>$$<br>s_{i}^{0}\ &#x3D; \ \sqrt{ \sum_{j&#x3D;1}^{n} (c_{ij}-c_{j}^{0})^{2}}<br>$$</p><h3 id="计算综合评价指数"><a href="#计算综合评价指数" class="headerlink" title="计算综合评价指数"></a>计算综合评价指数</h3><p>$$<br>f_{i}^{\ast} \ &#x3D;\ \frac{s_{i}^{0}} {s_{i}^{0}+s_{i}^{\ast}}<br>$$</p><p>根据综合评价指数便可得出方案的优劣次序。</p><h2 id="数据的处理"><a href="#数据的处理" class="headerlink" title="数据的处理"></a>数据的处理</h2><h3 id="属性值比例化"><a href="#属性值比例化" class="headerlink" title="属性值比例化"></a>属性值比例化</h3><p>属性值不好直接从数值大小进行判断时，我们需要对数据进行预处理，使得表中任意属性下性能越优的方案变换后的属性值越大。</p><h3 id="非量纲化"><a href="#非量纲化" class="headerlink" title="非量纲化"></a>非量纲化</h3><p>不同属性之间量纲的不同使属性具有不可公度性，我们需要在数据处理时消除量纲的影响。</p><h3 id="归一化"><a href="#归一化" class="headerlink" title="归一化"></a>归一化</h3><p>属性之间数值大小差别较大，为了方便直观比较，我们需要对属性的数值进行归一化。</p><h3 id="常见的处理方法"><a href="#常见的处理方法" class="headerlink" title="常见的处理方法"></a>常见的处理方法</h3><ol><li>线性变换</li></ol><p>$$<br>b_{ij}&#x3D;\frac{a_{ij}}{a_{j}^{max}}<br>$$</p><ol start="2"><li>标准0-1变换</li></ol><blockquote><p>为了使最优为1，最差为0</p></blockquote><p>对效益性属性：<br>$$<br>b_{ij}=\ \frac{a_{ij}-a_{j}^{max}}{a_{j}^{max}-a_{j}^{min}}<br>$$</p><p>对成本性属性：<br>$$<br>b_{ij}=\ \frac{a_{j}^{max}-a_{ij}}{a_{j}^{max}-a_{j}^{min}}<br>$$</p><ol start="3"><li>区间属性的变换<br>属性在某一个区间范围内最优，我们设给出的最优区间为 $[a_{j}^{0},a_{j}^{\ast}]$ , $a_{j}^{‘}$ 为无法容忍下限， $a_{j}^{‘’}$ 为无法容忍上限，则</li></ol><p>$$<br>b_{ij}&#x3D;<br>\begin{cases}<br>1-\frac{a_{j}^{0}-a_{ij}}{a_{j}^{0}-a_{j}^{‘}} , a_{j}^{‘}\le a_{ij}\le a_{j}^{0}\\<br> \\<br>1 , a_{j}^{0}\le a_{ij}\le a_{j}^{\ast}\\<br> \\<br>1-\frac{a_{ij}-a_{j}^{\ast}}{a_{j}^{‘’}-a_{j}^{\ast}} , a_{j}^{\ast}\le a_{ij}\le a_{j}^{‘’}<br> \\<br>0<br>\end{cases}<br>$$</p><p>变换后的属性值对应的函数图形为一般梯形。当最优区间的上下界相等，退化为三角形。</p><ol start="4"><li>向量规范化</li></ol><p>$$<br>b_{ij}&#x3D; \frac{a_{ij}}{\sqrt {\sum_{i&#x3D;1}^{m} a_{ij}^{2}}}<br>$$</p><p>经常用于计算欧氏距离的场合。</p>]]></content>
    
    
    <categories>
      
      <category>MCM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MCM</tag>
      
      <tag>TOPSIS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>AHP</title>
    <link href="/2024/01/28/%E5%B1%82%E6%AC%A1%E5%88%86%E6%9E%90%E6%B3%95-AHP/"/>
    <url>/2024/01/28/%E5%B1%82%E6%AC%A1%E5%88%86%E6%9E%90%E6%B3%95-AHP/</url>
    
    <content type="html"><![CDATA[<h1 id="层次分析法-AHP-基本模型"><a href="#层次分析法-AHP-基本模型" class="headerlink" title="层次分析法(AHP)基本模型"></a>层次分析法(AHP)基本模型</h1><p>层次分析法旨在对于复杂的决策问题的本质、影响因素及其内在关系等进行深入分析的基础上，利用较少的定量信息使决策的思维过程数学化，从而为多目标、多准则或无结构特性的复杂决策问题提供简便的决策方法。</p><h2 id="层次分析法概述"><a href="#层次分析法概述" class="headerlink" title="层次分析法概述"></a>层次分析法概述</h2><p>AHP的基本内容：</p><ul><li>将定量分析和定性分析结合起来</li><li>用决策者的<strong>经验判断</strong>各衡量目标能否实现的标准之间的<strong>相对重要程度</strong></li><li>给出每个决策方案的每个标准的权数，利用权数求出各方案的优劣次序</li></ul><h2 id="层次分析法的典型应用"><a href="#层次分析法的典型应用" class="headerlink" title="层次分析法的典型应用"></a>层次分析法的典型应用</h2><ul><li>用于最佳方案的选取</li><li>用于评价类问题</li><li>用于指标体系的优选</li></ul><h2 id="层次分析法的步骤和方法"><a href="#层次分析法的步骤和方法" class="headerlink" title="层次分析法的步骤和方法"></a>层次分析法的步骤和方法</h2><h3 id="建立层次结构模型"><a href="#建立层次结构模型" class="headerlink" title="建立层次结构模型"></a>建立层次结构模型</h3><blockquote><p>将决策的目标、考虑的因素（决策准则）和决策对象按他们之间的相互关系分为最高层、中间层和最底层，绘出层次结构图。</p></blockquote><ul><li>最高层：决策的目的、要解决的问题</li><li>最底层：决策时的备选方案</li><li>中间层：考虑的因素、决策的准则</li></ul><blockquote><p>对于相邻的两层，称高层为目标层，低层为因素层。</p></blockquote><p>例子：对于大学毕业生，在选择就业岗位时，一般会考虑以下因素（不完全）：</p><ol><li>能发挥自己的才干做出贡献</li><li>收入较好</li><li>生活环境好</li><li>单位名声好</li><li>工作环境好</li><li>发展前景好</li></ol><p>根据这些因素，我们可以建立以下的层次结构模型：</p><p><img src="/Pictures/MCM/AHP/plot01.png" alt="img"></p><p>每层之间的若干元素用直线连接。</p><h3 id="构造判断（成对比较）矩阵"><a href="#构造判断（成对比较）矩阵" class="headerlink" title="构造判断（成对比较）矩阵"></a>构造判断（成对比较）矩阵</h3><p>在确定各层次各因素之间的权重时，如果只是定性的结果，则常常不容易被别人接受。故我们采用<strong>一致矩阵法</strong>，将因素之间两两比较，采用相对尺度，提高准确度。</p><p>判断矩阵时表示本层所有因素针对上一层某一个因素的相对重要性的比较。</p><p>判断矩阵的元素 $a_{ij}$ （第i项因素相对于第j项元素的标度）由Santy的1-9标度方法给出。</p><blockquote><p>在选取比较的因素时，建议不要超过9个。</p></blockquote><p>判断矩阵元素 $a_{ij}$ 的标度方法</p><table><thead><tr><th align="center">标度</th><th align="center">含义</th></tr></thead><tbody><tr><td align="center">1</td><td align="center">表示两个因素相比,具有同等重要性</td></tr><tr><td align="center">3</td><td align="center">表示两个因素相比，一个因素比另一个稍微重要</td></tr><tr><td align="center">5</td><td align="center">一个因素比另一个明显重要</td></tr><tr><td align="center">7</td><td align="center">一个因素比另一个强烈重要</td></tr><tr><td align="center">9</td><td align="center">一个因素比另一个极端重要</td></tr><tr><td align="center">2,4,6,8</td><td align="center">相邻的中值</td></tr><tr><td align="center">倒数</td><td align="center">因素 $i,j$ 之间一方标度为 $a_{ij}$ ,则另一方为倒数</td></tr></tbody></table><p>构造出来的矩阵 $A&#x3D;(a_{ij})_{n*n}$ 为正互反矩阵</p><p>下面是一个例子：</p><p>$$\begin{bmatrix}<br>  1&amp;  \frac{1}{2}&amp;  4&amp;  3&amp;3 \\<br>  2&amp;  1&amp;  7&amp;  5&amp;5 \\<br>  \frac{1}{4}&amp;  \frac{1}{7}&amp;  1&amp;  \frac{1}{2}&amp;\frac{1}{3} \\<br>  \frac{1}{3}&amp;  \frac{1}{5}&amp;  2&amp;  1&amp;1 \\<br>  \frac{1}{3}&amp;  \frac{1}{5}&amp;  3&amp;  1&amp;1<br>\end{bmatrix}$$</p><h3 id="层次单排序及其一致性检验"><a href="#层次单排序及其一致性检验" class="headerlink" title="层次单排序及其一致性检验"></a>层次单排序及其一致性检验</h3><p>实际上，上述矩阵存在问题。</p><p>我们假设因素用 $C_{i}\ (i&#x3D;1,2,3,4,5)$ 来表示，则 $a_{ij}&#x3D;C_{i}:C_{j}$</p><p>我们发现: $\frac{C_{1}}{C_{2}}&#x3D;\frac{1}{2}$ , $\frac{C_{1}}{C_{3}}&#x3D;4$ ,然而 $\frac{C_{2}}{C_{3}}&#x3D;7$ ，这显然和我们的评价不一致。</p><p>考虑到实际情况中存在的<strong>边际效应</strong>和<strong>评价的相对性</strong>，我们允许不一致的出现，但要确定不一致的允许范围。</p><p>如果我们得出的矩阵完全一致，即 $rank(A)&#x3D;1$ ，我们称这样的矩阵为一致阵，其中非零特征值为 $tr(A)&#x3D;n$ 。</p><p>对于不一致的比较矩阵，我们可以将对大的特征值 $\lambda_{max}$ 对应的特征向量作为权向量，记为 $w$ 。</p><p>权向量为同一层次因素对于上一层次因素某因素相对重要性的排序权值，这一过程称为层次单排序。</p><p>一致性检验的工作正是确定偏移值A的范围。</p><p>定义一致性指标如下： </p><p>$$CI\ &#x3D;\ \frac{\lambda -n}{n-1}$$</p><p><strong>CI越接近于0，一致性越高。</strong></p><p>为衡量CI的大小，引入<em>随机一致性指标RI</em>。方法为随即构造500个成对比较矩阵 $A_{n}$ ，可得一致性指标 $CT_{n}$ 。取算术平均数即为RI大小。</p><p>对于不同的n，RI的值由下表给出：</p><table><thead><tr><th>n</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th><th>8</th><th>9</th><th>10</th><th>11</th></tr></thead><tbody><tr><td>RI</td><td>0</td><td>0</td><td>0.58</td><td>0.90</td><td>1.12</td><td>1.24</td><td>1.32</td><td>1.41</td><td>1.45</td><td>1.49</td><td>1.51</td></tr></tbody></table><p>定义一致性比率：</p><p>$CR\ &#x3D;\ \frac{CI}{RI}$ ，当CR&lt;0.1时，认为A的不一致程度在容许范围之内，有满意的一致性，通过一致性检验。可用其归一化 <em>（列和为1）</em> 特征向量作为权向量，否则需要重新构造比较矩阵A进行调整。</p><p><img src="/Pictures/MCM/AHP/plot02.png" alt="img"></p><h3 id="层次总排序及其一致性检验"><a href="#层次总排序及其一致性检验" class="headerlink" title="层次总排序及其一致性检验"></a>层次总排序及其一致性检验</h3><p>计算某一层次所有因素对于最高层（总目标）相对重要性的权值，称为层次总排序，这一过程是从最高层次到最低层次依次进行的。</p><p><img src="/Pictures/MCM/AHP/plot03.png" alt="img"></p><p><img src="/Pictures/MCM/AHP/plot04.png" alt="img"></p><p>层次总排序的一致性比率为：</p><p>$$CR\ &#x3D;\ \frac{a_{1}CI_{1}+a_{2}CI_{2}+\ldots+a_{m}CI_{m}}{a_{1}RI_{1}+a_{2}RI_{2}+\ldots+a_{m}RI_{m}}$$</p><p>当CR&lt;0.1是，认为层次总排序通过一致性检验。层次总排序具有满意度一致性，根据最下层（决策层）的层次总排序做出最后决策。</p>]]></content>
    
    
    <categories>
      
      <category>MCM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MCM</tag>
      
      <tag>AHP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>规划类问题</title>
    <link href="/2024/01/26/%E8%A7%84%E5%88%92%E7%B1%BB%E9%97%AE%E9%A2%98/"/>
    <url>/2024/01/26/%E8%A7%84%E5%88%92%E7%B1%BB%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<h1 id="线性规划问题"><a href="#线性规划问题" class="headerlink" title="线性规划问题"></a>线性规划问题</h1><p>在人们的生产实践中，经常会遇到如何利用现有资源来安排生产以取得最大效益的问题。</p><p>此类问题构成了运筹学的一个重要分支——数学规划，而LP（Linear Programming）则是其中的一个重要分支。</p><h2 id="线性规划的基本形式"><a href="#线性规划的基本形式" class="headerlink" title="线性规划的基本形式"></a>线性规划的基本形式</h2><p>\begin{cases}<br>maxS &#x3D; c_{1}x_{1}+c_{2}x_{2}+\ldots+c_{n}x_{n} &#x3D; CX \ldots (1.1)\\<br>a_{11}x_{1}+a_{12}x_{2}+\ldots+a_{1n}x_{n} &#x3D; b_{1} \\<br>a_{21}x_{1}+a_{22}x_{2}+\ldots+a_{2n}x_{n} &#x3D; b_{2}  \ldots (1.2)\\<br>\ldots \\<br>a_{n1}x_{1}+a_{n2}x_{2}+\ldots+a_{nn}x_{n} &#x3D; b_{n}\\<br>\end{cases}</p><p>其中，$x_{i}\ge0$ , $b_{j}\ge0$ , $(i,j)\in(1,2,\ldots,n)^2$ , $C$ , $X$表示矩阵</p><p>变量 $X$ 称为决策变量，式(1.1)称为问题的目标函数，(1.2)中的几个不等式称为约束条件，记为s.t.</p><p>如果目标函数是求最小值 $minZ &#x3D; CX$ ，令 $S&#x3D;-Z$，则$maxS&#x3D;-CX$。</p><h2 id="线性规划问题的MATLAB求解"><a href="#线性规划问题的MATLAB求解" class="headerlink" title="线性规划问题的MATLAB求解"></a>线性规划问题的MATLAB求解</h2><p>在MATLAB中，线性规划的目标函数默认为最小值，其规范形式为：</p><p>$$s.t.<br>\begin{cases}<br>Ax\le b\\<br>Aeq.x&#x3D;beq\\<br>lb\le x \le ub\\<br>\end{cases}$$</p><p>其中， $c,x,b,beq,lb,ub$ 为列向量， $f$ 称为价值向量， $b$ 称为资源向量， $A,Aeq$ 为矩阵</p><p>MATLAB内置函数支持三种模式的线性规划问题的求解:</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs MATLAB">[x,fval] = linprog(c,A,b)<br>[x,fval] = linprog(c,A,b,Aeq,beq)<br>[x,fval] = linprog(c,A,b,Aeq,beq,lb,ub)<br></code></pre></td></tr></table></figure><p>其中x返回的是决策变量的取值，fval返回的是目标函数的最优值，c为价值向量，A，b对应的是线性不等式约束，Aeq，beq对应的是线性等式约束，lb和ub对应决策向量的下界和上界。</p><h2 id="一道例题"><a href="#一道例题" class="headerlink" title="一道例题"></a>一道例题</h2><p>$$<br>max\ z&#x3D;2x_{1}+3x_{2}-5x_{3}<br>$$</p><p>$$s.t.<br>\begin{cases}<br>x_{1}+x_{2}+x_{3}&#x3D;7\\<br>2x_{1}-5x_{2}+x_{3}\ge 10\\<br>x_{1}+3x_{2}+x_{3}\le 12\\<br>x_{1},x_{2},x_{3}\ge 0<br>\end{cases}$$</p><p><strong>MATLAB代码如下：</strong></p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs MATLAB">f=[<span class="hljs-number">-2</span>;<span class="hljs-number">-3</span>;<span class="hljs-number">5</span>];<br>a=[<span class="hljs-number">-2</span>,<span class="hljs-number">5</span>,<span class="hljs-number">-1</span>;<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">1</span>];<br>b=[<span class="hljs-number">-10</span>;<span class="hljs-number">12</span>];<br>aeq=[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>];<br>beq=<span class="hljs-number">7</span>;<br>[x,y]=linprog(f,a,b,aeq,beq,<span class="hljs-built_in">zeros</span>(<span class="hljs-number">3</span>,<span class="hljs-number">1</span>));<br>x,y=-y<br></code></pre></td></tr></table></figure><h2 id="可转化为线性规划的问题"><a href="#可转化为线性规划的问题" class="headerlink" title="可转化为线性规划的问题"></a>可转化为线性规划的问题</h2><p>规划问题为</p><p>$$min\ \left| x_{1} \right|+\left| x_{2} \right|+ \ldots + \left| x_{n} \right|\\<br>s.t.\ Ax\le b$$</p><p>其中 $x&#x3D;\begin{bmatrix}x_{1}&amp;\ldots&amp;x_{n} \end{bmatrix}^{T}$ </p><p>事实上，我们可以进行如下处理：</p><p>取 $$u_{i}&#x3D;\frac{x_{i}+\left| x_{i} \right|}{2}$$</p><p>$$v_{i}&#x3D;\frac{-x_{i}+\left| x_{i} \right|}{2}$$</p><p>这样就把上面的问题转化为了：</p><p>$$<br>min\ \sum_{i&#x3D;1}^{n}(u_{i}+v_{i})<br>$$</p><p>$$s.t.<br>\begin{cases}<br>A(u-v)\le b\\<br>u,v\ge 0\\<br>\end{cases}$$</p><h2 id="审题到建模全过程分析"><a href="#审题到建模全过程分析" class="headerlink" title="审题到建模全过程分析"></a>审题到建模全过程分析</h2><p>市场上有n种资产 $s_{i}$ （i&#x3D;1,2,L,n） 可供选择，现用数额为M的相当大的资金作为一个时期的投资。这种n资产在这一时期内购买 $s_{i}$ 的平均收益为 $r_{i}$ ，风险损失率为 $q_{i}$ ，投资越分散，总的风险越少，总体风险可用投资的 $s_{i}$ 最大的一个风险来度量。</p><p>购买 $s_{i}$ 时需要交付交易费，费率为 $p_{i}$ ，当购买额不超过给定值 $u_{i}$ 时，交易费按购买 $u_{i}$ 计算。另外，假定同期银行存款利率时 $r_{0}$ ，既无交易费又无风险。（$r_{0}$&#x3D;5%）。n&#x3D;4时，相关数据如下表：</p><table><thead><tr><th>$s_{i}$</th><th>$r_{i}$(%)</th><th>$q_{i}$(%)</th><th>$p_{i}$(%)</th><th>$u_{i}$(元)</th></tr></thead><tbody><tr><td>$u_{i}$</td><td>28</td><td>2.5</td><td>1</td><td>103</td></tr><tr><td>$s_{2}$</td><td>21</td><td>1.5</td><td>2</td><td>198</td></tr><tr><td>$s_{3}$</td><td>23</td><td>5.5</td><td>4.5</td><td>52</td></tr><tr><td>$s_{4}$</td><td>25</td><td>2.6</td><td>6.5</td><td>40</td></tr></tbody></table><p>试给该公司设计一种投资组合方案，即给定资金M，有选择地购买若干种资产或存银行生息，使净收益尽可能大，使总体风险尽可能小。</p><h3 id="符号规定"><a href="#符号规定" class="headerlink" title="符号规定"></a>符号规定</h3><p>$s_{i}$ 表示第i种投资项目，如股票，债券等，$i&#x3D;0,1,L,n$,其中 $s_{0}$ 指存入银行；$r_{i},p_{i},q_{i}$ 分别表示 $s_{i}$ 的平均收益率、交易费率、风险损失率，$i&#x3D;0,L,n$,其中 $p_{0}&#x3D;0,q_{0}&#x3D;0$，<br>$u_{i}$ 表示 $s_{i}$ 的交易定额，$i&#x3D;1,L,n;x_{i}$ 表示投资项目 $s_{i}$ 的资金，$i&#x3D;0,1,L,n$ ; $a$ 表示投资风险度，$Q$ 表示总体收益。</p><h3 id="基本假设"><a href="#基本假设" class="headerlink" title="基本假设"></a>基本假设</h3><ol><li>投资数额M相当大，假设M&#x3D;1</li><li>投资越分散，总风险越小</li><li>总体风险用投资项目 $s_{i}$ 中最大的一个来衡量</li><li>n+1种资产之间相互独立</li><li>投资期间各项利率为定值</li><li>净收益和总体风险不受其他因素影响</li></ol><h3 id="基于假设抽象出数学模型"><a href="#基于假设抽象出数学模型" class="headerlink" title="基于假设抽象出数学模型"></a>基于假设抽象出数学模型</h3><p>1.总体风险用最大的一个来衡量，即：</p><p>$$max{q_{i}x_{i}|i&#x3D;1,2,L,n}$$</p><p>2.购买 $s_{i}$ 所附的交易费是一个与 $x_{i}$ 相关的函数，即：</p><p>$$f(x)&#x3D;<br>\begin{cases}<br>p_{i}x_{i},x_{i}\ge u_{i} \\<br> \\<br>p_{i}u_{i},x_{i}\le u_{i} \\<br>\end{cases}$$</p><p>而题目所给的定值 $u_{i}$ 相对总投资很小，所以购买 $s_{i}$ 都收益可以简化为 $(r_{i}-p_{i})x_{i}$。</p><p>3.要使净收益尽可能打，总体风险尽可能小，这是一个多目标规划模型，需要转化。</p><p>目标函数为：</p><p>$$\begin{cases}<br>max\ \sum_{i&#x3D;0}^{n}(r_{i}-p_{i})x_{i} \\<br> \\<br>min{max{q_{i}x_{i}}}<br>\end{cases}$$</p><p>约束条件为：</p><p>$$\begin{cases}<br>\sum_{i&#x3D;0}^{n}(1+p_{i})x_{i}&#x3D;M \\<br> \\<br>x_{i}\ge 0,  i&#x3D;0,1,\ldots n\\<br>\end{cases}$$</p><p><strong>模型一：</strong>固定风险水平，最大化优化收益</p><p>给定一个风险界限a，使最大的一个风险满足条件，这样就可以找到相应的投资方案。</p><p>$$<br>max\ \sum_{i&#x3D;0}^{n}(r_{i}-p_{i})x_{i}<br>$$</p><p>$$s.t.<br>\begin{cases}<br>\frac{q_{i}x_{i}}{M} \le a \\<br> \\<br>\sum_{i&#x3D;0}^{n}(1+p_{i})x_{i}&#x3D;M \\<br>\end{cases}$$</p><p>代入数据可得到以下公式：</p><p>$$<br>min\ f&#x3D;(-0.05,-0.27,-0.19,-0.185,-0,185)(x_{0},x_{1},x_{2},x_{3},x_{4})^{T}<br>$$</p><p>$$s.t.<br>\begin{cases}<br>x_{0}+1.01x_{1}+1.02x_{2}+1.045x_{3}+1.065x_{4}&#x3D;1\\<br>0.025x_{1}\le a\\<br>0.015x_{2}\le a\\<br>0.055x_{3}\le a\\<br>0.026x_{4}\le a\\<br>x_{i}\ge 0<br>\end{cases}$$</p><p>由于a是任意给定的风险度，我们可以从a&#x3D;0开始，以步长 $\Delta a&#x3D;0.001$ 进行循环搜索,程序如下：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs MATLAB">clc,clear<br>a=<span class="hljs-number">0</span>;<br><span class="hljs-built_in">hold</span> on<br><span class="hljs-keyword">while</span> a&lt;<span class="hljs-number">0.05</span><br>    c=[<span class="hljs-number">-0.05</span>,<span class="hljs-number">-0.27</span>,<span class="hljs-number">-0.19</span>,<span class="hljs-number">-0.185</span>,<span class="hljs-number">-0.185</span>];<br>    A=[<span class="hljs-built_in">zeros</span>(<span class="hljs-number">4</span>,<span class="hljs-number">1</span>),<span class="hljs-built_in">diag</span>([<span class="hljs-number">0.025</span>,<span class="hljs-number">0.015</span>,<span class="hljs-number">0.055</span>,<span class="hljs-number">0.026</span>])]<br>    b=a*<span class="hljs-built_in">ones</span>(<span class="hljs-number">4</span>,<span class="hljs-number">1</span>);<br>    Aeq=[<span class="hljs-number">1</span>,<span class="hljs-number">1.01</span>,<span class="hljs-number">1.02</span>,<span class="hljs-number">1.045</span>,<span class="hljs-number">1.065</span>];<br>    beq=<span class="hljs-number">1</span>;<br>    LB=<span class="hljs-built_in">zeros</span>(<span class="hljs-number">5</span>,<span class="hljs-number">1</span>);<br>    [x,Q]=linprog(c,A,b,Aeq,beq,LB);<br>    Q=-Q;<span class="hljs-built_in">plot</span>(a,Q,<span class="hljs-string">&#x27;*k&#x27;</span>);<br>    a=a+<span class="hljs-number">0.001</span>;<br><span class="hljs-keyword">end</span><br>xlabel(<span class="hljs-string">&#x27;a&#x27;</span>),ylabel(<span class="hljs-string">&#x27;Q&#x27;</span>)<br></code></pre></td></tr></table></figure><p>得到如下图形<br><img src="/Pictures/MCM/01/plot01.png" alt="img"></p><p>分析图形可知，随着风险度提升，收益上升。其中有两个拐点我们可以重点关注：<br>a&#x3D;0.006和a&#x3D;0.025<br>可以结合接下来的模型进一步分析。</p><p><strong>模型二：</strong>固定盈利水平，极小化风险</p><p>$$<br>min (max {q_{i}x_{i}})<br>$$</p><p>$$s.t<br>\begin{cases}<br>\sum_{i&#x3D;0}^{n}(r_{i}-p_{i})x_{i} \ge k\\<br> \\<br>\sum_{i&#x3D;0}^{n}(1+p_{i})x_{i}&#x3D;M \\<br>\end{cases}$$</p><p><strong>模型三：</strong>对风险和收益赋给权重s和（1-s），s称为投资偏好系数。</p><p>$$<br>min\ (s*{max{q_{i}x_{i}}}) -(1-s) \sum_{i&#x3D;0}^{n}(r_{i}-p_{i})x_{i}<br>$$</p><p>$$<br>s.t.\ \sum_{i&#x3D;0}^{n}(1+p_{i})x_{i}&#x3D;M<br>$$</p><h1 id="整数规划模型"><a href="#整数规划模型" class="headerlink" title="整数规划模型"></a>整数规划模型</h1><p>若数学规划中的变量（部分或全部）限制为整数时，称为整数规划。若在线性规划模型中，变量限制为整数，则称为整数线性规划（IP）。目前话没有一种方法能有效地求解一切整数规划。</p><p>整数规划有下面一些特点：</p><ol><li>原线性规划最优解全是整数，则整数规划与线性规划最优解一致。</li><li>整数规划无可行解。</li><li>有可行解，但最优解变差。</li><li>整数规划求最优解不能按照实数最优解简单取整所得。</li></ol><p>依照决策变量取证要求的不同，整数规划可分为<strong>纯整数规划、全整数规划、混合整数规划、0-1整数规划。</strong></p><ul><li><p>纯整数规划</p><blockquote><p>所有决策变量要求取非负整数。</p></blockquote></li><li><p>全整数规划</p><blockquote><p>除了所有决策变量要求非负整数外，系数 $a_{ij}$ 和常数 $b_{i}$ 也要求取整数。</p></blockquote></li><li><p>混合整数规划</p><blockquote><p>只有一部分决策变量要求取非负整数。</p></blockquote></li><li><p>0-1整数规划</p><blockquote><p>所有决策变量只能取0或1两个整数。</p></blockquote></li></ul><h2 id="整数线性规划的求解方法"><a href="#整数线性规划的求解方法" class="headerlink" title="整数线性规划的求解方法"></a>整数线性规划的求解方法</h2><p>设整数规划问题如下：</p><p>$$<br>max\ z &#x3D; x_{1}+x_{2}<br>$$</p><p>$$\begin{cases}<br>14x_{1}+9x_{2}\le 51 \\<br>-6x_{1}+3x_{2}\le 1 \\<br>x_{1},x_{2}\ge 0 且为整数 \\<br>\end{cases}$$</p><p>首先不考虑整数约束，得到线性规划问题（一般称为<strong>松弛问题</strong>或<strong>伴随问题</strong>）</p><p>得出图像如下：<br><img src="/Pictures/MCM/02/plot01.png" alt="img"></p><p>在解集内的所有整数点找出，一一带入，求出最优解，此法为完全枚举法，适用于约束条件较小的情况。</p><p>目前，常用的求解整数规划的方法：<em>分枝定界法、割平面法</em>；对于特殊的0-1规划问题采用<em>隐枚举法和匈牙利算法</em>。</p><h3 id="分枝定界法"><a href="#分枝定界法" class="headerlink" title="分枝定界法"></a>分枝定界法</h3><p>首先不考虑整数限制求出相应的松弛问题的最优解，若松弛问题无可行解，则ILP无可行解。</p><p>若求得的松弛问题最优解符合证书要求，则是ILP的最优解。</p><p>若不满足整数条件，则任选一个不满足整数条件的变量 $x_{i}^{0}$ 来构造新的约束条件添加到松弛问题中形成两个子问题（分别添加）：</p><p>$$<br>x_{i}\le \left [ x_{i}^{0} \right ] ; x_{i} \ge \left [ x_{i}^{0} \right ]+1<br>$$</p><p>依次在缩小的可行域中求解新构造线性规划的最优解，并重复上述过程直到子问题无解或有整数最优解。</p><h3 id="割平面算法"><a href="#割平面算法" class="headerlink" title="割平面算法"></a>割平面算法</h3><p>割平面算法的基本思想：</p><ul><li>如果松弛问题无解，则整数规划无解</li><li>如果松弛问题的最优解为整数向量，则其也是整数规划的最优解</li><li>如果解含有非整数分量，则对松弛问题添加线性约束条件来进行“割平面”操作，重复操作直到求出解或无解。</li></ul><p>$$<br>max\ z&#x3D;x_{1}+x_{2}<br>$$</p><p>$$\begin{cases}<br>-x_{1}+x_{2}\le 1 \\<br>3x_{1}+x_{2}\le 4 \\<br>x_{1},x_{2} \ge 0 且为整数<br>\end{cases}$$</p><p><img src="/Pictures/MCM/02/plot02.png" alt="img"></p><p>此时松弛问题的最优解不是整数，故我们分析图像可知：y轴截距做平行线上面的部分无法满足整数解，故舍去，体现在约束条件为 $x_{2}\le 1$ 。</p><p>对于一些问题，我们也可以利用引入松弛变量来将不等式的约束条件转化为等式约束条件。</p><p>在上题，我们可以引入松弛变量 $x_{3},x_{4}$ 来将不等约束转化为等式约束：</p><p>$$<br>max\ z&#x3D;x_{1}+x_{2}+0x_{3}+0x_{4}<br>$$</p><p>$$\begin{cases}<br>-x_{1}+x_{2}+x_{3}&#x3D;1 \\<br>3x_{1}+x_{2}+x_{4}&#x3D;4 \\<br>x_{1},x_{2},x_{3},x_{4} \ge 0 且为整数<br>\end{cases}$$</p><p>这样我们可以得到一个等式，<strong>将各变量的系数拆分为整数部分和小数部分</strong>。可以取 $x_{3},x_{4}$ 为自由变量，考虑利用线性代数的知识得出基础解系，再在基础解系中找出整数解。</p><p><img src="/Pictures/MCM/02/plot03.png" alt="img"></p><h3 id="匈牙利算法解决0-1规划问题"><a href="#匈牙利算法解决0-1规划问题" class="headerlink" title="匈牙利算法解决0-1规划问题"></a>匈牙利算法解决0-1规划问题</h3><p>$e.g.1$ 现有如下投资问题：</p><p>有600万元投资五个项目，收益如表，求利润最大的方案</p><table><thead><tr><th>项目</th><th>投资额</th><th>项目收益</th></tr></thead><tbody><tr><td>I</td><td>210</td><td>160</td></tr><tr><td>II</td><td>300</td><td>210</td></tr><tr><td>III</td><td>150</td><td>60</td></tr><tr><td>IV</td><td>130</td><td>80</td></tr><tr><td>V</td><td>260</td><td>180</td></tr></tbody></table><p>约束条件：项目I、II、III中选一项；项目III、IV中选一项；项目V以项目I为先验条件。</p><p>我们假设 $x_{i}&#x3D; \begin{cases} 1 ,选中第i项 \\ 0 不选第i项 \end{cases}$</p><p>则可以抽象出下列模型：</p><p>$$<br>max\ Z&#x3D;160x_{1}+210x_{2}+60x_{3}+80x_{4}+180x_{5}<br>$$</p><p>$$s.t.<br>\begin{cases}<br>210x_{1}+300x_{2}+150x_{3}+130x_{4}+260x_{5}\le 600 \\<br>x_{1}+x_{2}+x_{3}&#x3D;1 \\<br>x_{3}+x_{4}&#x3D;1 \\<br>x_{5}\le x_{1} \\<br>x_{1},x_{2},x_{3},x_{4},x_{5}&#x3D;0 or 1\\<br>\end{cases}$$</p><p>$e.g.2$ 指派问题</p><p>甲乙丙丁四个人，ABCD四项工作，要求每人只能做一项工作，每项工作只由一人完成，问如何让指派总时间最短？</p><table><thead><tr><th>人员&#x2F;时间&#x2F;任务</th><th>A</th><th>B</th><th>C</th><th>D</th></tr></thead><tbody><tr><td>甲</td><td>3</td><td>5</td><td>8</td><td>4</td></tr><tr><td>乙</td><td>6</td><td>8</td><td>5</td><td>4</td></tr><tr><td>丙</td><td>2</td><td>5</td><td>8</td><td>5</td></tr><tr><td>丁</td><td>9</td><td>2</td><td>5</td><td>2</td></tr></tbody></table><p>引入0-1变量 $x_{ij}$<br>$x_{ij}&#x3D;1 : 第 i 人做第 j 项工作$<br>$x_{ij}&#x3D;0 ：第 i 人不做第 j 项工作$</p><p>$$<br>min\ Z&#x3D;3x_{11}+5x_{12}+8x_{13}+4x_{14}+6x_{21}+8x_{22}+5x_{23}+4x_{24}+2x_{31}+5x_{32}+8x_{33}+5x_{34}+9x_{41}+2x_{42}+5x_{43}+2x_{44}<br>$$</p><p>每项任务只由一个人完成、每人只完成一项任务：每行每列之和均为1，即：<br>$$s.t.<br>\begin{cases}<br>\sum_{i&#x3D;1}^{n}x_{ij}&#x3D;1 \\<br> \\<br>\sum_{j&#x3D;1}^{n}x_{ij}&#x3D;1 \\<br> \\<br>x_{ij}&#x3D;0 or 1 \\<br>\end{cases}$$</p><p>一些特殊情况的处理：</p><ul><li>人少工作多：添加虚拟的“人”，代价都为0</li><li>人多工作少：添加虚拟的工作，代价都为0</li><li>一个人可做多件工作：该人变为几个相同的“人”</li><li>某工作一定不能有某人做：该人做该工作的相应代价取足够大M</li></ul><p><strong>指派问题的匈牙利解法的一般步骤：</strong></p><ol><li><p>第一步：变换指派问题的系数矩阵 $(c_{ij})$ 为 $(b_{ij})$ ，使在 $(b_{ij})$ 的各行各列中都出现0元素，即：</p><ul><li>从 $(c_{ij})$ 的每行元素中都减去该行的最小元素</li><li>再从所得新系数矩阵的每列元素中减去该列的最小元素<blockquote><p>其中， $(c_{ij})$ 为每行每列仅有一个1的矩阵</p></blockquote></li></ul></li><li><p>进行试指派，以寻求最优解</p><ul><li>在 $(b_{ij})$ 中尽可能寻找多的独立0元素，若能找出n个独立0元素，就以这n个独立0元素对应解矩阵 $(x_{ij})$ 中的元素为1，其余为0，这就得到最优解。</li><li>从只有一个0元素的行（列）开始，给这个0元素加圈，记作 O 。然后划去 O 所在列（行）的其它0元素，记作 X ，这表示这列所代表的任务已经指派完，不需要考虑他人。</li><li>给只有一个0元素的列（行）中的0元素加圈，划去所在行的0元素。</li><li>重复上述步骤直到尽可能多的0元素都被圈出和划掉。</li></ul></li><li><p>若仍有没有画圈的0元素，且同行（列）的0元素至少有两个，则从剩下0元素最少的行（列）开始，比较他们列中0元素的数量，选择0元素少的那个0元素。</p></li></ol><p>$$\begin{bmatrix}<br>  3&amp;  8&amp;  2&amp;  10&amp;3 \\<br>  8&amp;  7&amp;  2&amp;  9&amp;7 \\<br>  6&amp;  4&amp;  2&amp;  7&amp;5 \\<br>  8&amp;  4&amp;  2&amp;  3&amp;5 \\<br>  9&amp;  10&amp;  6&amp;  9&amp;10<br>\end{bmatrix}$$</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs MATLAB">c=[<span class="hljs-number">3</span>,<span class="hljs-number">8</span>,<span class="hljs-number">2</span>,<span class="hljs-number">10</span>,<span class="hljs-number">3</span>;<span class="hljs-number">8</span>,<span class="hljs-number">7</span>,<span class="hljs-number">2</span>,<span class="hljs-number">9</span>,<span class="hljs-number">7</span>;<span class="hljs-number">6</span>,<span class="hljs-number">4</span>,<span class="hljs-number">2</span>,<span class="hljs-number">7</span>,<span class="hljs-number">5</span>;<span class="hljs-number">8</span>,<span class="hljs-number">4</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">5</span>;<span class="hljs-number">9</span>,<span class="hljs-number">10</span>,<span class="hljs-number">6</span>,<span class="hljs-number">9</span>,<span class="hljs-number">10</span>]<br>c=c(:) <span class="hljs-comment">%将矩阵转化为向量</span><br>a=<span class="hljs-built_in">zeros</span>(<span class="hljs-number">10</span>,<span class="hljs-number">25</span>);<br><span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span>=<span class="hljs-number">1</span>:<span class="hljs-number">5</span><br>    a(<span class="hljs-built_in">i</span>,(<span class="hljs-built_in">i</span><span class="hljs-number">-1</span>)*<span class="hljs-number">5</span>+<span class="hljs-number">1</span>:<span class="hljs-number">5</span>*<span class="hljs-built_in">i</span>)=<span class="hljs-number">1</span>;<br>    a(<span class="hljs-number">5</span>+<span class="hljs-built_in">i</span>,<span class="hljs-built_in">i</span>:<span class="hljs-number">5</span>:<span class="hljs-number">25</span>)=<span class="hljs-number">1</span>;<br><span class="hljs-keyword">end</span>  <span class="hljs-comment">%循环将指派问题转化为线性规划问题</span><br>b=<span class="hljs-built_in">ones</span>(<span class="hljs-number">10</span>,<span class="hljs-number">1</span>);<br>[x,y]=linprog(c,[],[],a,b,<span class="hljs-built_in">zeros</span>(<span class="hljs-number">25</span>,<span class="hljs-number">1</span>),<span class="hljs-built_in">ones</span>(<span class="hljs-number">25</span>,<span class="hljs-number">1</span>));<br>X=<span class="hljs-built_in">reshape</span>(x,<span class="hljs-number">5</span>,<span class="hljs-number">5</span>)<br>opt=y<br></code></pre></td></tr></table></figure><p>求得最优指派方案为 $x_{15}&#x3D;x_{23}&#x3D;x_{32}&#x3D;x_{44}&#x3D;x_{51}&#x3D;1$，最优值为21.</p><h1 id="非线性规划"><a href="#非线性规划" class="headerlink" title="非线性规划"></a>非线性规划</h1><p>一般形式：<br>$$<br>min\ f(x)<br>$$</p><p>$$s.t.<br>\begin{cases}<br>h_{j}(x)\le 0\ j&#x3D;1,2,\ldots q \\<br> \\<br>g_{i}(x) &#x3D; 0\ i&#x3D;1,2,\ldots p<br>\end{cases}$$</p><p>在一组等式或不等式的约束下，求一个函数的最大值（或最小值）问题，其中至少有一个非线性函数，这类问题称之为非线性规划问题。</p><h2 id="MATLAB中非线性规划的数学模型写成以下形式："><a href="#MATLAB中非线性规划的数学模型写成以下形式：" class="headerlink" title="MATLAB中非线性规划的数学模型写成以下形式："></a>MATLAB中非线性规划的数学模型写成以下形式：</h2><p>$$<br>min\ f(x)<br>$$</p><p>$$s.t.<br>\begin{cases}<br>A.x\le b \\<br>Aeq.x &#x3D; beq \\<br>c(x) \le 0 \\<br>ceq(x) &#x3D; 0 \\<br>lb\le x \le ub<br>\end{cases}$$</p><p>其中 $f(x)$ 是标量函数， $c(x),ceq(x)$ 是非线性向量函数。</p><h2 id="二次规划"><a href="#二次规划" class="headerlink" title="二次规划"></a>二次规划</h2><p>若某非线性规划的目标函数为自变量的二次函数，约束条件又全是线性的，就称这种规划为二次规划。<br>MATLAB中二次规划的数学模型可以表述如下：<br>$$<br>min\ \frac{1}{2}x^{T}Hx+f^{T}x<br>$$</p><p>$$s.t.<br>\begin{cases}<br>Ax\le b \\<br>Aeq.x&#x3D;beq \\<br>lb \le x \le ub<br>\end{cases}$$</p><p>这里的H是实对称矩阵（二次型），f，b，beq，lb，ub是列向量，A，Aeq是相应维数的矩阵</p><p>MATLAB中二次规划的命令是<br>[x,fval]&#x3D;quadprog(H,f,A,b,Aeq,beq,lb,ub,x0,options)</p><h2 id="一道例题-1"><a href="#一道例题-1" class="headerlink" title="一道例题"></a>一道例题</h2><p>某公司有6个建筑工地要开工，每个工地的位置（用平面坐标系a，b表示，距离单位：KM）及水泥日用量d（吨）由下表给出。目前有两个临时料场位于A（5，1），B（2，7），日储量各有20吨。假设从料场导工地之间均有直线道路相连。</p><ol><li>试制定每天的供应计划，即从A，B两料场分别向各工地运送多少吨水泥，使总的吨千米数最小</li><li>为了进一步减少吨千米数，打算舍弃两个临时料场，改建两个新的，日储量各为20吨，问应建在何处，使得节省的吨千米数最大？</li></ol><p>工地位置(a,b)坐标参数以及水泥日用量d</p><table><thead><tr><th></th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th></tr></thead><tbody><tr><td>a</td><td>1.25</td><td>8.75</td><td>0.5</td><td>5.75</td><td>3</td><td>7.25</td></tr><tr><td>b</td><td>1.25</td><td>0.75</td><td>4.75</td><td>5</td><td>6.5</td><td>7.25</td></tr><tr><td>d</td><td>3</td><td>5</td><td>4</td><td>7</td><td>6</td><td>11</td></tr></tbody></table><h3 id="建立模型"><a href="#建立模型" class="headerlink" title="建立模型"></a>建立模型</h3><p>我们可以记工地的位置为 $(a_{i},b_{i})$ ，水泥日用量为 $d_{i}$ ，料场的坐标为 $(x_{j},y_{j})$ 日储量为 $e_{j}$ ，从料场j向工地i的运送量为 $X_{ij}$ 。</p><p>目标函数为： $min\ f&#x3D;\sum_{j&#x3D;1}^{2} \sum_{i&#x3D;1}^{6} X_{ij} \sqrt{(x_{j}-a_{i})^{2}+(y_{j}-b_{i})^{2}}$</p><p>$$s.t.<br>\begin{cases}<br>\sum_{j&#x3D;1}^{2}X_{ij}&#x3D;d_{i} \\<br> \\<br>\sum_{i&#x3D;1}^{6}X_{ij}\le e_{j}<br>\end{cases}$$</p><p>当启用临时料场时决策变量为 $X_{ij}$ ，<br>不用临时料场时决策变量为： $X_{ij},x_{j},y_{j}$</p><hr><p>来源：b站数模老哥，SJTU数模资料库。</p>]]></content>
    
    
    <categories>
      
      <category>MCM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MCM</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MCM绪论</title>
    <link href="/2024/01/26/MCM%E6%A8%A1%E5%9E%8B%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    <url>/2024/01/26/MCM%E6%A8%A1%E5%9E%8B%E4%B8%8E%E7%AE%97%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h2>数学建模的六个步骤</h2><h3>模型准备</h3>了解问题的实际背景，明确其实际意义，掌握对象的各种信息，用数学问题来解释问题的精髓。<blockquote><p>了解模型的<em>主要功能</em>、<em>使用场景</em>、<em>需要条件</em>、<em>优缺点</em>、<em>改进方向</em></p></blockquote><h3>模型假设</h3>根据实际对象的特征和建模的目的，对问题进行必要的简化，并用精确的语言提出一些恰当的假设，并用表达式将其表达出来。<h3>模型建立</h3>在假设的基础上，利用适当的数学工具来刻划各变量之间的数学关系，建立相应的数据结构。<h3>模型求解</h3>利用获取的数据资料，对模型的所有参数做出计算。推导模型的公式，将数学表达式变为建模方法的标准形式，通过限制条件，对模型进行求解。<h3>模型分析</h3>对所要建立模型的思路进行阐述，对所得的结果进行数学上的分析。包括误差分析、数据稳定性分析等。<h3>模型检验</h3>用非技术性的语言回答实际问题。将模型分析结果与实际情景进行比较，用来验证模型的准确性、合理性和适用性。<hr><h2>赛题的类型</h2><h3>预测类</h3>通过分析已有的数据或者现象，找出其内在发展规律，热案后对未来情形做出预测的过程。<ul><li>小样本内部预测</li><li>大样本内部预测</li><li>小样本未来预测</li><li>大样本随机因素或周期特征的未来预测</li></ul><p>解决预测类赛题的一般步骤：</p><ol><li>确定预测目标</li><li>收集、分析资料</li><li>选择合适的模型进行拟合</li><li>分析结果并修正</li></ol><h3>评价类</h3>按照一定的标准对事物的发展或者现状进行划分的过程。<ul><li>生态环境</li><li>社会建设</li><li>方案策略</li></ul><p>解决评价类赛题的一般步骤：</p><ol><li>明确评价目的</li><li>确定被评价的对象</li><li>建立评价指标体系</li><li>确定个指标相对应的权重系数</li><li>选择或构造综合评价模型</li><li>计算各系统的综合评价值并得出结果</li></ol><h3>机理分析类赛题</h3>根据对现实对象特性的认识，分析其因果关系，找出反应內部机理的规律。<ul><li>空气动力学</li><li>流体力学</li><li>热力学</li></ul><h3>优化类赛题</h3>在现有条件相对固定的情况下，如何使目标效果达到最佳。优化类问题往往需要分析三个关键因素：<ul><li>目标函数</li><li>决策变量</li><li>约束条件</li></ul><p>解决优化类赛题的一般步骤：</p><ol><li>确定优化目标</li><li>确定决策变量</li><li>构建目标函数</li><li>根据已知条件构建约束条件</li><li>选择合适的方法求解目标函数并给出优化结果</li></ol>]]></content>
    
    
    <categories>
      
      <category>MCM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MCM</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
